Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 1310
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                      data_dir
0   1       3.2    10.0                     2.5   lsp_sap  data/clsb/consistency_group/
1  10      22.9    42.6                    21.5   lsp_sap  data/clsb/consistency_group/
2  50      40.3    61.2                    39.0   lsp_sap  data/clsb/consistency_group/
Save log/bert-large-uncased/clsb/consistency_group/IsA.lsp_sap.csv
Save log/bert-large-uncased/clsb/consistency_group/IsA.lsp_sap.tsv

#Test_instances: 1310
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                      data_dir
0   1      14.4    16.5                    12.0   lsp_dap  data/clsb/consistency_group/
1  10      39.8    48.2                    38.2   lsp_dap  data/clsb/consistency_group/
2  50      61.0    66.0                    59.2   lsp_dap  data/clsb/consistency_group/
Save log/bert-large-uncased/clsb/consistency_group/IsA.lsp_dap.csv
Save log/bert-large-uncased/clsb/consistency_group/IsA.lsp_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 1337
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                     data_dir
0   1       1.3     6.0                     1.2   lsp_sap  data/hypernymsuite/BLESS/consistency_group/
1  10      10.0    21.0                     9.5   lsp_sap  data/hypernymsuite/BLESS/consistency_group/
2  50      22.1    37.5                    21.1   lsp_sap  data/hypernymsuite/BLESS/consistency_group/
Save log/bert-large-uncased/BLESS/consistency_group/IsA.lsp_sap.csv
Save log/bert-large-uncased/BLESS/consistency_group/IsA.lsp_sap.tsv

#Test_instances: 1337
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                     data_dir
0   1       7.0     8.6                     5.9   lsp_dap  data/hypernymsuite/BLESS/consistency_group/
1  10      19.4    25.1                    18.5   lsp_dap  data/hypernymsuite/BLESS/consistency_group/
2  50      36.3    44.4                    35.1   lsp_dap  data/hypernymsuite/BLESS/consistency_group/
Save log/bert-large-uncased/BLESS/consistency_group/IsA.lsp_dap.csv
Save log/bert-large-uncased/BLESS/consistency_group/IsA.lsp_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 957
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1       0.0     1.4                     0.0   lsp_sap  data/hypernymsuite/EVAL/consistency_group/
1  10       3.7    14.3                     3.3   lsp_sap  data/hypernymsuite/EVAL/consistency_group/
2  50      14.0    32.2                    12.5   lsp_sap  data/hypernymsuite/EVAL/consistency_group/
Save log/bert-large-uncased/EVAL/consistency_group/IsA.lsp_sap.csv
Save log/bert-large-uncased/EVAL/consistency_group/IsA.lsp_sap.tsv

#Test_instances: 957
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1       1.3     2.5                     0.7   lsp_dap  data/hypernymsuite/EVAL/consistency_group/
1  10      11.7    17.8                    10.7   lsp_dap  data/hypernymsuite/EVAL/consistency_group/
2  50      32.1    39.7                    28.9   lsp_dap  data/hypernymsuite/EVAL/consistency_group/
Save log/bert-large-uncased/EVAL/consistency_group/IsA.lsp_dap.csv
Save log/bert-large-uncased/EVAL/consistency_group/IsA.lsp_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 1385
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1       1.3     5.7                     1.2   lsp_sap  data/hypernymsuite/LEDS/consistency_group/
1  10      13.0    33.4                    12.2   lsp_sap  data/hypernymsuite/LEDS/consistency_group/
2  50      28.2    54.7                    26.6   lsp_sap  data/hypernymsuite/LEDS/consistency_group/
Save log/bert-large-uncased/LEDS/consistency_group/IsA.lsp_sap.csv
Save log/bert-large-uncased/LEDS/consistency_group/IsA.lsp_sap.tsv

#Test_instances: 1385
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1       5.2     8.8                     4.0   lsp_dap  data/hypernymsuite/LEDS/consistency_group/
1  10      29.0    42.2                    27.4   lsp_dap  data/hypernymsuite/LEDS/consistency_group/
2  50      53.1    62.8                    51.3   lsp_dap  data/hypernymsuite/LEDS/consistency_group/
Save log/bert-large-uncased/LEDS/consistency_group/IsA.lsp_dap.csv
Save log/bert-large-uncased/LEDS/consistency_group/IsA.lsp_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 576
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                        data_dir
0   1       5.9    14.6                     5.2   lsp_sap  data/lm_diagnostic_extended/consistency_group/
1  10      23.4    43.2                    20.8   lsp_sap  data/lm_diagnostic_extended/consistency_group/
2  50      37.5    64.4                    33.7   lsp_sap  data/lm_diagnostic_extended/consistency_group/
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.lsp_sap.csv
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.lsp_sap.tsv

#Test_instances: 576
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                        data_dir
0   1      22.0    25.3                    19.6   lsp_dap  data/lm_diagnostic_extended/consistency_group/
1  10      47.9    57.5                    46.0   lsp_dap  data/lm_diagnostic_extended/consistency_group/
2  50      65.5    75.5                    62.8   lsp_dap  data/lm_diagnostic_extended/consistency_group/
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.lsp_dap.csv
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.lsp_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 12994
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', 'obj_mask_sentence_sg_4', 'obj_mask_sentence_sg_5', 'obj_mask_sentence_sg_6']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4', 'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6']
    K  Singular  Plural  Paired Singular-Plural mask_type                                       data_dir
0   1       0.1     0.3                     0.1   lsp_sap  data/hypernymsuite/SHWARTZ/consistency_group/
1  10       1.0     3.3                     0.8   lsp_sap  data/hypernymsuite/SHWARTZ/consistency_group/
2  50       3.2     9.1                     2.6   lsp_sap  data/hypernymsuite/SHWARTZ/consistency_group/
Traceback (most recent call last):
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 261, in save
    self._save()
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 266, in _save
    self._save_body()
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 304, in _save_body
    self._save_chunk(start_i, end_i)
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 315, in _save_chunk
    libwriters.write_csv_rows(
  File "pandas/_libs/writers.pyx", line 75, in pandas._libs.writers.write_csv_rows
OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

OSError: [Errno 122] Disk quota exceeded

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "consistency_check_group.py", line 1134, in <module>
    df.to_csv(outpath)
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3551, in to_csv
    return DataFrameRenderer(formatter).to_csv(
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/formats/format.py", line 1180, in to_csv
    csv_formatter.save()
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 261, in save
    self._save()
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/common.py", line 124, in __exit__
    self.close()
  File "/home/chunhua/.local/lib/python3.8/site-packages/pandas/io/common.py", line 116, in close
    handle.close()
OSError: [Errno 122] Disk quota exceeded
