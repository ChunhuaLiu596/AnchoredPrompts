Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 1310
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                               data_dir
0   1      10.1     0.3                     0.2   def_sap  data/clsb/singular/consistency_group/
1  10      36.8     8.6                     8.2   def_sap  data/clsb/singular/consistency_group/
Save log/bert-large-uncased/singular/consistency_group/IsA.def_sap.csv
Save log/bert-large-uncased/singular/consistency_group/IsA.def_sap.tsv

#Test_instances: 1310
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                               data_dir
0   1      15.3     1.2                     1.1   def_dap  data/clsb/singular/consistency_group/
1  10      40.5    13.1                    13.0   def_dap  data/clsb/singular/consistency_group/
Save log/bert-large-uncased/singular/consistency_group/IsA.def_dap.csv
Save log/bert-large-uncased/singular/consistency_group/IsA.def_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 1337
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                     data_dir
0   1       5.5     0.1                     0.1   def_sap  data/hypernymsuite/BLESS/consistency_group/
1  10      19.8     3.8                     2.6   def_sap  data/hypernymsuite/BLESS/consistency_group/
Save log/bert-large-uncased/BLESS/consistency_group/IsA.def_sap.csv
Save log/bert-large-uncased/BLESS/consistency_group/IsA.def_sap.tsv

#Test_instances: 1337
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                     data_dir
0   1       7.9     1.0                     0.9   def_dap  data/hypernymsuite/BLESS/consistency_group/
1  10      19.6     5.7                     5.5   def_dap  data/hypernymsuite/BLESS/consistency_group/
Save log/bert-large-uncased/BLESS/consistency_group/IsA.def_dap.csv
Save log/bert-large-uncased/BLESS/consistency_group/IsA.def_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 957
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1       2.8     0.2                     0.1   def_sap  data/hypernymsuite/EVAL/consistency_group/
1  10      21.5     2.6                     2.0   def_sap  data/hypernymsuite/EVAL/consistency_group/
Save log/bert-large-uncased/EVAL/consistency_group/IsA.def_sap.csv
Save log/bert-large-uncased/EVAL/consistency_group/IsA.def_sap.tsv

#Test_instances: 957
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1       4.1     0.4                     0.3   def_dap  data/hypernymsuite/EVAL/consistency_group/
1  10      25.2     5.7                     4.7   def_dap  data/hypernymsuite/EVAL/consistency_group/
Save log/bert-large-uncased/EVAL/consistency_group/IsA.def_dap.csv
Save log/bert-large-uncased/EVAL/consistency_group/IsA.def_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 1385
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1       4.9     0.2                     0.2   def_sap  data/hypernymsuite/LEDS/consistency_group/
1  10      29.2     5.1                     4.4   def_sap  data/hypernymsuite/LEDS/consistency_group/
Save log/bert-large-uncased/LEDS/consistency_group/IsA.def_sap.csv
Save log/bert-large-uncased/LEDS/consistency_group/IsA.def_sap.tsv

#Test_instances: 1385
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                    data_dir
0   1      11.3     1.2                     0.9   def_dap  data/hypernymsuite/LEDS/consistency_group/
1  10      38.9     9.0                     8.3   def_dap  data/hypernymsuite/LEDS/consistency_group/
Save log/bert-large-uncased/LEDS/consistency_group/IsA.def_dap.csv
Save log/bert-large-uncased/LEDS/consistency_group/IsA.def_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 576
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                        data_dir
0   1      13.7     0.7                     0.7   def_sap  data/lm_diagnostic_extended/consistency_group/
1  10      50.9     9.9                     9.7   def_sap  data/lm_diagnostic_extended/consistency_group/
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.def_sap.csv
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.def_sap.tsv

#Test_instances: 576
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                        data_dir
0   1      30.7     0.5                     0.5   def_dap  data/lm_diagnostic_extended/consistency_group/
1  10      66.3    19.6                    19.4   def_dap  data/lm_diagnostic_extended/consistency_group/
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.def_dap.csv
Save log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.def_dap.tsv

Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Debug: False
#Test_instances: 12994
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                       data_dir
0   1       0.4     0.1                     0.0   def_sap  data/hypernymsuite/SHWARTZ/consistency_group/
1  10       2.7     1.3                     0.5   def_sap  data/hypernymsuite/SHWARTZ/consistency_group/
Save log/bert-large-uncased/SHWARTZ/consistency_group/IsA.def_sap.csv
Save log/bert-large-uncased/SHWARTZ/consistency_group/IsA.def_sap.tsv

#Test_instances: 12994
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  warnings.warn(
---------------------------------------- obj_label evaluation ----------------------------------------
pred_col_sg ['obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3']
pred_col_pl ['obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2', 'obj_mask_sentence_pl_3']
    K  Singular  Plural  Paired Singular-Plural mask_type                                       data_dir
0   1       1.4     0.2                     0.2   def_dap  data/hypernymsuite/SHWARTZ/consistency_group/
1  10       8.4     3.3                     2.3   def_dap  data/hypernymsuite/SHWARTZ/consistency_group/
Save log/bert-large-uncased/SHWARTZ/consistency_group/IsA.def_dap.csv
Save log/bert-large-uncased/SHWARTZ/consistency_group/IsA.def_dap.tsv

