{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json \n",
    "import copy\n",
    "import re \n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from copy import deepcopy\n",
    "import pathlib\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import string\n",
    "from inflection import pluralize, singularize\n",
    "from util_wordnet import get_sister_terms\n",
    "from transformers import pipeline\n",
    "\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "STOP_WORDS = en.Defaults.stop_words\n",
    "\n",
    "from IPython.display import display\n",
    "from df_to_latex import DataFrame2Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_article(word):\n",
    "    if word[0] in ['a', 'e', 'i', 'o', 'u']:\n",
    "        return 'an'\n",
    "    return 'a'\n",
    "\n",
    "\n",
    "def save_dict_to_json(examples, output_path):\n",
    "    ''' \n",
    "    save a list of dicts into otuput_path, orient='records' (each line is a dict) \n",
    "    examples: a list of dicts\n",
    "    output_path: \n",
    "    '''\n",
    "\n",
    "    with open(output_path, 'w') as fout:\n",
    "        for example in examples:\n",
    "            json.dump(example, fout)\n",
    "            fout.write(\"\\n\")\n",
    "        print(f\"save {output_path} with {len(examples)} lines\")\n",
    "\n",
    "def add_period_at_the_end_of_sentence(sentence):\n",
    "    last_token = sentence[-1]\n",
    "    if last_token != '.': \n",
    "        return sentence + '.'\n",
    "    return [sentence]\n",
    "\n",
    "def get_unmasker(model, device, targets=None):\n",
    "    if targets is None: \n",
    "        unmasker = pipeline('fill-mask', model=model)# 'bert-large-uncased') #initialize the masker\n",
    "    else:\n",
    "        unmasker = pipeline('fill-mask', model=model, targets=targets )# 'bert-large-uncased') #initialize the masker\n",
    "    return unmasker\n",
    "\n",
    "\n",
    "\n",
    "def remove_noisy_test_data(df):\n",
    "  ''' \n",
    "  relation=\"hasproperty\"\n",
    "  why? some data points don't belong to this relation types \n",
    "  case1., sub_label=number, such as \"10 is ten.\"  We don't say ten is the property of 10\n",
    "  case2, sub_label = 'person_name' and obj_label = 'nuts;, such as \"\"Andrew is [MASK].\", [MASK]=nuts\n",
    "  '''\n",
    "  sub_labels_to_exclude = ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '30', '5', '50', '60', '7', '70', '70s', '80', '9', '90']\n",
    "  obj_labels_to_exclude  = ['nuts']\n",
    "  df = df.query(f\"sub_label not in {sub_labels_to_exclude}\")\n",
    "  df = df.query(f\"sub_label not in {obj_labels_to_exclude}\")\n",
    "  return  df.reset_index(drop=True)\n",
    "\n",
    "def locate_sub_obj_position(ent, sentence, index_not_in) :\n",
    "  ''' \n",
    "  function: find the index of ent in a sentence, the result will be used to filter instances whose ent cannot be find at their sentences\n",
    "  args: \n",
    "    sentence: the sentnces to mask, could be the string or a list of tokens \n",
    "    ent: the ent to be found (sub_label) \n",
    "    index_not_in: the default index for failed instances (an ent not in a sentence)\n",
    "  ''' \n",
    "\n",
    "  if isinstance(sentence, list):\n",
    "    if ent not in sentence:\n",
    "      return index_not_in\n",
    "    return sentence.index(ent)  \n",
    "  else:\n",
    "    sentence = copy.deepcopy(sentence).lower()\n",
    "    if isinstance(sentence, str):\n",
    "      try:\n",
    "        index = sentence.index(ent)\n",
    "        return  index \n",
    "      except: \n",
    "        print(f\"NOT FOUND sub_label: {ent} -> in sentence: {sentence}\")\n",
    "        return index_not_in\n",
    "      \n",
    "        print(ent, sentence)\n",
    "        return index_not_in\n",
    "\n",
    "def load_data(filepath, clean_test=True, tokenize=False):\n",
    "  '''\n",
    "  return the cleaned data\n",
    "  args:\n",
    "    tokenize: if True: the maksed_sentences will be tokenzied (this is slwoers); \n",
    "            otherwise, we use the string match to filter the failed sentences\n",
    "    clean_test: default is True. We filter out some noisy samples spoted by huamns \n",
    "               Note that this is relation specific \n",
    "\n",
    "  '''\n",
    "  index_not_in = 10000\n",
    "\n",
    "  with open(filepath, 'r', encoding='utf-8') as fin:\n",
    "    data = fin.readlines()\n",
    "    data = [eval(x) for x in data]\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df['obj_label'] = df['obj_label'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "\n",
    "  if tokenize:\n",
    "    df['masked_sentence_tokens'] = df['masked_sentences'].apply(lambda x: tokenize_sentence(x[0]))\n",
    "    df['sub_position'] = df[['sub_label', 'masked_sentence_tokens']].apply(lambda x: locate_sub_obj_position(x[0], x[1], index_not_in=index_not_in), axis=1)\n",
    "\n",
    "  if clean_test: \n",
    "    df = remove_noisy_test_data(df)\n",
    "    df['sub_position'] = df[['sub_label', 'masked_sentences']].apply(lambda x: locate_sub_obj_position(x[0], x[1][0], index_not_in), axis=1)\n",
    "    df = df.query(f\"sub_position !={index_not_in}\") #.reset_index() #cue can not be matched in the sentence\n",
    "\n",
    "  print(f\"#Test_instances: {len(df.index)}\")\n",
    "  return df.reset_index(drop=True)\n",
    "\n",
    "def get_unmasker(model, targets=None):\n",
    "    if targets is None: \n",
    "        unmasker = pipeline('fill-mask', model=model)# 'bert-large-uncased') #initialize the masker\n",
    "    else:\n",
    "        unmasker = pipeline('fill-mask', model=model, targets=targets )# 'bert-large-uncased') #initialize the masker\n",
    "    return unmasker\n",
    "\n",
    "\n",
    "def get_highest_mrr_among_labels(label, pred):\n",
    "    '''\n",
    "    return the highest rank among the multiple labels. This is applicable to single labels as well, if we the single label is put in a list\n",
    "\n",
    "    pred: a list of words (candidates)\n",
    "    label: the true labels, which is a list (different forms of a word, e.g., singular or plurs, like animal and animals)\n",
    "    '''\n",
    "    mrr = 0 \n",
    "    if pred is None: return mrr \n",
    "\n",
    "    rank_list = [ pred.index(item) + 1 for item in label if item in pred] \n",
    "    if len(rank_list)>0:\n",
    "        mrr = 1/min(rank_list)\n",
    "    return mrr \n",
    "\n",
    "\n",
    "def get_predictions(input_words, outputs, filter_objects_flag=True, filter_objects_with_input=True):\n",
    "    '''\n",
    "    excluding x from outputs\n",
    "    '''\n",
    "    filled_tokens = list()\n",
    "    filled_scores = defaultdict()\n",
    "    for i, output in enumerate(outputs):\n",
    "#         print(output)\n",
    "        filled_token = output['token_str'].strip().lower()\n",
    "        filled_score = output['score']\n",
    "        if filter_objects_flag:\n",
    "            \n",
    "            #####Add conditions to filter unwanted ################\n",
    "            # filter the repetation of a concept in the explanation. See the the following example\n",
    "            # [MASK] is the capability to do a particular job . -> capacity \n",
    "            if not filled_token.isalpha(): continue\n",
    "            if filled_token in STOP_WORDS: continue \n",
    "            if len(filled_token)<=1: continue \n",
    "            if filter_objects_with_input:\n",
    "                if filled_token in [input_words]: continue\n",
    "                # [re.sub(\"\\s+\", '', x) for x in input_word.split()]: continue #filter out the target in input  \n",
    "            if filled_token.startswith(\"#\"): continue\n",
    "            #####Add conditions to filter unwanted ################\n",
    "\n",
    "            filled_tokens.append(filled_token)\n",
    "            filled_scores[filled_token] = filled_score\n",
    "        else:\n",
    "            filled_tokens.append(filled_token)\n",
    "            filled_scores[filled_token] = filled_score\n",
    "    \n",
    "    return pd.Series((filled_tokens, filled_scores))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_to_jsonl_path={\n",
    "    \"EVAL\": \"../data/hypernymysuite/data/hypernymsuite/EVAL/IsA.jsonl\",\n",
    "    \"BLESS\": \"../data/hypernymysuite/data/hypernymsuite/BLESS/IsA.jsonl\",\n",
    "    \"LEDS\": \"../data/hypernymysuite/data/hypernymsuite/LEDS/IsA.jsonl\",\n",
    "    \"DIAG\": \"../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/singular/IsA.jsonl\",\n",
    "    \"CLSB\": \"../data/CLSB/single_label/IsA.jsonl\",\n",
    "    \"SHWARTZ\": \"../data/hypernymysuite/data/hypernymsuite/SHWARTZ/IsA.jsonl\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layout_table(df, dataset_list =['BLESS','LMDIAG', 'CLSB', 'SHWARTZ', 'EVAL', 'LEDS']):\n",
    "    '''\n",
    "    format the output with desired dataset layout and metrics \n",
    "    '''\n",
    "    df_groups = []\n",
    "    for dataset in dataset_list: \n",
    "       \n",
    "        df_group = df.query(f\"dataset == '{dataset}'\")\n",
    "        df_group = df_group.pivot(index=\"pattern_id\", columns=['dataset'], values=['MRR', 'P@K'])\n",
    "        df_group = df_group.swaplevel(0, 1, axis=1)\n",
    "        df_groups.append(df_group)\n",
    "\n",
    "    df_groups = pd.concat(df_groups, axis=1)\n",
    "    return df_groups\n",
    "\n",
    "def merge_predictions_in_concept_level(uniform_funcion, words, top_k=None ):\n",
    "    '''\n",
    "    uniform_function: either signualarize or pluralize \n",
    "    '''\n",
    "    words_uniformed = [uniform_funcion(word) for word in words]\n",
    "    concepts = list(OrderedDict.fromkeys(words_uniformed))\n",
    "    return concepts[:top_k] if top_k is not None else concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchor helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inflection import singularize, pluralize\n",
    "\n",
    "def read_anchors(path_sg, path_pl, anchor_source, debug=False):\n",
    "    '''\n",
    "    read the anchor files mined from singualr and plural\n",
    "    \n",
    "    args: \n",
    "        anchor_soure: using the anchors mined from singular probe or plural probe\n",
    "        \n",
    "    return: \n",
    "        dic_sub_to_anchors_singular: both sub_label and subj_anchors are singular \n",
    "        dic_sub_to_anchors_plural: both sub_label and subj_anchors are plural \n",
    "    '''\n",
    "#     dfsg = pd.read_csv(path_sg)\n",
    "#     dfsg['subj_anchors'] = dfsg['subj_anchors'].apply(lambda x: eval(x))\n",
    "    \n",
    "#     dfpl = pd.read_csv(path_pl)\n",
    "#     dfpl['subj_anchors'] = dfpl['subj_anchors'].apply(lambda x: eval(x))\n",
    "#     df = pd.merge(dfsg, dfpl, on = 'uuid', suffixes=('_sg', '_pl'))\n",
    "# if anchor_source == 'plural':\n",
    "#         #convert the singular anchors into singular format\n",
    "#         df['subj_anchors_sg'] = df['subj_anchors_pl'].progress_apply(lambda x: [singularize(word) for word in x])\n",
    "#     elif anchor_source == 'singular':\n",
    "#         #convert the plural anchors into singular format\n",
    "#         df['subj_anchors_pl'] = df['subj_anchors_sg'].progress_apply(lambda x: [pluralize(word) for word in x])\n",
    "\n",
    "    df = pd.read_csv(path_pl)\n",
    "    \n",
    "    if debug: df = df.head(5)\n",
    "    df['subj_anchors_sg'] = df['subj_anchors_sg'].apply(lambda x: eval(x))\n",
    "    df['subj_anchors_pl'] = df['subj_anchors_pl'].apply(lambda x: eval(x))\n",
    "        \n",
    "    dic_sub_to_anchors_singular = dict(zip(df['sub_label_sg'], df['subj_anchors_sg']))\n",
    "    dic_sub_to_anchors_plural = dict(zip(df['sub_label_pl'], df['subj_anchors_pl']))\n",
    "    \n",
    "    return dic_sub_to_anchors_singular, dic_sub_to_anchors_plural\n",
    "\n",
    "def insert_anchors(dic_sub_to_anchors, df, mask_col, sub_col, anchor_col, probe_type, article_for_z=False):\n",
    "    \n",
    "    df[anchor_col] = df[sub_col].apply(lambda x: dic_sub_to_anchors.get(x) )\n",
    "#     display(df[mask_col].head())\n",
    "    \n",
    "    if probe_type =='plural':\n",
    "        df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', anchor)  for anchor in x[0]], axis=1)\n",
    "    elif probe_type == 'singular':\n",
    "        if article_for_z: \n",
    "           df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', \"{} {}\".format(_get_article(anchor), anchor))  for anchor in x[0]], axis=1) \n",
    "        else:\n",
    "#             display(df.head())\n",
    "#             for anchor_col, mask_col in zip(df[anchor_col], df[mask_col]):\n",
    "#                 print(anchor_col, mask_col)\n",
    "#                 print([mask_col.replace('[Z]', anchor)  for anchor in anchor_col])\n",
    "            \n",
    "            df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', anchor)  for anchor in x[0]], axis=1) \n",
    "            \n",
    "    return df \n",
    "\n",
    "\n",
    "def save_hypernym_vocab(df, vocab_path, y_singular=True, y_plural=True):\n",
    "    vocab_sg = set(x[0] for x in df['obj_label_singular'])\n",
    "    vocab_pl = set(x[0] for x in df_def_sap['obj_label_plural'])\n",
    "    \n",
    "    if y_singular and y_plural: \n",
    "        vocab = vocab_sg.union(vocab_pl)\n",
    "        df_vocab = pd.DataFrame(data=list(vocab))\n",
    "        with open(vocab_path, 'w') as fout:\n",
    "            df_vocab.to_csv(vocab_path, header=None, index=None, sep=' ', mode='a')\n",
    "    print(f\"save {vocab_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitional Patterns (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Test_instances: 957\n",
      "#Test_instances: 1337\n",
      "#Test_instances: 1385\n",
      "#Test_instances: 576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Test_instances: 1310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"2\" halign=\"left\">BLESS</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LMDIAG</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CLSB</th>\n",
       "      <th colspan=\"2\" halign=\"left\">EVAL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LEDS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>P@K</th>\n",
       "      <th>MRR</th>\n",
       "      <th>P@K</th>\n",
       "      <th>MRR</th>\n",
       "      <th>P@K</th>\n",
       "      <th>MRR</th>\n",
       "      <th>P@K</th>\n",
       "      <th>MRR</th>\n",
       "      <th>P@K</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pattern_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>35.1</td>\n",
       "      <td>72.2</td>\n",
       "      <td>25.7</td>\n",
       "      <td>51.6</td>\n",
       "      <td>17.6</td>\n",
       "      <td>41.6</td>\n",
       "      <td>22.0</td>\n",
       "      <td>50.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.5</td>\n",
       "      <td>38.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>73.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>59.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>48.8</td>\n",
       "      <td>30.6</td>\n",
       "      <td>60.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.8</td>\n",
       "      <td>64.6</td>\n",
       "      <td>21.1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset    BLESS       LMDIAG        CLSB        EVAL        LEDS      \n",
       "             MRR   P@K    MRR   P@K   MRR   P@K   MRR   P@K   MRR   P@K\n",
       "pattern_id                                                             \n",
       "1           11.2  25.4   35.1  72.2  25.7  51.6  17.6  41.6  22.0  50.7\n",
       "2           18.5  38.9   42.9  73.1  32.6  59.8  21.4  48.8  30.6  60.9\n",
       "3           14.6  31.0   28.8  64.6  21.1  44.0  13.3  34.2  14.3  37.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "14\n",
      "\\begin{table*}[!h]\n",
      "\\centering\n",
      "\\begin{adjustbox}{width=\\textwidth}\n",
      "\\label{tab:def_single_pattern_ablation}\n",
      "\\begin{tabular}{l|ll|ll|ll|ll|ll|ll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{2}{c|}{BLESS} & \\multicolumn{2}{c|}{LMDIAG} & \\multicolumn{2}{c|}{CLSB} & \\multicolumn{2}{c|}{EVAL} & \\multicolumn{2}{c|}{LEDS} \\\\\n",
      " & MRR & P@K & MRR & P@K & MRR & P@K & MRR & P@K & MRR & P@K \\\\\n",
      "pattern_id &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1 & 11.2 & 25.4 & 35.1 & 72.2 & 25.7 & 51.6 & 17.6 & 41.6 & 22.0 & 50.7 \\\\\n",
      "2 & \\textbf{18.5} & \\textbf{38.9} & \\textbf{42.9} & \\textbf{73.1} & \\textbf{32.6} & \\textbf{59.8} & \\textbf{21.4} & \\textbf{48.8} & \\textbf{30.6} & \\textbf{60.9} \\\\\n",
      "3 & 14.6 & 31.0 & 28.8 & 64.6 & 21.1 & 44.0 & 13.3 & 34.2 & 14.3 & 37.5 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      " \\end{adjustbox}\n",
      "\\caption{Experimental results on definitional single patterns.}\n",
      "\\end{table*}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<df_to_latex.DataFrame2Latex at 0x2b273e380a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def_sap_id_to_patterns = {\n",
    "         \"1\": \"[X] is a [Y].\", \n",
    "         \"2\": \"[X] is a type of [Y].\", \n",
    "         \"3\": \"[X] is a kind [Y].\", \n",
    "        }\n",
    "\n",
    "unmasker = unmasker = pipeline('fill-mask', model= 'bert-large-uncased', device=0)\n",
    "top_k=10\n",
    "batch_size = 100 \n",
    "df_res_def = []\n",
    "debug =  False #True \n",
    "# debug =  True\n",
    "\n",
    "for dataset, filepath in dataset_to_jsonl_path.items():\n",
    "    if dataset ==\"SHWARTZ\": continue \n",
    "        \n",
    "    df = load_data(filepath)\n",
    "    \n",
    "    for idx, pattern in def_sap_id_to_patterns.items():\n",
    "        df[f'masked_sentences_{idx}'] = df['sub_label'].apply(lambda x: [pattern.replace(\"[Y]\", \"[MASK]\").replace(\"[X]\", f\"{_get_article(x)} {x}\")])\n",
    "    \n",
    "    if debug: \n",
    "        df = df.head(5)\n",
    "#         display(df.head())    \n",
    "    for idx in range(1, len(def_sap_id_to_patterns.keys())+1 ):\n",
    "        df[f'outputs_{idx}']  = unmasker(df[f'masked_sentences_{idx}'].to_list(), top_k= 2*top_k, batch_size=batch_size)\n",
    "        df[[f'pred_{idx}', f'pred_{idx}_score']] = df[['sub_label',f'outputs_{idx}']].apply(lambda x: get_predictions(input_words=x[0], outputs=x[1], \n",
    "                                                                                           filter_objects_flag=True, \n",
    "                                                                                           filter_objects_with_input=True), \n",
    "                                                                                      axis=1)\n",
    "        \n",
    "#         df[f'pred_{idx}']= df[f'pred_{idx}'].apply(lambda x: merge_predictions_in_concept_level(uniform_funcion=singularize, words=x, top_k=top_k))\n",
    "        df['obj_label_sg'] = df['obj_label']#.apply(lambda x: [singularize(x[0])])\n",
    "        \n",
    "        df[f'p@{top_k}_{idx}'] = df[['obj_label_sg', f'pred_{idx}']].apply(lambda x: 1 if x[0][0] in x[1]  else 0, axis=1)\n",
    "        df[f'mrr@{top_k}_{idx}'] = df[['obj_label_sg', f'pred_{idx}']].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "        \n",
    "        p_at_k = df[f'p@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        mrr = df[f'mrr@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        df_res_def.append({\"dataset\": dataset, \"pattern_id\": idx, \"P@K\": round(p_at_k, 3)*100, 'MRR': round(mrr,3)*100 })\n",
    "        \n",
    "df_res_def = pd.DataFrame(df_res_def)\n",
    "df_res_def_pivot = layout_table(df_res_def, dataset_list =['BLESS','LMDIAG', 'CLSB',  'EVAL', 'LEDS']) #'SHWARTZ',\n",
    "display(df_res_def_pivot)\n",
    "\n",
    "DataFrame2Latex(df= df_res_def_pivot , label=f'tab:def_single_pattern_ablation', \n",
    "            caption=f'Experimental results on definitional single patterns.', \n",
    "            output_file= None , #'../log/paper_results/latex.test.tex',\n",
    "            adjustbox_width = 'textwidth',\n",
    "            precision = 1,\n",
    "            column_format='l|ll|ll|ll|ll|ll|ll',\n",
    "            multicolumn_format='c|'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[digger, shovel, tool, grave, coffin, person, spade, stone, potter, corpse, tombstone, carpenter, knife, miner, human, man, hammer, blacksmith, blade, marker]</td>\n",
       "      <td>[shovel, tool, coffin, oven, digger, grave, tombstone, marker, knife, instrument, mortar, container, spade, implement, hammer, vessel, potter, cutler, weapon, pottery]</td>\n",
       "      <td>[person, man, object, gesture, creature, worker, individual, human, thing, woman, animal, deed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fish, catfish, salmon, shark, trout, swimmer, carp, bass, freshwater, gastropod, river, mollusk, perch, frog, crocodile, mouth, fishery, toad, dolphin]</td>\n",
       "      <td>[fish, catfish, shark, toad, salmon, swimmer, frog, mosquito, river, bass, mouth, turtle, alligator, bird, gastropod, snake, mollusk, freshwater, dolphin]</td>\n",
       "      <td>[fish, swimmer, mouth, animal, catfish, bird, snake, creature, species, person, frog, dog, shark, lizard, tongue]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bird, parrot, penguin, dolphin, fish, dog, pigeon, turtle, whale, butterfly, cat, mammal, vulture, duck, shark, monkey, kite, crane, heron, ship]</td>\n",
       "      <td>[bird, fish, dolphin, parrot, turtle, animal, dog, pigeon, cat, shark, mammal, penguin, whale, aircraft, boat, monkey, crane, chicken, crab, helicopter]</td>\n",
       "      <td>[bird, animal, fish, dog, object, creature, ship, vessel, gesture, person, monkey, parrot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[snake, worm, spider, bug, lizard, predator, troll, rat, vampire, demon, fish, frog, mosquito, toad, viper, slug, scorpion, pest, mammal, monster]</td>\n",
       "      <td>[insect, spider, snake, animal, lizard, wasp, beetle, ant, fish, mammal, worm, rat, slug, bug, turtle, scorpion, bird, mosquito, troll, catfish]</td>\n",
       "      <td>[person, creature, man, animal, demon, human, spirit, robot, monster, alien, snake, elf, soul, character]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[fish, canoe, drum, dog, boat, drummer, bird, parrot, person, horse, vessel, puppet, turtle, kite, cow, man, kettle, woman, donkey, tree]</td>\n",
       "      <td>[drum, boat, canoe, guitar, fish, umbrella, flute, instrument, vessel, toy, bell, whip, banjo, gong, knife, bird, container, bicycle, kettle, puppet]</td>\n",
       "      <td>[person, man, gesture, woman, animal, creature, object, dog, spirit, bird, character, horse, individual, human, soul, fish, male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>[plane, aircraft, glider, helicopter, airship, spaceship, balloon, spacecraft, machine, airplane, design, fighter, ship, kite, vehicle, rocket, zeppelin, boat, bomber]</td>\n",
       "      <td>[aircraft, airplane, airship, plane, helicopter, spacecraft, glider, balloon, vehicle, ship, automobile, warship, boat, airline, machine, fighter, bomber, aviation, car]</td>\n",
       "      <td>[aircraft, machine, object, ship, vehicle, car, spaceship, airplane, vessel, plane, spacecraft, robot, design, gesture, building]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>[tree, plant, vegetable, shrub, monkey, banana, bush, palm, bamboo, grass, bug, bean, vine, leaf, spider, python, herb, fruit, mammal, bird]</td>\n",
       "      <td>[plant, tree, vegetable, monkey, grass, banana, shrub, fruit, bean, palm, bamboo, spider, bird, animal, insect, python, herb, bread, mammal, cactus]</td>\n",
       "      <td>[tree, palm, animal, monkey, plant, insect, bird, object, gesture, fruit, man, fish, game]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>[vehicle, plane, ship, machine, vessel, car, spacecraft, warship, boat, spaceship, helicopter, design, carrier, craft, robot, structure, building, platform, weapon, device]</td>\n",
       "      <td>[vehicle, spacecraft, vessel, machine, ship, warship, airplane, structure, car, building, plane, craft, weapon, transport, robot, automobile, object, helicopter, boat]</td>\n",
       "      <td>[object, machine, thing, vehicle, vessel, ship, person, spaceship, spacecraft, body, gesture, robot, design, building, car]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>[person, horse, woman, man, vessel, fish, dog, tree, boat, bird, human, ship, verb, river, vegetable, robot, dragon, mountain, noun, pig]</td>\n",
       "      <td>[pastry, cheese, bread, cake, pottery, fish, knife, vessel, soup, pig, sausage, wine, bamboo, mortar, boat, rock, rice, stone, tree, coin]</td>\n",
       "      <td>[person, man, woman, gesture, object, spirit, creature, character, dog, horse, human, animal, male]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>[bicycle, track, sport, wheel, slide, cycle, cyclist, ski, skier, brake, machine, team, downhill, vault, discipline, sprinter, walker, vehicle, bike, platform]</td>\n",
       "      <td>[bicycle, sport, cycling, track, vault, cyclist, slide, skiing, platform, event, trap, cycle, competition, ski, skier, downhill, skeleton, freestyle, racing, exercise]</td>\n",
       "      <td>[machine, object, boat, vehicle, movement, game, vessel, play, shot, gesture, table, horse, sport]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                           pred_1  \\\n",
       "0                  [digger, shovel, tool, grave, coffin, person, spade, stone, potter, corpse, tombstone, carpenter, knife, miner, human, man, hammer, blacksmith, blade, marker]   \n",
       "1                        [fish, catfish, salmon, shark, trout, swimmer, carp, bass, freshwater, gastropod, river, mollusk, perch, frog, crocodile, mouth, fishery, toad, dolphin]   \n",
       "2                              [bird, parrot, penguin, dolphin, fish, dog, pigeon, turtle, whale, butterfly, cat, mammal, vulture, duck, shark, monkey, kite, crane, heron, ship]   \n",
       "3                              [snake, worm, spider, bug, lizard, predator, troll, rat, vampire, demon, fish, frog, mosquito, toad, viper, slug, scorpion, pest, mammal, monster]   \n",
       "4                                       [fish, canoe, drum, dog, boat, drummer, bird, parrot, person, horse, vessel, puppet, turtle, kite, cow, man, kettle, woman, donkey, tree]   \n",
       "..                                                                                                                                                                            ...   \n",
       "571       [plane, aircraft, glider, helicopter, airship, spaceship, balloon, spacecraft, machine, airplane, design, fighter, ship, kite, vehicle, rocket, zeppelin, boat, bomber]   \n",
       "572                                  [tree, plant, vegetable, shrub, monkey, banana, bush, palm, bamboo, grass, bug, bean, vine, leaf, spider, python, herb, fruit, mammal, bird]   \n",
       "573  [vehicle, plane, ship, machine, vessel, car, spacecraft, warship, boat, spaceship, helicopter, design, carrier, craft, robot, structure, building, platform, weapon, device]   \n",
       "574                                     [person, horse, woman, man, vessel, fish, dog, tree, boat, bird, human, ship, verb, river, vegetable, robot, dragon, mountain, noun, pig]   \n",
       "575               [bicycle, track, sport, wheel, slide, cycle, cyclist, ski, skier, brake, machine, team, downhill, vault, discipline, sprinter, walker, vehicle, bike, platform]   \n",
       "\n",
       "                                                                                                                                                                        pred_2  \\\n",
       "0      [shovel, tool, coffin, oven, digger, grave, tombstone, marker, knife, instrument, mortar, container, spade, implement, hammer, vessel, potter, cutler, weapon, pottery]   \n",
       "1                   [fish, catfish, shark, toad, salmon, swimmer, frog, mosquito, river, bass, mouth, turtle, alligator, bird, gastropod, snake, mollusk, freshwater, dolphin]   \n",
       "2                     [bird, fish, dolphin, parrot, turtle, animal, dog, pigeon, cat, shark, mammal, penguin, whale, aircraft, boat, monkey, crane, chicken, crab, helicopter]   \n",
       "3                             [insect, spider, snake, animal, lizard, wasp, beetle, ant, fish, mammal, worm, rat, slug, bug, turtle, scorpion, bird, mosquito, troll, catfish]   \n",
       "4                        [drum, boat, canoe, guitar, fish, umbrella, flute, instrument, vessel, toy, bell, whip, banjo, gong, knife, bird, container, bicycle, kettle, puppet]   \n",
       "..                                                                                                                                                                         ...   \n",
       "571  [aircraft, airplane, airship, plane, helicopter, spacecraft, glider, balloon, vehicle, ship, automobile, warship, boat, airline, machine, fighter, bomber, aviation, car]   \n",
       "572                       [plant, tree, vegetable, monkey, grass, banana, shrub, fruit, bean, palm, bamboo, spider, bird, animal, insect, python, herb, bread, mammal, cactus]   \n",
       "573    [vehicle, spacecraft, vessel, machine, ship, warship, airplane, structure, car, building, plane, craft, weapon, transport, robot, automobile, object, helicopter, boat]   \n",
       "574                                 [pastry, cheese, bread, cake, pottery, fish, knife, vessel, soup, pig, sausage, wine, bamboo, mortar, boat, rock, rice, stone, tree, coin]   \n",
       "575    [bicycle, sport, cycling, track, vault, cyclist, slide, skiing, platform, event, trap, cycle, competition, ski, skier, downhill, skeleton, freestyle, racing, exercise]   \n",
       "\n",
       "                                                                                                                                pred_3  \n",
       "0                                      [person, man, object, gesture, creature, worker, individual, human, thing, woman, animal, deed]  \n",
       "1                    [fish, swimmer, mouth, animal, catfish, bird, snake, creature, species, person, frog, dog, shark, lizard, tongue]  \n",
       "2                                           [bird, animal, fish, dog, object, creature, ship, vessel, gesture, person, monkey, parrot]  \n",
       "3                            [person, creature, man, animal, demon, human, spirit, robot, monster, alien, snake, elf, soul, character]  \n",
       "4    [person, man, gesture, woman, animal, creature, object, dog, spirit, bird, character, horse, individual, human, soul, fish, male]  \n",
       "..                                                                                                                                 ...  \n",
       "571  [aircraft, machine, object, ship, vehicle, car, spaceship, airplane, vessel, plane, spacecraft, robot, design, gesture, building]  \n",
       "572                                         [tree, palm, animal, monkey, plant, insect, bird, object, gesture, fruit, man, fish, game]  \n",
       "573        [object, machine, thing, vehicle, vessel, ship, person, spaceship, spacecraft, body, gesture, robot, design, building, car]  \n",
       "574                                [person, man, woman, gesture, object, spirit, creature, character, dog, horse, human, animal, male]  \n",
       "575                                 [machine, object, boat, vehicle, movement, game, vessel, play, shot, gesture, table, horse, sport]  \n",
       "\n",
       "[576 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['pred_1', 'pred_2', 'pred_3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexico-Synatactic Patterns (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Test_instances: 576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>pattern_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Function functools.partial(<function _highlight_value at 0x2afcba792700>, op='max') resulted in the apply method collapsing to a Series.\nUsually, this is the result of the function returning a single value, instead of list-like.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9f8e9158662a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m DataFrame2Latex(df= df_res_lsp_pivot , label=f'tab:lsp_single_pattern_ablation', \n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mcaption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Experimental results on LSP single patterns.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;31m#'../log/paper_results/latex.test.tex',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gpfs/projects/punim0478/chunhua/cogsci/DAP/pre_post_process/script/df_to_latex.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, label, caption, output_file, adjustbox_width, precision, column_format, multicolumn_format, hide_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticolumn_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulticolumn_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         self.convert_df_to_latex_table(self.df, label=self.label, caption=self.caption, \n\u001b[0m\u001b[1;32m     14\u001b[0m                                        \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjustbox_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madjustbox_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                        \u001b[0mprecision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gpfs/projects/punim0478/chunhua/cogsci/DAP/pre_post_process/script/df_to_latex.py\u001b[0m in \u001b[0;36mconvert_df_to_latex_table\u001b[0;34m(self, df, label, caption, output_file, adjustbox_width, span_two_columns, bold_max, precision, column_format, multicolumn_format, hide_index)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mmulticolumn_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'l'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         table_latex = table_string.to_latex(\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mcolumn_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mmulticol_align\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulticolumn_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36mto_latex\u001b[0;34m(self, buf, column_format, position, position_float, hrules, clines, label, caption, sparse_index, sparse_columns, multirow_align, multicol_align, siunitx, environment, encoding, convert_css)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0mmulticol_align\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulticol_align\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"styler.latex.multicol_align\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0mmultirow_align\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultirow_align\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"styler.latex.multirow_align\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m         latex = obj._render_latex(\n\u001b[0m\u001b[1;32m   1042\u001b[0m             \u001b[0msparse_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[0msparse_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/style_render.py\u001b[0m in \u001b[0;36m_render_latex\u001b[0;34m(self, sparse_index, sparse_columns, clines, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mRender\u001b[0m \u001b[0ma\u001b[0m \u001b[0mStyler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlatex\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \"\"\"\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/style_render.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_todo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, func, axis, subset, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1448\u001b[0m                 \u001b[0;34mf\"Function {repr(func)} resulted in the apply method collapsing to a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m                 \u001b[0;34mf\"Series.\\nUsually, this is the result of the function returning a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Function functools.partial(<function _highlight_value at 0x2afcba792700>, op='max') resulted in the apply method collapsing to a Series.\nUsually, this is the result of the function returning a single value, instead of list-like."
     ]
    }
   ],
   "source": [
    "\n",
    "lsp_sap_id_to_patterns = {\n",
    "         \"1\": \"[Y] such as [X].\", \n",
    "         \"2\": \"[Y], including [X].\", \n",
    "         \"3\": \"[Y], especially [X].\", \n",
    "         \"4\": \"[X] or other [Y].\", \n",
    "         \"5\": \"[X] and other [Y].\", \n",
    "         \"6\": \"such [Y] as [X].\", \n",
    "        }\n",
    "\n",
    "\n",
    "debug =  False #True \n",
    "# debug = True \n",
    "batch_size=100\n",
    "unmasker = unmasker = pipeline('fill-mask', model= 'bert-large-uncased', device=0)\n",
    "top_k=10\n",
    "\n",
    "df_res_lsp = []\n",
    "for dataset, filepath in dataset_to_jsonl_path.items():\n",
    "    if dataset!='DIAG': continue \n",
    "    df = load_data(filepath)\n",
    "\n",
    "    df['sub_label_pl'] = df['sub_label'].apply(lambda x: pluralize(x))\n",
    "    df['obj_label_pl'] = df['obj_label'].apply(lambda x: [pluralize(x[0])])\n",
    "    for idx, pattern in lsp_sap_id_to_patterns.items():\n",
    "        df[f'masked_sentences_{idx}'] = df['sub_label_pl'].apply(lambda x: [pattern.replace(\"[Y]\", \"[MASK]\").replace(\"[X]\", x)])\n",
    "    \n",
    "    if debug: \n",
    "        df = df.head(5)\n",
    "#         display(df.head(5))\n",
    "    \n",
    "    for idx, pattern in lsp_sap_id_to_patterns.items():\n",
    "        df[f'outputs_{idx}']  = unmasker(df[f'masked_sentences_{idx}'].to_list(), top_k= 2*top_k, batch_size=batch_size)\n",
    "        df[[f'pred_{idx}', f'pred_{idx}_score']] = df[['sub_label_pl',f'outputs_{idx}']].apply(lambda x: get_predictions(input_words=x[0], outputs=x[1], \n",
    "                                                                                           filter_objects_flag=True, \n",
    "                                                                                           filter_objects_with_input=True), \n",
    "                                                                                      axis=1)\n",
    "        \n",
    "        df[f'pred_{idx}']= df[f'pred_{idx}'].apply(lambda x: merge_predictions_in_concept_level(uniform_funcion=pluralize, words=x, top_k=top_k))\n",
    "        df[f'p@{top_k}_{idx}'] = df[['obj_label_pl', f'pred_{idx}']].apply(lambda x: 1 if x[0][0] in x[1] else 0, axis=1)\n",
    "        df[f'mrr@{top_k}_{idx}'] = df[['obj_label_pl', f'pred_{idx}']].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "        \n",
    "        p_at_k = df[f'p@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        mrr = df[f'mrr@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        df_res_lsp.append({\"dataset\": dataset, \"pattern_id\": idx, \"P@K\": round(p_at_k, 3) *100 , 'MRR': round(mrr, 3)*100})\n",
    "\n",
    "\n",
    "df_res_lsp = pd.DataFrame(df_res_lsp)\n",
    "df_res_lsp_pivot = layout_table(df_res_lsp)\n",
    "display(df_res_lsp_pivot)\n",
    "\n",
    "\n",
    "DataFrame2Latex(df= df_res_lsp_pivot , label=f'tab:lsp_single_pattern_ablation', \n",
    "            caption=f'Experimental results on LSP single patterns.', \n",
    "            output_file= None , #'../log/paper_results/latex.test.tex',\n",
    "            adjustbox_width = 'textwidth',\n",
    "            precision = 1,\n",
    "            column_format='l|ll|ll|ll|ll|ll|ll',\n",
    "            multicolumn_format='c|'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lsp_sap_id_to_patterns = {\n",
    "         \"1\": \"[Y] such as [X].\", \n",
    "         \"2\": \"[Y], including [X].\", \n",
    "         \"3\": \"[Y], especially [X].\", \n",
    "         \"4\": \"[X] or other [Y].\", \n",
    "         \"5\": \"[X] and other [Y].\", \n",
    "         \"6\": \"such [Y] as [X].\", \n",
    "        }\n",
    "\n",
    "\n",
    "debug =  False #True \n",
    "# debug = True \n",
    "batch_size=100\n",
    "unmasker = unmasker = pipeline('fill-mask', model= 'bert-large-uncased', device=0)\n",
    "top_k=10\n",
    "\n",
    "df_res_lsp = []\n",
    "for dataset, filepath in dataset_to_jsonl_path.items():\n",
    "    if dataset!='DIAG': continue \n",
    "    df = load_data(filepath)\n",
    "\n",
    "    df['sub_label_pl'] = df['sub_label'].apply(lambda x: pluralize(x))\n",
    "    df['obj_label_pl'] = df['obj_label']#.apply(lambda x: x[0]])\n",
    "    for idx, pattern in lsp_sap_id_to_patterns.items():\n",
    "        df[f'masked_sentences_{idx}'] = df['sub_label_pl'].apply(lambda x: [pattern.replace(\"[Y]\", \"[MASK]\").replace(\"[X]\", x)])\n",
    "    \n",
    "    if debug: \n",
    "        df = df.head(5)\n",
    "#         display(df.head(5))\n",
    "    \n",
    "    for idx, pattern in lsp_sap_id_to_patterns.items():\n",
    "        df[f'outputs_{idx}']  = unmasker(df[f'masked_sentences_{idx}'].to_list(), top_k= 2*top_k, batch_size=batch_size)\n",
    "        df[[f'pred_{idx}', f'pred_{idx}_score']] = df[['sub_label_pl',f'outputs_{idx}']].apply(lambda x: get_predictions(input_words=x[0], outputs=x[1], \n",
    "                                                                                           filter_objects_flag=True, \n",
    "                                                                                           filter_objects_with_input=True), \n",
    "                                                                                      axis=1)\n",
    "        \n",
    "        df[f'pred_{idx}']= df[f'pred_{idx}'].apply(lambda x: merge_predictions_in_concept_level(uniform_funcion=singularize, words=x, top_k=top_k))\n",
    "        df[f'p@{top_k}_{idx}'] = df[['obj_label', f'pred_{idx}']].apply(lambda x: 1 if x[0][0] in x[1] else 0, axis=1)\n",
    "        df[f'mrr@{top_k}_{idx}'] = df[['obj_label', f'pred_{idx}']].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "        \n",
    "        p_at_k = df[f'p@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        mrr = df[f'mrr@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        df_res_lsp.append({\"dataset\": dataset, \"pattern_id\": idx, \"P@K\": round(p_at_k, 3) *100 , 'MRR': round(mrr, 3)*100})\n",
    "\n",
    "\n",
    "df_res_lsp = pd.DataFrame(df_res_lsp)\n",
    "df_res_lsp_pivot = layout_table(df_res_lsp)\n",
    "display(df_res_lsp_pivot)\n",
    "\n",
    "\n",
    "DataFrame2Latex(df= df_res_lsp_pivot , label=f'tab:lsp_single_pattern_ablation', \n",
    "            caption=f'Experimental results on LSP single patterns.', \n",
    "            output_file= None , #'../log/paper_results/latex.test.tex',\n",
    "            adjustbox_width = 'textwidth',\n",
    "            precision = 1,\n",
    "            column_format='l|ll|ll|ll|ll|ll|ll',\n",
    "            multicolumn_format='c|'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subset vs group\n",
    "- we want to examine what's the effect of pattern numbers to the final performance\n",
    "- plot: x is the number of patterns, y is the performance on the subset of the patterns with corresponding number on x \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
