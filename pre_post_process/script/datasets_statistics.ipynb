{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json \n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import string\n",
    "from inflection import pluralize\n",
    "from util_wordnet import get_sister_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bert_vocab(bert_vocab_path = 'data/bert-large-uncased-vocab.txt'):\n",
    "    \n",
    "    \n",
    "    vocab = set()\n",
    "    with open(bert_vocab_path, 'r') as fin: \n",
    "        lines = fin.readlines()\n",
    "        for line in lines: \n",
    "            line = line.strip()\n",
    "            vocab.add(line)\n",
    "    return vocab        \n",
    "\n",
    "bert_vocab= read_bert_vocab(bert_vocab_path = '../../data/bert-large-uncased-vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'BLESS': '../../data/hypernymsuite/BLESS/IsA.jsonl',\n",
       "             'DIAG': '../../data/lm_diagnostic_extended/singular/IsA.jsonl',\n",
       "             'CLSB': '../../data/clsb/singular/IsA.jsonl',\n",
       "             'LEDS': '../../data/hypernymsuite/LEDS/IsA.jsonl',\n",
       "             'EVAL': '../../data/hypernymsuite/EVAL/IsA.jsonl',\n",
       "             'SHWARTZ': '../../data/hypernymsuite/SHWARTZ/IsA.jsonl'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_respath={\n",
    "    \"hypernymsuite-BLESS\": \"data/hypernymsuite/BLESS/IsA.jsonl\",\n",
    "    \"lm_diagnostic_extended-singular\": \"data/lm_diagnostic_extended/singular/IsA.jsonl\",\n",
    "    \"clsb-singular\": \"data/clsb/singular/IsA.jsonl\",\n",
    "    \"hypernymsuite-LEDS\": \"data/hypernymsuite/LEDS/IsA.jsonl\",\n",
    "    \"hypernymsuite-EVAL\": \"data/hypernymsuite/EVAL/IsA.jsonl\",\n",
    "    \"hypernymsuite-SHWARTZ\": \"data/hypernymsuite/SHWARTZ/IsA.jsonl\"}\n",
    "\n",
    "def get_dataset_to_respath(dataset_to_respath, print_flag=False):\n",
    "    # remote path \n",
    "#     dataset_to_respath = {'hypernymsuite-BLESS': 'log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'lm_diagnostic_extended-singular': 'log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv', 'clsb-singular': 'log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv', 'hypernymsuite-LEDS': 'log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-EVAL': 'log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-SHWARTZ': 'log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv'}\n",
    "\n",
    "    source_dir = 'spartan:~/cogsci/DAP/'\n",
    "    target_dir = '../../'\n",
    "    dataset_to_localpath = defaultdict()\n",
    "    dataset_rename = {\n",
    "        'hypernymsuite-BLESS': 'BLESS', 'lm_diagnostic_extended-singular': 'DIAG', 'clsb-singular':'CLSB', 'hypernymsuite-LEDS': 'LEDS', 'hypernymsuite-EVAL': 'EVAL', 'hypernymsuite-SHWARTZ': \n",
    "        \"SHWARTZ\"\n",
    "    }\n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        path = path.replace(\".tsv\", \".csv\")\n",
    "        source_path = source_dir + path \n",
    "        dataset_l1 = dataset.split(\"-\")[0]\n",
    "        dataset_l2 = dataset.split(\"-\")[1] \n",
    "        target_path = target_dir + path\n",
    "        scp_string = f\"!scp {source_path} {target_path}\"\n",
    "        if print_flag:\n",
    "            print(scp_string)\n",
    "            print()\n",
    "#         print(target_path)\n",
    "        dataset_to_localpath[dataset_rename[dataset]] = target_path \n",
    "#     print(dataset_to_localpath)\n",
    "    return dataset_to_localpath\n",
    "dataset_to_localpath = get_dataset_to_respath(dataset_to_respath)\n",
    "dataset_to_localpath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_label_pl</th>\n",
       "      <th>relation</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A graver is a [MASK].]</td>\n",
       "      <td>tool</td>\n",
       "      <td>graver</td>\n",
       "      <td>gravers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[bevel, dibber, spreader, hammer, crank, float...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[A smallmouth is a [MASK].]</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouth</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[largemouth]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A pelican is a [MASK].]</td>\n",
       "      <td>bird</td>\n",
       "      <td>pelican</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[cormorant, snakebird, tropicbird, darter, anh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A sapsucker is a [MASK].]</td>\n",
       "      <td>bird</td>\n",
       "      <td>sapsucker</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[wryneck, redhead, piculet, ivorybill, flicker]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A mako is a [MASK].]</td>\n",
       "      <td>fish</td>\n",
       "      <td>mako</td>\n",
       "      <td>makos</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[porbeagle]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              masked_sentences obj_label   sub_label sub_label_pl relation  \\\n",
       "0      [A graver is a [MASK].]      tool      graver      gravers      IsA   \n",
       "1  [A smallmouth is a [MASK].]      fish  smallmouth  smallmouths      IsA   \n",
       "2     [A pelican is a [MASK].]      bird     pelican     pelicans      IsA   \n",
       "3   [A sapsucker is a [MASK].]      bird   sapsucker   sapsuckers      IsA   \n",
       "4        [A mako is a [MASK].]      fish        mako        makos      IsA   \n",
       "\n",
       "                                          sub_sister  uuid  \n",
       "0  [bevel, dibber, spreader, hammer, crank, float...     1  \n",
       "1                                       [largemouth]     2  \n",
       "2  [cormorant, snakebird, tropicbird, darter, anh...     3  \n",
       "3    [wryneck, redhead, piculet, ivorybill, flicker]     4  \n",
       "4                                        [porbeagle]     5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as fin:\n",
    "        data = fin.readlines()\n",
    "        data = [eval(x) for x in data]\n",
    "        new_example = []\n",
    "        for example in data:\n",
    "            example['obj_label'] = example['obj_label'][0]\n",
    "            if example['obj_label'] not in bert_vocab: continue \n",
    "            new_example.append(example)\n",
    "        df = pd.DataFrame(new_example)\n",
    "\n",
    "        #df['obj_label'] = df['obj_label'].apply(lambda x: eval(x)[0] if isinstance(x, str) else x[0])\n",
    "    return df \n",
    "\n",
    "df = load_data(dataset_to_localpath['DIAG'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>#Hypon</th>\n",
       "      <th>#Hyper</th>\n",
       "      <th>#Pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLESS</td>\n",
       "      <td>200</td>\n",
       "      <td>85</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIAG</td>\n",
       "      <td>576</td>\n",
       "      <td>9</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLSB</td>\n",
       "      <td>508</td>\n",
       "      <td>232</td>\n",
       "      <td>1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHWARTZ</td>\n",
       "      <td>11061</td>\n",
       "      <td>1101</td>\n",
       "      <td>12724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EVAL</td>\n",
       "      <td>621</td>\n",
       "      <td>348</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LEDS</td>\n",
       "      <td>1073</td>\n",
       "      <td>364</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset #Hypon #Hyper #Pairs\n",
       "0    BLESS    200     85    935\n",
       "1     DIAG    576      9    576\n",
       "2     CLSB    508    232   1079\n",
       "3  SHWARTZ  11061   1101  12724\n",
       "4     EVAL    621    348    953\n",
       "5     LEDS   1073    364   1262"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &  Dataset & \\#Hypon & \\#Hyper & \\#Pairs \\\\\n",
      "\\midrule\n",
      "0 &    BLESS &    200 &     85 &    935 \\\\\n",
      "1 &     DIAG &    576 &      9 &    576 \\\\\n",
      "2 &     CLSB &    508 &    232 &   1079 \\\\\n",
      "3 &  SHWARTZ &  11061 &   1101 &  12724 \\\\\n",
      "4 &     EVAL &    621 &    348 &    953 \\\\\n",
      "5 &     LEDS &   1073 &    364 &   1262 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-79d77633e64d>:22: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(datasets_to_stats.to_latex())\n"
     ]
    }
   ],
   "source": [
    "query_datasets = ['BLESS', \"DIAG\", \"CLSB\", \"SHWARTZ\", \"EVAL\", \"LEDS\"]\n",
    "\n",
    "datasets_to_stats = []\n",
    "for dataset in query_datasets:\n",
    "    df = load_data(dataset_to_localpath[dataset])    \n",
    "    word_pairs = [name for name, group in df.groupby(['sub_label', 'obj_label'])]\n",
    "    hyper = set(df['obj_label'])\n",
    "    num_hypon = len(set(df['sub_label']))\n",
    "    num_hyper = len(hyper)\n",
    "    num_pairs = len(word_pairs)\n",
    "    \n",
    "    #print(f\"#Hypo {num_hypon}\")\n",
    "    #print(f\"#Hyper {len(hyper)}\")\n",
    "    #print(f\"#Hypo-Hyper pairs:\",len(word_pairs) )    \n",
    "\n",
    "    stats = pd.Series({\"Dataset\": dataset, \"#Hypon\": num_hypon, \"#Hyper\": num_hyper, \"#Pairs\": num_pairs }).T\n",
    "    datasets_to_stats.append(stats)\n",
    "    #print(\"-\"*80)\n",
    "    #print()\n",
    "datasets_to_stats=pd.concat(datasets_to_stats, axis=1).T\n",
    "display(datasets_to_stats)\n",
    "print(datasets_to_stats.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degbug SHWAERTZ (noisy data)\n",
    "\n",
    "the sub_label are noisy:\n",
    "shaadi.com\n",
    ".hack//sign\n",
    "risk/reward\n",
    "dmz//38\n",
    "s.w.a.t.\n",
    "f.l.m.\n",
    "s.r.o.\n",
    "i.o.u.s.a.\n",
    "c.r.a.z.y.\n",
    "brother/sister\n",
    "m.sc\n",
    "m.p.g.\n",
    "m.b.b.s.\n",
    "d.s.\n",
    "d.p.o.\n",
    "n.i.b.\n",
    "t.n.t.shaadi.com\n",
    ".hack//sign\n",
    "risk/reward\n",
    "dmz//38\n",
    "s.w.a.t.\n",
    "f.l.m.\n",
    "s.r.o.\n",
    "i.o.u.s.a.\n",
    "c.r.a.z.y.\n",
    "brother/sister\n",
    "m.sc\n",
    "m.p.g.\n",
    "m.b.b.s.\n",
    "d.s.\n",
    "d.p.o.\n",
    "n.i.b.\n",
    "t.n.t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/hypernymysuite/data/eval.tsv\n",
      "EVAL\n",
      "../data/hypernymysuite/data/bibless.tsv\n",
      "BIBLESS\n",
      "../data/hypernymysuite/data/bless.tsv\n",
      "BLESS\n",
      "../data/hypernymysuite/data/leds.tsv\n",
      "LEDS\n",
      "../data/hypernymysuite/data/eval.revisit_hypernym.tsv\n",
      "EVAL.REVISIT_HYPERNYM\n",
      "../data/hypernymysuite/data/shwartz.tsv\n",
      "SHWARTZ\n",
      "#Hypo 11375\n",
      "#Hyper 1312\n",
      "#Hypo-Hyper pairs: 13104\n",
      "{'sub_label': '.hack//sign', 'obj_label': ['anime'], 'masked_sentences': ['A .hack//sign is a [MASK].', 'A .hack//sign is an [MASK].']}\n",
      "{'sub_label': '.info', 'obj_label': ['magazine'], 'masked_sentences': ['A .info is a [MASK].', 'A .info is an [MASK].']}\n",
      "{'sub_label': '3oh!3', 'obj_label': ['band'], 'masked_sentences': ['A 3oh!3 is a [MASK].', 'A 3oh!3 is an [MASK].']}\n",
      "{'sub_label': '7-tease', 'obj_label': ['album'], 'masked_sentences': ['A 7-tease is a [MASK].', 'A 7-tease is an [MASK].']}\n",
      "{'sub_label': 'a*teens', 'obj_label': ['band'], 'masked_sentences': ['An a*teens is a [MASK].', 'An a*teens is an [MASK].']}\n",
      "{'sub_label': 'a.w.o.l.', 'obj_label': ['album', 'film'], 'masked_sentences': ['An a.w.o.l. is a [MASK].', 'An a.w.o.l. is an [MASK].']}\n",
      "{'sub_label': 'b-52', 'obj_label': ['cocktail'], 'masked_sentences': ['A b-52 is a [MASK].', 'A b-52 is an [MASK].']}\n",
      "{'sub_label': 'b.sc', 'obj_label': ['university'], 'masked_sentences': ['A b.sc is a [MASK].', 'A b.sc is an [MASK].']}\n",
      "{'sub_label': 'b.z.', 'obj_label': ['newspaper'], 'masked_sentences': ['A b.z. is a [MASK].', 'A b.z. is an [MASK].']}\n",
      "{'sub_label': 'bb&t', 'obj_label': ['company'], 'masked_sentences': ['A bb&t is a [MASK].', 'A bb&t is an [MASK].']}\n",
      "{'sub_label': 'biel/bienne', 'obj_label': ['city'], 'masked_sentences': ['A biel/bienne is a [MASK].', 'A biel/bienne is an [MASK].']}\n",
      "{'sub_label': \"blacksummers'night\", 'obj_label': ['album'], 'masked_sentences': [\"A blacksummers'night is a [MASK].\", \"A blacksummers'night is an [MASK].\"]}\n",
      "{'sub_label': 'blink-182', 'obj_label': ['album'], 'masked_sentences': ['A blink-182 is a [MASK].', 'A blink-182 is an [MASK].']}\n",
      "{'sub_label': 'brother/sister', 'obj_label': ['album'], 'masked_sentences': ['A brother/sister is a [MASK].', 'A brother/sister is an [MASK].']}\n",
      "{'sub_label': 'c.r.a.z.y.', 'obj_label': ['film'], 'masked_sentences': ['A c.r.a.z.y. is a [MASK].', 'A c.r.a.z.y. is an [MASK].']}\n",
      "{'sub_label': 'carrefour', 'obj_label': ['s.a.'], 'masked_sentences': ['A carrefour is a [MASK].', 'A carrefour is an [MASK].']}\n",
      "{'sub_label': 'cbc.ca', 'obj_label': ['news'], 'masked_sentences': ['A cbc.ca is a [MASK].', 'A cbc.ca is an [MASK].']}\n",
      "{'sub_label': 'cencosud', 'obj_label': ['s.a.'], 'masked_sentences': ['A cencosud is a [MASK].', 'A cencosud is an [MASK].']}\n",
      "{'sub_label': 'ch!pz', 'obj_label': ['band'], 'masked_sentences': ['A ch!pz is a [MASK].', 'A ch!pz is an [MASK].']}\n",
      "{'sub_label': \"d'eux\", 'obj_label': ['album'], 'masked_sentences': [\"A d'eux is a [MASK].\", \"A d'eux is an [MASK].\"]}\n",
      "{'sub_label': \"d'jais\", 'obj_label': ['restaurant'], 'masked_sentences': [\"A d'jais is a [MASK].\", \"A d'jais is an [MASK].\"]}\n",
      "{'sub_label': 'd-17', 'obj_label': ['film'], 'masked_sentences': ['A d-17 is a [MASK].', 'A d-17 is an [MASK].']}\n",
      "{'sub_label': 'd.a.z.', 'obj_label': ['album'], 'masked_sentences': ['A d.a.z. is a [MASK].', 'A d.a.z. is an [MASK].']}\n",
      "{'sub_label': 'd.p.o.', 'obj_label': ['episode'], 'masked_sentences': ['A d.p.o. is a [MASK].', 'A d.p.o. is an [MASK].']}\n",
      "{'sub_label': 'd.s.', 'obj_label': ['song'], 'masked_sentences': ['A d.s. is a [MASK].', 'A d.s. is an [MASK].']}\n",
      "{'sub_label': 'delhi-6', 'obj_label': ['film'], 'masked_sentences': ['A delhi-6 is a [MASK].', 'A delhi-6 is an [MASK].']}\n",
      "{'sub_label': 'dmz//38', 'obj_label': ['band'], 'masked_sentences': ['A dmz//38 is a [MASK].', 'A dmz//38 is an [MASK].']}\n",
      "{'sub_label': 'e.m.d.', 'obj_label': ['band'], 'masked_sentences': ['An e.m.d. is a [MASK].', 'An e.m.d. is an [MASK].']}\n",
      "{'sub_label': 'f.i.d.', 'obj_label': ['album'], 'masked_sentences': ['A f.i.d. is a [MASK].', 'A f.i.d. is an [MASK].']}\n",
      "{'sub_label': 'f.l.m.', 'obj_label': ['album'], 'masked_sentences': ['A f.l.m. is a [MASK].', 'A f.l.m. is an [MASK].']}\n",
      "{'sub_label': 'f.l.y.', 'obj_label': ['band'], 'masked_sentences': ['A f.l.y. is a [MASK].', 'A f.l.y. is an [MASK].']}\n",
      "{'sub_label': 'f.o.a.d.', 'obj_label': ['album'], 'masked_sentences': ['A f.o.a.d. is a [MASK].', 'A f.o.a.d. is an [MASK].']}\n",
      "{'sub_label': 'f.t.t.w.', 'obj_label': ['album'], 'masked_sentences': ['A f.t.t.w. is a [MASK].', 'A f.t.t.w. is an [MASK].']}\n",
      "{'sub_label': 'famine-33', 'obj_label': ['film'], 'masked_sentences': ['A famine-33 is a [MASK].', 'A famine-33 is an [MASK].']}\n",
      "{'sub_label': 'frost/nixon', 'obj_label': ['film'], 'masked_sentences': ['A frost/nixon is a [MASK].', 'A frost/nixon is an [MASK].']}\n",
      "{'sub_label': 'getz/gilberto', 'obj_label': ['album'], 'masked_sentences': ['A getz/gilberto is a [MASK].', 'A getz/gilberto is an [MASK].']}\n",
      "{'sub_label': 'go-round', 'obj_label': ['album'], 'masked_sentences': ['A go-round is a [MASK].', 'A go-round is an [MASK].']}\n",
      "{'sub_label': 'h-58', 'obj_label': ['road'], 'masked_sentences': ['A h-58 is a [MASK].', 'A h-58 is an [MASK].']}\n",
      "{'sub_label': 'i.d.', 'obj_label': ['album'], 'masked_sentences': ['An i.d. is a [MASK].', 'An i.d. is an [MASK].']}\n",
      "{'sub_label': 'i.e.m.', 'obj_label': ['album'], 'masked_sentences': ['An i.e.m. is a [MASK].', 'An i.e.m. is an [MASK].']}\n",
      "{'sub_label': 'i.o.u.s.a.', 'obj_label': ['film'], 'masked_sentences': ['An i.o.u.s.a. is a [MASK].', 'An i.o.u.s.a. is an [MASK].']}\n",
      "{'sub_label': 'ks-23', 'obj_label': ['shotgun'], 'masked_sentences': ['A ks-23 is a [MASK].', 'A ks-23 is an [MASK].']}\n",
      "{'sub_label': \"l'argent\", 'obj_label': ['film'], 'masked_sentences': [\"A l'argent is a [MASK].\", \"A l'argent is an [MASK].\"]}\n",
      "{'sub_label': \"l'austral\", 'obj_label': ['ship'], 'masked_sentences': [\"A l'austral is a [MASK].\", \"A l'austral is an [MASK].\"]}\n",
      "{'sub_label': \"l'immortelle\", 'obj_label': ['film'], 'masked_sentences': [\"A l'immortelle is a [MASK].\", \"A l'immortelle is an [MASK].\"]}\n",
      "{'sub_label': 'l.i.e.', 'obj_label': ['film'], 'masked_sentences': ['A l.i.e. is a [MASK].', 'A l.i.e. is an [MASK].']}\n",
      "{'sub_label': 'l.m.l.', 'obj_label': ['album'], 'masked_sentences': ['A l.m.l. is a [MASK].', 'A l.m.l. is an [MASK].']}\n",
      "{'sub_label': 'lithium-7', 'obj_label': ['isotope'], 'masked_sentences': ['A lithium-7 is a [MASK].', 'A lithium-7 is an [MASK].']}\n",
      "{'sub_label': 'm*a*s*h', 'obj_label': ['book'], 'masked_sentences': ['A m*a*s*h is a [MASK].', 'A m*a*s*h is an [MASK].']}\n",
      "{'sub_label': 'm-10', 'obj_label': ['road'], 'masked_sentences': ['A m-10 is a [MASK].', 'A m-10 is an [MASK].']}\n",
      "{'sub_label': 'm-130', 'obj_label': ['road'], 'masked_sentences': ['A m-130 is a [MASK].', 'A m-130 is an [MASK].']}\n",
      "{'sub_label': 'm-134', 'obj_label': ['road'], 'masked_sentences': ['A m-134 is a [MASK].', 'A m-134 is an [MASK].']}\n",
      "{'sub_label': 'm-150', 'obj_label': ['road'], 'masked_sentences': ['A m-150 is a [MASK].', 'A m-150 is an [MASK].']}\n",
      "{'sub_label': 'm-153', 'obj_label': ['road'], 'masked_sentences': ['A m-153 is a [MASK].', 'A m-153 is an [MASK].']}\n",
      "{'sub_label': 'm-185', 'obj_label': ['road'], 'masked_sentences': ['A m-185 is a [MASK].', 'A m-185 is an [MASK].']}\n",
      "{'sub_label': 'm-217', 'obj_label': ['road'], 'masked_sentences': ['A m-217 is a [MASK].', 'A m-217 is an [MASK].']}\n",
      "{'sub_label': 'm-25', 'obj_label': ['road'], 'masked_sentences': ['A m-25 is a [MASK].', 'A m-25 is an [MASK].']}\n",
      "{'sub_label': 'm-27', 'obj_label': ['road'], 'masked_sentences': ['A m-27 is a [MASK].', 'A m-27 is an [MASK].']}\n",
      "{'sub_label': 'm-34', 'obj_label': ['road'], 'masked_sentences': ['A m-34 is a [MASK].', 'A m-34 is an [MASK].']}\n",
      "{'sub_label': 'm-39', 'obj_label': ['road'], 'masked_sentences': ['A m-39 is a [MASK].', 'A m-39 is an [MASK].']}\n",
      "{'sub_label': 'm-47', 'obj_label': ['road'], 'masked_sentences': ['A m-47 is a [MASK].', 'A m-47 is an [MASK].']}\n",
      "{'sub_label': 'm-79', 'obj_label': ['road'], 'masked_sentences': ['A m-79 is a [MASK].', 'A m-79 is an [MASK].']}\n",
      "{'sub_label': 'm.b.b.s.', 'obj_label': ['university'], 'masked_sentences': ['A m.b.b.s. is a [MASK].', 'A m.b.b.s. is an [MASK].']}\n",
      "{'sub_label': 'm.khanapur', 'obj_label': ['village'], 'masked_sentences': ['A m.khanapur is a [MASK].', 'A m.khanapur is an [MASK].']}\n",
      "{'sub_label': 'm.l.a.', 'obj_label': ['film'], 'masked_sentences': ['A m.l.a. is a [MASK].', 'A m.l.a. is an [MASK].']}\n",
      "{'sub_label': 'm.p.g.', 'obj_label': ['album'], 'masked_sentences': ['A m.p.g. is a [MASK].', 'A m.p.g. is an [MASK].']}\n",
      "{'sub_label': 'm.phil', 'obj_label': ['university'], 'masked_sentences': ['A m.phil is a [MASK].', 'A m.phil is an [MASK].']}\n",
      "{'sub_label': 'm.s.w.', 'obj_label': ['university'], 'masked_sentences': ['A m.s.w. is a [MASK].', 'A m.s.w. is an [MASK].']}\n",
      "{'sub_label': 'm.sc', 'obj_label': ['university'], 'masked_sentences': ['A m.sc is a [MASK].', 'A m.sc is an [MASK].']}\n",
      "{'sub_label': 'm60-ucd1', 'obj_label': ['galaxy'], 'masked_sentences': ['A m60-ucd1 is a [MASK].', 'A m60-ucd1 is an [MASK].']}\n",
      "{'sub_label': 'm@rix', 'obj_label': ['album'], 'masked_sentences': ['A m@rix is a [MASK].', 'A m@rix is an [MASK].']}\n",
      "{'sub_label': 'masisa', 'obj_label': ['s.a.'], 'masked_sentences': ['A masisa is a [MASK].', 'A masisa is an [MASK].']}\n",
      "{'sub_label': 'maz-525', 'obj_label': ['truck'], 'masked_sentences': ['A maz-525 is a [MASK].', 'A maz-525 is an [MASK].']}\n",
      "{'sub_label': \"modi'in\", 'obj_label': ['place'], 'masked_sentences': [\"A modi'in is a [MASK].\", \"A modi'in is an [MASK].\"]}\n",
      "{'sub_label': 'n.i.b.', 'obj_label': ['song'], 'masked_sentences': ['A n.i.b. is a [MASK].', 'A n.i.b. is an [MASK].']}\n",
      "{'sub_label': \"o'brien\", 'obj_label': ['city'], 'masked_sentences': [\"An o'brien is a [MASK].\", \"An o'brien is an [MASK].\"]}\n",
      "{'sub_label': \"o'hara\", 'obj_label': ['writer'], 'masked_sentences': [\"An o'hara is a [MASK].\", \"An o'hara is an [MASK].\"]}\n",
      "{'sub_label': 'o.h.m.s.', 'obj_label': ['film'], 'masked_sentences': ['An o.h.m.s. is a [MASK].', 'An o.h.m.s. is an [MASK].']}\n",
      "{'sub_label': 'o.s.t.', 'obj_label': ['album'], 'masked_sentences': ['An o.s.t. is a [MASK].', 'An o.s.t. is an [MASK].']}\n",
      "{'sub_label': 'p.s.', 'obj_label': ['film'], 'masked_sentences': ['A p.s. is a [MASK].', 'A p.s. is an [MASK].']}\n",
      "{'sub_label': 'pescanova', 'obj_label': ['s.a.'], 'masked_sentences': ['A pescanova is a [MASK].', 'A pescanova is an [MASK].']}\n",
      "{'sub_label': 'r.s.v.p.', 'obj_label': ['album'], 'masked_sentences': ['A r.s.v.p. is a [MASK].', 'A r.s.v.p. is an [MASK].']}\n",
      "{'sub_label': 'renault', 'obj_label': ['s.a.'], 'masked_sentences': ['A renault is a [MASK].', 'A renault is an [MASK].']}\n",
      "{'sub_label': 'respect.', 'obj_label': ['magazine'], 'masked_sentences': ['A respect. is a [MASK].', 'A respect. is an [MASK].']}\n",
      "{'sub_label': 'rgd-5', 'obj_label': ['grenade'], 'masked_sentences': ['A rgd-5 is a [MASK].', 'A rgd-5 is an [MASK].']}\n",
      "{'sub_label': 'risk/reward', 'obj_label': ['film'], 'masked_sentences': ['A risk/reward is a [MASK].', 'A risk/reward is an [MASK].']}\n",
      "{'sub_label': 'rm-38', 'obj_label': ['mortar'], 'masked_sentences': ['A rm-38 is a [MASK].', 'A rm-38 is an [MASK].']}\n",
      "{'sub_label': 's-25', 'obj_label': ['rocket'], 'masked_sentences': ['A s-25 is a [MASK].', 'A s-25 is an [MASK].']}\n",
      "{'sub_label': 's-94', 'obj_label': ['film'], 'masked_sentences': ['A s-94 is a [MASK].', 'A s-94 is an [MASK].']}\n",
      "{'sub_label': 's.e.s.', 'obj_label': ['album'], 'masked_sentences': ['A s.e.s. is a [MASK].', 'A s.e.s. is an [MASK].']}\n",
      "{'sub_label': 's.i.o.s.o.s.', 'obj_label': ['album'], 'masked_sentences': ['A s.i.o.s.o.s. is a [MASK].', 'A s.i.o.s.o.s. is an [MASK].']}\n",
      "{'sub_label': 's.r.o.', 'obj_label': ['album'], 'masked_sentences': ['A s.r.o. is a [MASK].', 'A s.r.o. is an [MASK].']}\n",
      "{'sub_label': 's.w.a.t.', 'obj_label': ['film'], 'masked_sentences': ['A s.w.a.t. is a [MASK].', 'A s.w.a.t. is an [MASK].']}\n",
      "{'sub_label': \"sant'antonino\", 'obj_label': ['municipality'], 'masked_sentences': [\"A sant'antonino is a [MASK].\", \"A sant'antonino is an [MASK].\"]}\n",
      "{'sub_label': \"sant'eustachio\", 'obj_label': ['church'], 'masked_sentences': [\"A sant'eustachio is a [MASK].\", \"A sant'eustachio is an [MASK].\"]}\n",
      "{'sub_label': 'shaadi.com', 'obj_label': ['website'], 'masked_sentences': ['A shaadi.com is a [MASK].', 'A shaadi.com is an [MASK].']}\n",
      "{'sub_label': 'shake/shiver/moan', 'obj_label': ['album'], 'masked_sentences': ['A shake/shiver/moan is a [MASK].', 'A shake/shiver/moan is an [MASK].']}\n",
      "{'sub_label': \"sirk'i\", 'obj_label': ['mountain'], 'masked_sentences': [\"A sirk'i is a [MASK].\", \"A sirk'i is an [MASK].\"]}\n",
      "{'sub_label': 'strategy+business', 'obj_label': ['magazine'], 'masked_sentences': ['A strategy+business is a [MASK].', 'A strategy+business is an [MASK].']}\n",
      "{'sub_label': 't.i.p.', 'obj_label': ['album'], 'masked_sentences': ['A t.i.p. is a [MASK].', 'A t.i.p. is an [MASK].']}\n",
      "{'sub_label': 't.n.t.', 'obj_label': ['album'], 'masked_sentences': ['A t.n.t. is a [MASK].', 'A t.n.t. is an [MASK].']}\n",
      "{'sub_label': 't.o.p', 'obj_label': ['album'], 'masked_sentences': ['A t.o.p is a [MASK].', 'A t.o.p is an [MASK].']}\n",
      "{'sub_label': 't.o.p.', 'obj_label': ['album'], 'masked_sentences': ['A t.o.p. is a [MASK].', 'A t.o.p. is an [MASK].']}\n",
      "{'sub_label': 'u.f.orb', 'obj_label': ['album'], 'masked_sentences': ['An u.f.orb is a [MASK].', 'An u.f.orb is an [MASK].']}\n",
      "{'sub_label': 'vol.2', 'obj_label': ['album'], 'masked_sentences': ['A vol.2 is a [MASK].', 'A vol.2 is an [MASK].']}\n",
      "{'sub_label': 'w.a.r.', 'obj_label': ['album'], 'masked_sentences': ['A w.a.r. is a [MASK].', 'A w.a.r. is an [MASK].']}\n",
      "{'sub_label': 'w.a.s.p.', 'obj_label': ['album'], 'masked_sentences': ['A w.a.s.p. is a [MASK].', 'A w.a.s.p. is an [MASK].']}\n",
      "save ../data/hypernymysuite/data/hypernymsuite/SHWARTZ/IsA.jsonl with 11268 lines\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json \n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from inflection import pluralize\n",
    "from util_wordnet import get_sister_terms\n",
    "import string\n",
    "\n",
    "def add_plural(word):\n",
    "    word_plural = pluralize(word)\n",
    "    return [word, word_plural] if word_plural!=word else [word]\n",
    "\n",
    "def merge_multiple_labels(df, relations, output_path):\n",
    "    df= df.query(f\"relation in {relations}\")\n",
    "    examples = []\n",
    "    for name, group in df.groupby(by='sub_label'):\n",
    "        example = defaultdict()\n",
    "        example['sub_label'] = name\n",
    "        example['obj_label'] = [obj[0] for obj in group['obj_label'].values] #.tolist()\n",
    "        example['masked_sentences'] = [f\"{_get_article(name)} {name} is a [MASK].\", f\"{_get_article(name)} {name} is an [MASK].\"]\n",
    "        examples.append(example)\n",
    "    examples = pd.DataFrame(examples)\n",
    "    \n",
    "    return examples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_dir = '../data/hypernymysuite/data'\n",
    "add_plural_ground_truth = False #True \n",
    "multi_label = True \n",
    "p = Path(data_dir)\n",
    "paths = list(p.glob(f'*.tsv'))\n",
    "for path in paths:\n",
    "    if 'hyperlex_rnd' in path.stem or 'wbless' in path.stem: continue \n",
    "    print(path)\n",
    "    dataset_name = path.stem.upper()\n",
    "    print(dataset_name)\n",
    "    if dataset_name !='SHWARTZ': continue \n",
    "    out_dir = f\"{path.parents[0]}/hypernymsuite/{dataset_name}/\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir + \"IsA.jsonl\"\n",
    "\n",
    "    df = pd.read_csv(path, sep='\\t').query(\"label==True\")\n",
    "    if 'relation' in df.columns:\n",
    "        df = df.query(\"relation=='hyper'\")\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df['masked_sentences'] = df[['word1', 'word2']].apply(lambda x: [_get_article(x[0]) + f\" {x[0]} is a [MASK].\", _get_article(x[0]) + f\" {x[0]} is an [MASK].\"], axis=1)\n",
    "    \n",
    "    word_pairs = [name for name, group in df.groupby(['word1', 'word2'])]\n",
    "    hyper = set(df['word2'])\n",
    "    \n",
    "    df = df.rename(columns={'word1': 'sub_label', 'word2': 'obj_label'})\n",
    "    print(f\"#Hypo {len(set(df['sub_label']))}\")\n",
    "    print(f\"#Hyper {len(hyper)}\")\n",
    "    print(f\"#Hypo-Hyper pairs:\",len(word_pairs) )\n",
    "    \n",
    "    df['uuid'] = df.index \n",
    "    df['relation'] = 'IsA'\n",
    "#     df['sub_sister'] = df['sub_label'].apply(lambda x: get_sister_terms(x, distance_to_hypernym=1))\n",
    "    \n",
    "    if add_plural_ground_truth: \n",
    "        df['obj_label'] = df['obj_label'].apply(lambda x: add_plural(x)) \n",
    "    else: \n",
    "        df['obj_label'] = df['obj_label'].apply(lambda x: [x]) \n",
    "    \n",
    "    if not multi_label: \n",
    "        df = df[['sub_label', 'obj_label', 'relation', 'masked_sentences', 'uuid']]\n",
    "        display(df.head())\n",
    "        examples = df.to_dict(orient='records')\n",
    "    else: \n",
    "        examples = merge_multiple_labels(df, ['IsA'],output_path=out_path ).to_dict(orient=\"records\")\n",
    "#         save_dict_to_json(examples.to_dict(orient=\"records\") , output_path =output_path )\n",
    "    examples = remove_noisy_examples(examples)\n",
    "    save_dict_to_json(examples=examples, output_path=out_path)\n",
    "    print(\"-\"*80)\n",
    "    print()\n",
    "\n",
    "\n",
    "# a_string = '!hi. wh?at is the weat[h]er lik?e.'\n",
    "# new_string = a_string.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# df.query(\"{}\")\n",
    "df_new = pd.DataFrame(examples)\n",
    "# df = ['sub_label'] \n",
    "sub_labels = set(df_new['sub_label'])\n",
    "for x in sub_labels:\n",
    "    if '/' in x or '.' in x: \n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi what is the weather like'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "l = re.findall(r\"[\\w']+|[.,!?;]\", \".hack//signs\")\n",
    "\n",
    "filepath = '../data/hypernymysuite/data/hypernymsuite/SHWARTZ/IsA.jsonl'\n",
    "with open(filepath, 'r', encoding='utf-8') as fin:\n",
    "    data = fin.readlines()\n",
    "    data = [eval(x) for x in data]\n",
    "    df = pd.DataFrame(data)\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
