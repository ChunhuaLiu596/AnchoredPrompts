{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do anchors help each SAP pattern? \n",
    "- the best single defp: A(n) X is a type of Y.\n",
    "- the best single lsp: Y such as X and Z. \n",
    "\n",
    "insert anchors into the two patterns and compare their performance with (without) anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json \n",
    "import copy\n",
    "import re \n",
    "import math\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from copy import deepcopy\n",
    "import pathlib\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import string\n",
    "from inflection import pluralize, singularize\n",
    "from util_wordnet import get_sister_terms\n",
    "from transformers import pipeline\n",
    "\n",
    "import spacy\n",
    "en = spacy.load('en_core_web_sm')\n",
    "STOP_WORDS = en.Defaults.stop_words\n",
    "\n",
    "from IPython.display import display\n",
    "from df_to_latex import DataFrame2Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_article(word):\n",
    "    if word[0] in ['a', 'e', 'i', 'o', 'u']:\n",
    "        return 'an'\n",
    "    return 'a'\n",
    "\n",
    "def save_dict_to_json(examples, output_path):\n",
    "    ''' \n",
    "    save a list of dicts into otuput_path, orient='records' (each line is a dict) \n",
    "    examples: a list of dicts\n",
    "    output_path: \n",
    "    '''\n",
    "\n",
    "    with open(output_path, 'w') as fout:\n",
    "        for example in examples:\n",
    "            json.dump(example, fout)\n",
    "            fout.write(\"\\n\")\n",
    "        print(f\"save {output_path} with {len(examples)} lines\")\n",
    "\n",
    "def add_period_at_the_end_of_sentence(sentence):\n",
    "    last_token = sentence[-1]\n",
    "    if last_token != '.': \n",
    "        return sentence + '.'\n",
    "    return [sentence]\n",
    "\n",
    "def get_unmasker(model, device, targets=None):\n",
    "    if targets is None: \n",
    "        unmasker = pipeline('fill-mask', model=model)# 'bert-large-uncased') #initialize the masker\n",
    "    else:\n",
    "        unmasker = pipeline('fill-mask', model=model, targets=targets )# 'bert-large-uncased') #initialize the masker\n",
    "    return unmasker\n",
    "\n",
    "\n",
    "\n",
    "def remove_noisy_test_data(df):\n",
    "  ''' \n",
    "  relation=\"hasproperty\"\n",
    "  why? some data points don't belong to this relation types \n",
    "  case1., sub_label=number, such as \"10 is ten.\"  We don't say ten is the property of 10\n",
    "  case2, sub_label = 'person_name' and obj_label = 'nuts;, such as \"\"Andrew is [MASK].\", [MASK]=nuts\n",
    "  '''\n",
    "  sub_labels_to_exclude = ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '30', '5', '50', '60', '7', '70', '70s', '80', '9', '90']\n",
    "  obj_labels_to_exclude  = ['nuts']\n",
    "  df = df.query(f\"sub_label not in {sub_labels_to_exclude}\")\n",
    "  df = df.query(f\"sub_label not in {obj_labels_to_exclude}\")\n",
    "  return  df.reset_index(drop=True)\n",
    "\n",
    "def locate_sub_obj_position(ent, sentence, index_not_in) :\n",
    "  ''' \n",
    "  function: find the index of ent in a sentence, the result will be used to filter instances whose ent cannot be find at their sentences\n",
    "  args: \n",
    "    sentence: the sentnces to mask, could be the string or a list of tokens \n",
    "    ent: the ent to be found (sub_label) \n",
    "    index_not_in: the default index for failed instances (an ent not in a sentence)\n",
    "  ''' \n",
    "\n",
    "  if isinstance(sentence, list):\n",
    "    if ent not in sentence:\n",
    "      return index_not_in\n",
    "    return sentence.index(ent)  \n",
    "  else:\n",
    "    sentence = copy.deepcopy(sentence).lower()\n",
    "    if isinstance(sentence, str):\n",
    "      try:\n",
    "        index = sentence.index(ent)\n",
    "        return  index \n",
    "      except: \n",
    "        print(f\"NOT FOUND sub_label: {ent} -> in sentence: {sentence}\")\n",
    "        return index_not_in\n",
    "      \n",
    "        print(ent, sentence)\n",
    "        return index_not_in\n",
    "\n",
    "def load_data(filepath, clean_test=True, tokenize=False):\n",
    "  '''\n",
    "  return the cleaned data\n",
    "  args:\n",
    "    tokenize: if True: the maksed_sentences will be tokenzied (this is slwoers); \n",
    "            otherwise, we use the string match to filter the failed sentences\n",
    "    clean_test: default is True. We filter out some noisy samples spoted by huamns \n",
    "               Note that this is relation specific \n",
    "\n",
    "  '''\n",
    "  index_not_in = 10000\n",
    "\n",
    "  with open(filepath, 'r', encoding='utf-8') as fin:\n",
    "    data = fin.readlines()\n",
    "    data = [eval(x) for x in data]\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df['obj_label'] = df['obj_label'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "\n",
    "  if tokenize:\n",
    "    df['masked_sentence_tokens'] = df['masked_sentences'].apply(lambda x: tokenize_sentence(x[0]))\n",
    "    df['sub_position'] = df[['sub_label', 'masked_sentence_tokens']].apply(lambda x: locate_sub_obj_position(x[0], x[1], index_not_in=index_not_in), axis=1)\n",
    "\n",
    "  if clean_test: \n",
    "    df = remove_noisy_test_data(df)\n",
    "    df['sub_position'] = df[['sub_label', 'masked_sentences']].apply(lambda x: locate_sub_obj_position(x[0], x[1][0], index_not_in), axis=1)\n",
    "    df = df.query(f\"sub_position !={index_not_in}\") #.reset_index() #cue can not be matched in the sentence\n",
    "\n",
    "  print(f\"#Test_instances: {len(df.index)}\")\n",
    "  return df.reset_index(drop=True)\n",
    "\n",
    "def get_unmasker(model, targets=None):\n",
    "    if targets is None: \n",
    "        unmasker = pipeline('fill-mask', model=model)# 'bert-large-uncased') #initialize the masker\n",
    "    else:\n",
    "        unmasker = pipeline('fill-mask', model=model, targets=targets )# 'bert-large-uncased') #initialize the masker\n",
    "    return unmasker\n",
    "\n",
    "\n",
    "def get_highest_mrr_among_labels(label, pred):\n",
    "    '''\n",
    "    return the highest rank among the multiple labels. This is applicable to single labels as well, if we the single label is put in a list\n",
    "\n",
    "    pred: a list of words (candidates)\n",
    "    label: the true labels, which is a list (different forms of a word, e.g., singular or plurs, like animal and animals)\n",
    "    '''\n",
    "    mrr = 0 \n",
    "    if pred is None: return mrr \n",
    "\n",
    "    rank_list = [ pred.index(item) + 1 for item in label if item in pred] \n",
    "    if len(rank_list)>0:\n",
    "        mrr = 1/min(rank_list)\n",
    "    return mrr \n",
    "\n",
    "\n",
    "def get_predictions(input_words, outputs, filter_objects_flag=True, filter_objects_with_input=True):\n",
    "    '''\n",
    "    excluding x from outputs\n",
    "    '''\n",
    "    filled_tokens = list()\n",
    "    filled_scores = defaultdict()\n",
    "    for i, output in enumerate(outputs):\n",
    "#         print(output)\n",
    "        filled_token = output['token_str'].strip().lower()\n",
    "        filled_score = output['score']\n",
    "        if filter_objects_flag:\n",
    "            \n",
    "            #####Add conditions to filter unwanted ################\n",
    "            # filter the repetation of a concept in the explanation. See the the following example\n",
    "            # [MASK] is the capability to do a particular job . -> capacity \n",
    "            if not filled_token.isalpha(): continue\n",
    "            if filled_token in STOP_WORDS: continue \n",
    "            if len(filled_token)<=1: continue \n",
    "            if filter_objects_with_input:\n",
    "                if filled_token in [input_words]: continue\n",
    "                # [re.sub(\"\\s+\", '', x) for x in input_word.split()]: continue #filter out the target in input  \n",
    "            if filled_token.startswith(\"#\"): continue\n",
    "            #####Add conditions to filter unwanted ################\n",
    "\n",
    "            filled_tokens.append(filled_token)\n",
    "            filled_scores[filled_token] = filled_score\n",
    "        else:\n",
    "            filled_tokens.append(filled_token)\n",
    "            filled_scores[filled_token] = filled_score\n",
    "    \n",
    "    return pd.Series((filled_tokens, filled_scores))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset_to_jsonl_path={\n",
    "    \"EVAL\": \"../data/hypernymysuite/data/hypernymsuite/EVAL/IsA.jsonl\",\n",
    "    \"BLESS\": \"../data/hypernymysuite/data/hypernymsuite/BLESS/IsA.jsonl\",\n",
    "    \"LEDS\": \"../data/hypernymysuite/data/hypernymsuite/LEDS/IsA.jsonl\",\n",
    "    \"LMDIAG\": \"../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/singular/IsA.jsonl\",\n",
    "    \"CLSB\": \"../data/CLSB/single_label/IsA.jsonl\",\n",
    "    \"SHWARTZ\": \"../data/hypernymysuite/data/hypernymsuite/SHWARTZ/IsA.jsonl\",\n",
    "    }\n",
    "\n",
    "def layout_table(df, dataset_list =['BLESS','LMDIAG', 'CLSB', 'SHWARTZ', 'EVAL', 'LEDS']):\n",
    "    '''\n",
    "    format the output with desired dataset layout and metrics \n",
    "    '''\n",
    "    df_groups = []\n",
    "    for dataset in dataset_list: \n",
    "       \n",
    "        df_group = df.query(f\"dataset == '{dataset}'\")\n",
    "        df_group = df_group.pivot(index=\"pattern_id\", columns=['dataset'], values=['MRR', 'P@K'])\n",
    "        df_group = df_group.swaplevel(0, 1, axis=1)\n",
    "        df_groups.append(df_group)\n",
    "\n",
    "    df_groups = pd.concat(df_groups, axis=1)\n",
    "    return df_groups\n",
    "\n",
    "def merge_predictions_in_concept_level(uniform_funcion, words, top_k=None ):\n",
    "    '''\n",
    "    uniform_function: either signualarize or pluralize \n",
    "    '''\n",
    "    words_uniformed = [uniform_funcion(word) for word in words]\n",
    "    concepts = list(OrderedDict.fromkeys(words_uniformed))\n",
    "    return concepts[:top_k] if top_k is not None else concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inflection import singularize, pluralize\n",
    "\n",
    "def read_anchors(data_path, anchor_source, debug=False):\n",
    "    '''\n",
    "    read the anchor files mined from singualr and plural\n",
    "    \n",
    "    args: \n",
    "        anchor_soure: using the anchors mined from singular probe or plural probe\n",
    "        \n",
    "    return: \n",
    "        dic_sub_to_anchors_singular: both sub_label and subj_anchors are singular \n",
    "        dic_sub_to_anchors_plural: both sub_label and subj_anchors are plural \n",
    "    '''\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    if debug: df = df.head(5)\n",
    "    df['subj_anchors_sg'] = df['subj_anchors_sg'].apply(lambda x: eval(x))\n",
    "    df['subj_anchors_pl'] = df['subj_anchors_pl'].apply(lambda x: eval(x))\n",
    "        \n",
    "    dic_sub_to_anchors_singular = dict(zip(df['sub_label_sg'], df['subj_anchors_sg']))\n",
    "    dic_sub_to_anchors_plural = dict(zip(df['sub_label_pl'], df['subj_anchors_pl']))\n",
    "    \n",
    "    return dic_sub_to_anchors_singular, dic_sub_to_anchors_plural\n",
    "\n",
    "\n",
    "\n",
    "def insert_anchors(dic_sub_to_anchors, df, mask_col, sub_col, anchor_col, probe_type, article_for_z=False, anchor_num=5):\n",
    "    \n",
    "    df[anchor_col] = df[sub_col].apply(lambda x: dic_sub_to_anchors.get(x) )\n",
    "#     display(df[mask_col].head())\n",
    "    \n",
    "    if probe_type =='plural':\n",
    "        df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', anchor)  for anchor in x[0][:anchor_num]], axis=1)\n",
    "    elif probe_type == 'singular':\n",
    "        if article_for_z: \n",
    "           df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', \"{} {}\".format(_get_article(anchor), anchor))  for anchor in x[0][:anchor_num]], axis=1) \n",
    "        else:\n",
    "            df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', anchor)  for anchor in x[0][:anchor_num]], axis=1) \n",
    "    return df \n",
    "\n",
    "\n",
    "def save_hypernym_vocab(df, vocab_path, y_singular=True, y_plural=True):\n",
    "    vocab_sg = set(x[0] for x in df['obj_label_singular'])\n",
    "    vocab_pl = set(x[0] for x in df_def_sap['obj_label_plural'])\n",
    "    \n",
    "    if y_singular and y_plural: \n",
    "        vocab = vocab_sg.union(vocab_pl)\n",
    "        df_vocab = pd.DataFrame(data=list(vocab))\n",
    "        with open(vocab_path, 'w') as fout:\n",
    "            df_vocab.to_csv(vocab_path, header=None, index=None, sep=' ', mode='a')\n",
    "    print(f\"save {vocab_path}\")\n",
    "    \n",
    "def aggregate_token_scores(input_word, token2probs, scorer, top_k, sort_flag=True ):\n",
    "    ''' \n",
    "    goal: we want the best scorer to consider:\n",
    "        (1) frequency: a token that are elicited by multiple promptso\n",
    "        (2) the probability: higher overall probability \n",
    "        (3)\n",
    "\n",
    "    token2prob: dictionary mapping a token to a list of probs \n",
    "    anchor_anchor_scorer_list = ['freqProbSum', 'probMultiply', 'probMultiplyAvg', 'freqProbMultiply', 'freq', 'probSum', 'probAvg'] #TODO: rank based\n",
    "\n",
    "\n",
    "    test case:\n",
    "    token2probs = {'achieve': [0.2, 0.1, 0.03, 0.006], 'tried': [0.008, 0.006, 0.003, 0.001], 'perform':[0.08], 'prevent': [0.06], 'use': [0.02], 'accomplished': [0.1], 'produce':[0.06]}\n",
    "    for scorer in  [ 'freqProbSum', 'probMultiply', 'probMultiplyAvg', 'freqProbMultiply' ]: #'freq', 'probSum', 'probAvg',\n",
    "        token2prob = aggregate_token_scores(token2probs, scorer, top_k=7, sort_flag=True)\n",
    "        print(scorer)\n",
    "        print(f\"\\t{token2prob}\" )\n",
    "        print()\n",
    "\n",
    "    '''\n",
    "    token2prob = defaultdict()\n",
    "    all_count = sum([len(item) for item in token2probs.values()])\n",
    "    for token, probs in token2probs.items(): #rank_score = w * p, w is the frequency weight, p is the probability\n",
    "            count = len(probs)\n",
    "            \n",
    "            freq_weight = count/all_count\n",
    "            \n",
    "            new_score = 0 \n",
    "            \n",
    "            if scorer=='freq':\n",
    "                new_score =  freq_weight \n",
    "\n",
    "            elif scorer=='probSum':\n",
    "                new_score = sum(probs)\n",
    "\n",
    "            elif scorer=='probAvg': #this ignore the frequency factor [not ideal]\n",
    "                new_score = sum(probs)/ len(probs)\n",
    "\n",
    "            elif scorer=='freqProbSum': #[close to ideal]\n",
    "                new_score = freq_weight * sum(probs)\n",
    "                # print(token, freq_weight,sum(probs), new_score )\n",
    "            elif scorer=='probLogSum':\n",
    "                probs_valid = [item for item in probs if item>0]\n",
    "                if len(probs_valid )==0:\n",
    "                    new_score= 0\n",
    "                else:\n",
    "                    new_score =  sum([math.log(item, 2) for item in probs_valid ])/len(probs_valid)\n",
    "                    # new_score =  sum([math.log(item, 2) for item in probs if item>0])/len(probs)\n",
    "\n",
    "            elif scorer=='freqProbLogSum': #[close to ideal, requires a token to be (1) frequent (2) high probs across prompts]\n",
    "                probs_valid = [item for item in probs if item>0]\n",
    "                if len(probs_valid )==0:\n",
    "                    new_score= 0\n",
    "                else:\n",
    "                    new_score =   sum([math.log(item*freq_weight, 2) for item in probs_valid ])/len(probs_valid)\n",
    "\n",
    "            token2prob[token] = new_score\n",
    "    return token2prob\n",
    "\n",
    "\n",
    "def filter_outputs_with_probs(inputs, outputs, filter_objects_flag=True, return_probs=True, top_k=None, scorer='freqProbSum', filter_objects_with_input=True, add_wordnet_path_score=False, add_cpt_score=False, cpt_unmasker=None, mask_string=None, cpt_only=False):\n",
    "    '''\n",
    "    inputs: the original inputs, for example [A] is a type of [B], A is the input\n",
    "    outputs: the candidates returned by PTLMs\n",
    "\n",
    "    filter: True \n",
    "        filter: non-alpha tokens); \n",
    "\n",
    "    top_k: take the top_k outputs. This is important when using multiple prompts for each sub \n",
    "    add_wordnet_path_score: add wordnet path score into the output scoring function \n",
    "    add_cpt_score: add concept-positioning test score into the output scoring function \n",
    "\n",
    "    '''\n",
    "    anchor_list = []\n",
    "    anchor_scores = [] \n",
    "        \n",
    "    for input_words, top_outputs in zip(inputs, outputs):  #iterate through the samples (sub)\n",
    "        input_words = [re.sub(\"\\s+\", '', x) for x in input_words.split()]\n",
    "        input_word  = input_words[0]\n",
    "        filled_tokens  = defaultdict(int) #filter/accumulate predictions for each sample \n",
    "        filled_scores = defaultdict(list) #a list of token:[score1, score2, ...]   \n",
    "        token2cpt  = defaultdict(list) #filter/accumulate predictions for each sample \n",
    "\n",
    "        if isinstance(top_outputs[0], list):\n",
    "            flatten_output = [item for top_k_output  in top_outputs for item in top_k_output]\n",
    "        else:\n",
    "            flatten_output = [item for item  in top_outputs]\n",
    "\n",
    "        for i, output in enumerate(flatten_output):\n",
    "            filled_token = output['token_str'].strip().lower()\n",
    "            filled_score = output['score']\n",
    "            if filter_objects_flag:\n",
    "                #####Add conditions to filter unwanted ################\n",
    "                # filter the repetation of a concept in the explanation. See the the following example\n",
    "                # [MASK] is the capability to do a particular job . -> capacity \n",
    "                if not filled_token.isalpha(): continue\n",
    "                if filled_token in STOP_WORDS: continue \n",
    "                if len(filled_token)<=1: continue \n",
    "                if filter_objects_with_input:\n",
    "                    if filled_token in input_words: continue\n",
    "                if filled_token.startswith(\"#\"): continue\n",
    "                #####Add conditions to filter unwanted ################\n",
    "                \n",
    "                filled_tokens[filled_token] +=1\n",
    "                filled_scores[filled_token].append(filled_score)\n",
    "            else:\n",
    "                filled_tokens[filled_token] +=1\n",
    "                filled_scores[filled_token] += filled_score\n",
    "\n",
    "        if len(filled_tokens) ==0: \n",
    "            filled_tokens={'MISSING':1}\n",
    "            filled_scores['MISSING'] = [0]\n",
    "\n",
    "        # feed the input into the agrregate _token_scores() so that we can calcuate the \n",
    "        token2probs = aggregate_token_scores(input_word, token2probs=filled_scores, scorer=scorer, top_k=top_k, sort_flag=True)\n",
    "            \n",
    "        if top_k is not None and isinstance(top_k, int):\n",
    "            token2probs = sorted(token2probs.items(), key=lambda x: x[1], reverse=True )\n",
    "            token2probs = token2probs[:top_k] \n",
    "            token2probs = dict(token2probs)\n",
    "        anchor_list.append(list(token2probs.keys())) \n",
    "        anchor_scores.append(token2probs) \n",
    "\n",
    "        # print(\"-\"*60)\n",
    "    return anchor_list if not return_probs  else pd.Series((anchor_list,anchor_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data HELPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_path import dataset_to_respath\n",
    "\n",
    "def get_dataset_to_respath(dataset_to_respath, print_flag=False):\n",
    "    # remote path \n",
    "#     dataset_to_respath = {'hypernymsuite-BLESS': 'log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', \n",
    "#                           'lm_diagnostic_extended-singular': 'log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv',\n",
    "#                           'clsb-singular': 'log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv', \n",
    "#                           'hypernymsuite-LEDS': 'log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', \n",
    "#                           'hypernymsuite-EVAL': 'log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', \n",
    "#                           'hypernymsuite-SHWARTZ': 'log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv'}\n",
    "\n",
    "    source_dir = 'spartan:~/cogsci/DAP/'\n",
    "    target_dir = '../../'\n",
    "    dataset_to_localpath = defaultdict()\n",
    "    dataset_rename = {\n",
    "        'hypernymsuite-BLESS': 'BLESS', 'lm_diagnostic_extended-singular': 'DIAG', 'clsb-singular':'CLSB', 'hypernymsuite-LEDS': 'LEDS', 'hypernymsuite-EVAL': 'EVAL', 'hypernymsuite-SHWARTZ': \n",
    "        \"SHWARTZ\"\n",
    "    }\n",
    "    dataset_name_to_relpath = defaultdict()\n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        path = path.replace(\".tsv\", \".csv\")\n",
    "        source_path = source_dir + path \n",
    "        dataset_l1 = dataset.split(\"-\")[0]\n",
    "        dataset_l2 = dataset.split(\"-\")[1] \n",
    "        target_path = target_dir + path\n",
    "        \n",
    "        scp_string = f\"!scp {source_path} {target_path}\"\n",
    "        if print_flag:\n",
    "            print(scp_string)\n",
    "            print()\n",
    "#         print(target_path)\n",
    "        dataset_to_localpath[dataset_rename[dataset]] = target_path \n",
    "        dataset_name_to_relpath[dataset_rename[dataset]] = \"/\".join(dataset.split('-'))\n",
    "#     print(dataset_to_localpath)\n",
    "    return dataset_to_localpath, dataset_name_to_relpath\n",
    "\n",
    "\n",
    "def read_data(filepath):\n",
    "    '''\n",
    "    the dataformat is the *.jsonl file we used to probe LMs\n",
    "    '''\n",
    "    if '.jsonl' in filepath:\n",
    "        df = load_json_to_df(filepath)\n",
    "        df['sub_label_sg'] = df['sub_label'].apply(lambda x: singularize(x))\n",
    "        df['sub_label_pl'] = df['sub_label'].apply(lambda x: pluralize(x))\n",
    "    elif \".csv\" in filepath:\n",
    "        df = pd.read_csv(filepath)\n",
    "        for col in ['obj_label']:\n",
    "            df[col] = df[col].apply(lambda x: eval(x))\n",
    "    \n",
    "    #df['obj_label'] = df['obj_label'].apply(lambda x: x[0])\n",
    "\n",
    "    df['relation'] = 'IsA'\n",
    "    df['uuid'] = df.index + 1\n",
    "    df['obj_label_sg'] =  df['obj_label'].apply(lambda x: [singularize(x[0])])\n",
    "    df['obj_label_pl'] =  df['obj_label'].apply(lambda x: [pluralize(x[0])])\n",
    "\n",
    "\n",
    "#     df = df[['sub_label_sg', 'obj_label_sg', \n",
    "#              'sub_label_pl', 'obj_label_pl', \n",
    "#              'uuid', 'relation', 'obj_label']]\n",
    "    return df \n",
    "\n",
    "# dataset_to_localpath, dataset_name_to_relpath = get_dataset_to_respath()\n",
    "# # print(dataset_to_localpath)\n",
    "# df_test = read_data(dataset_to_localpath['BLESS'])\n",
    "# # df_test.head()\n",
    "# dataset_to_localpath['BLESS']\n",
    "# dic_sub_to_anchors_singular,dic_sub_to_anchors_plural = read_anchors(data_path=dataset_to_localpath['BLESS'], anchor_source='plural', debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitional Patterns (DAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  1%|          | 10/879 [00:00<00:50, 17.08it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 879/879 [00:52<00:00, 16.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'BLESS', 'pattern_id': 1, 'P@K': 40.6, 'MRR': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/879 [00:00<?, ?it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 879/879 [00:51<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'BLESS', 'pattern_id': 2, 'P@K': 48.4, 'MRR': 26.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/879 [00:00<?, ?it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 879/879 [00:51<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'BLESS', 'pattern_id': 3, 'P@K': 46.2, 'MRR': 24.4}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"2\" halign=\"left\">BLESS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>P@K</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pattern_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>40.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.6</td>\n",
       "      <td>48.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.4</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset    BLESS      \n",
       "             MRR   P@K\n",
       "pattern_id            \n",
       "1           22.0  40.6\n",
       "2           26.6  48.4\n",
       "3           24.4  46.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "14\n",
      "\\begin{table*}[!h]\n",
      "\\centering\n",
      "\\begin{adjustbox}{width=\\textwidth}\n",
      "\\label{tab:def_single_pattern_ablation}\n",
      "\\begin{tabular}{l|ll|ll|ll|ll|ll|ll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{2}{c|}{BLESS} \\\\\n",
      " & MRR & P@K \\\\\n",
      "pattern_id &  &  \\\\\n",
      "\\midrule\n",
      "1 & 22.0 & 40.6 \\\\\n",
      "2 & \\textbf{26.6} & \\textbf{48.4} \\\\\n",
      "3 & 24.4 & 46.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      " \\end{adjustbox}\n",
      "\\caption{Experimental results on definitional single patterns.}\n",
      "\\end{table*}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<df_to_latex.DataFrame2Latex at 0x2b311443dd00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_anchors_from_swow(json_path_sg, json_path_pl):\n",
    "    dic_sub_to_anchors_singular = json.load(open(json_path_sg))\n",
    "    dic_sub_to_anchors_plural = json.load(open(json_path_pl))    \n",
    "    return dic_sub_to_anchors_singular,  dic_sub_to_anchors_plural\n",
    "\n",
    "def_sap_id_to_patterns = {\n",
    "         \"1\": \"[X] or [Z] is a [Y].\", \n",
    "         \"2\": \"[X] or [Z] is a type of [Y].\", \n",
    "         \"3\": \"[X] or [Z] is a kind [Y].\", \n",
    "        }\n",
    "# def_sap_id_to_patterns = {\n",
    "#          \"1\": \"[X] is a [Y]. So is [Z].\", \n",
    "#          \"2\": \"[X] is a type of [Y]. So is [Z].\", \n",
    "#          \"3\": \"[X] is a kind [Y]. So is [Z].\", \n",
    "#         }\n",
    "article_for_z=True \n",
    "unmasker = unmasker = pipeline('fill-mask', model= 'bert-large-uncased', device=0)\n",
    "top_k=10\n",
    "anchor_num= 5\n",
    "batch_size = 100 \n",
    "df_res_def = []\n",
    "debug =  False #True \n",
    "# debug =  True\n",
    "scorer_target_N_prompts = 'freqProbLogSum' #'probAvg' #'probLogSum'\n",
    "\n",
    "json_path_sg = '../../data/swow/swow.en.similar_words.sg.json' \n",
    "json_path_pl = '../../data/swow/swow.en.similar_words.pl.json'\n",
    "\n",
    "dataset_to_localpath, dataset_name_to_relpath = get_dataset_to_respath(dataset_to_respath)\n",
    "\n",
    "for dataset, data_path in dataset_to_localpath.items():\n",
    "    if dataset !=\"BLESS\": continue \n",
    "        \n",
    "    dic_sub_to_anchors_singular,dic_sub_to_anchors_plural = read_anchors_from_swow(json_path_sg, json_path_pl)\n",
    "    df = read_data(data_path)\n",
    "    dic_sub_to_anchors_singular_list = list(dic_sub_to_anchors_singular.keys())\n",
    "    df = df.query(f\"sub_label_sg in {dic_sub_to_anchors_singular_list}\")\n",
    "    \n",
    "    for idx, pattern in def_sap_id_to_patterns.items():\n",
    "        df[f'masked_sentences_{idx}'] = df['sub_label_sg'].apply(lambda x: pattern.replace(\"[Y]\", \"[MASK]\").replace(\"[X]\", f\"{_get_article(x)} {x}\"))\n",
    "        \n",
    "        df = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_singular, \n",
    "                                    df= df, \n",
    "                                    mask_col = f'masked_sentences_{idx}', \n",
    "                                    sub_col = 'sub_label_sg', \n",
    "                                    anchor_col='subj_anchors_sg', \n",
    "                                    probe_type='singular', \n",
    "                                    article_for_z=article_for_z,\n",
    "                                    anchor_num=anchor_num\n",
    "                           )\n",
    "\n",
    "    if debug: \n",
    "        df = df.head(5)\n",
    "        display(df)\n",
    "        \n",
    "    for idx in range(1, len(def_sap_id_to_patterns.keys())+1 ):\n",
    "        df[f'outputs_{idx}'] = [unmasker(x, top_k= 2*top_k) for x in tqdm(df[f'masked_sentences_{idx}'].to_list())]\n",
    "        df[[f'pred_{idx}', f'pred_{idx}_score']] = filter_outputs_with_probs(df.subj_anchors_combined.to_list(), \n",
    "                                                                                                        df[f'outputs_{idx}'],  \n",
    "                                                                                                        return_probs=True, \n",
    "                                                                                                        top_k= 2* top_k, \n",
    "                                                                                                        scorer= scorer_target_N_prompts,\n",
    "                                                                                                        filter_objects_flag = True,\n",
    "                                                                                                        filter_objects_with_input = True \n",
    "                                                                                                        )\n",
    "        \n",
    "        df[f'pred_{idx}']= df[f'pred_{idx}'].apply(lambda x: merge_predictions_in_concept_level(uniform_funcion=singularize, words=x, top_k=top_k))\n",
    "        #df['obj_label_sg'] = df['obj_label'].apply(lambda x: [singularize(x[0])])\n",
    "        #df['obj_label_sg'] = df['obj_label'].apply(lambda x: [eval(x[0])])\n",
    "        \n",
    "        df[f'p@{top_k}_{idx}'] = df[['obj_label_sg', f'pred_{idx}']].apply(lambda x: 1 if x[0][0] in x[1]  else 0, axis=1)\n",
    "        df[f'mrr@{top_k}_{idx}'] = df[['obj_label_sg', f'pred_{idx}']].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "        \n",
    "        p_at_k = df[f'p@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        mrr = df[f'mrr@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        cur_res = {\"dataset\": dataset, \"pattern_id\": idx, \"P@K\": round(p_at_k, 3)*100, 'MRR': round(mrr,3)*100 }\n",
    "        df_res_def.append(cur_res)\n",
    "        print(cur_res)\n",
    "        \n",
    "df_res_def = pd.DataFrame(df_res_def)\n",
    "df_res_def_pivot = layout_table(df_res_def, dataset_list =['BLESS','LMDIAG', 'CLSB', 'SHWARTZ', 'EVAL', 'LEDS']) \n",
    "display(df_res_def_pivot)\n",
    "\n",
    "DataFrame2Latex(df= df_res_def_pivot , label=f'tab:def_single_pattern_ablation', \n",
    "            caption=f'Experimental results on definitional single patterns.', \n",
    "            output_file= None , #'../log/paper_results/latex.test.tex',\n",
    "            adjustbox_width = 'textwidth',\n",
    "            precision = 1,\n",
    "            column_format='l|ll|ll|ll|ll|ll|ll',\n",
    "            multicolumn_format='c|'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_sg</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accident</td>\n",
       "      <td>[error]</td>\n",
       "      <td>[crime, liability, condition, disaster, mistake, problem, cause, tragedy, situation, catastrophe]</td>\n",
       "      <td>[injury, event, emergency, disaster, incident, damage, tragedy, crime, ambulance, death]</td>\n",
       "      <td>[gesture, deed, thing, word, judgment, sentence, term, play, act, mistake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accident</td>\n",
       "      <td>[mistake]</td>\n",
       "      <td>[crime, liability, condition, disaster, mistake, problem, cause, tragedy, situation, catastrophe]</td>\n",
       "      <td>[injury, event, emergency, disaster, incident, damage, tragedy, crime, ambulance, death]</td>\n",
       "      <td>[gesture, deed, thing, word, judgment, sentence, term, play, act, mistake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action</td>\n",
       "      <td>[event]</td>\n",
       "      <td>[process, thing, rule, decision, statement, concept, result, consequence, condition, verb]</td>\n",
       "      <td>[behavior, decision, activity, process, act, movement, communication, behaviour, event, response]</td>\n",
       "      <td>[deed, thing, act, gesture, judgment, idea, decision, object, statement, intention]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>action</td>\n",
       "      <td>[work]</td>\n",
       "      <td>[process, thing, rule, decision, statement, concept, result, consequence, condition, verb]</td>\n",
       "      <td>[behavior, decision, activity, process, act, movement, communication, behaviour, event, response]</td>\n",
       "      <td>[deed, thing, act, gesture, judgment, idea, decision, object, statement, intention]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor</td>\n",
       "      <td>[person]</td>\n",
       "      <td>[person, performer, musician, writer, professional, singer, movie, theater, stage, theatre]</td>\n",
       "      <td>[person, musician, performer, film, artist, entertainer, professional, writer, entertainment, celebrity]</td>\n",
       "      <td>[person, man, thing, gesture, character, people, individual, human, object, act]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>world</td>\n",
       "      <td>[experience]</td>\n",
       "      <td>[map, place, space, universe, concept, system, continent, country, global, globe]</td>\n",
       "      <td>[space, map, place, geography, universe, continent, earth, atlas, land, planet]</td>\n",
       "      <td>[object, thing, space, language, environment, universe, work, concept, planet, system]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>world</td>\n",
       "      <td>[place]</td>\n",
       "      <td>[map, place, space, universe, concept, system, continent, country, global, globe]</td>\n",
       "      <td>[space, map, place, geography, universe, continent, earth, atlas, land, planet]</td>\n",
       "      <td>[object, thing, space, language, environment, universe, work, concept, planet, system]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>worm</td>\n",
       "      <td>[animal]</td>\n",
       "      <td>[disease, virus, creature, parasite, bug, snake, crawl, lizard, fish, specie]</td>\n",
       "      <td>[insect, animal, bug, creature, virus, fish, snake, organism, lizard, spider]</td>\n",
       "      <td>[insect, creature, animal, snake, object, fish, parasite, thing, person, organism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>writer</td>\n",
       "      <td>[person]</td>\n",
       "      <td>[person, journalist, document, publisher, professional, reader, publication, manuscript, man, human]</td>\n",
       "      <td>[document, person, journalist, author, manuscript, artist, writing, editor, professional, book]</td>\n",
       "      <td>[person, man, individual, reader, object, fellow, human, woman, spirit, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>yard</td>\n",
       "      <td>[place]</td>\n",
       "      <td>[field, lot, space, backyard, place, property, unit, lawn, square, garden]</td>\n",
       "      <td>[land, field, property, area, lawn, space, measurement, build, home, measure]</td>\n",
       "      <td>[space, thing, work, object, land, area, gesture, place, distance, house]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>940 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_label_sg     obj_label  \\\n",
       "0       accident       [error]   \n",
       "1       accident     [mistake]   \n",
       "2         action       [event]   \n",
       "3         action        [work]   \n",
       "4          actor      [person]   \n",
       "..           ...           ...   \n",
       "948        world  [experience]   \n",
       "949        world       [place]   \n",
       "950         worm      [animal]   \n",
       "951       writer      [person]   \n",
       "952         yard       [place]   \n",
       "\n",
       "                                                                                                   pred_1  \\\n",
       "0       [crime, liability, condition, disaster, mistake, problem, cause, tragedy, situation, catastrophe]   \n",
       "1       [crime, liability, condition, disaster, mistake, problem, cause, tragedy, situation, catastrophe]   \n",
       "2              [process, thing, rule, decision, statement, concept, result, consequence, condition, verb]   \n",
       "3              [process, thing, rule, decision, statement, concept, result, consequence, condition, verb]   \n",
       "4             [person, performer, musician, writer, professional, singer, movie, theater, stage, theatre]   \n",
       "..                                                                                                    ...   \n",
       "948                     [map, place, space, universe, concept, system, continent, country, global, globe]   \n",
       "949                     [map, place, space, universe, concept, system, continent, country, global, globe]   \n",
       "950                         [disease, virus, creature, parasite, bug, snake, crawl, lizard, fish, specie]   \n",
       "951  [person, journalist, document, publisher, professional, reader, publication, manuscript, man, human]   \n",
       "952                            [field, lot, space, backyard, place, property, unit, lawn, square, garden]   \n",
       "\n",
       "                                                                                                       pred_2  \\\n",
       "0                    [injury, event, emergency, disaster, incident, damage, tragedy, crime, ambulance, death]   \n",
       "1                    [injury, event, emergency, disaster, incident, damage, tragedy, crime, ambulance, death]   \n",
       "2           [behavior, decision, activity, process, act, movement, communication, behaviour, event, response]   \n",
       "3           [behavior, decision, activity, process, act, movement, communication, behaviour, event, response]   \n",
       "4    [person, musician, performer, film, artist, entertainer, professional, writer, entertainment, celebrity]   \n",
       "..                                                                                                        ...   \n",
       "948                           [space, map, place, geography, universe, continent, earth, atlas, land, planet]   \n",
       "949                           [space, map, place, geography, universe, continent, earth, atlas, land, planet]   \n",
       "950                             [insect, animal, bug, creature, virus, fish, snake, organism, lizard, spider]   \n",
       "951           [document, person, journalist, author, manuscript, artist, writing, editor, professional, book]   \n",
       "952                             [land, field, property, area, lawn, space, measurement, build, home, measure]   \n",
       "\n",
       "                                                                                     pred_3  \n",
       "0                [gesture, deed, thing, word, judgment, sentence, term, play, act, mistake]  \n",
       "1                [gesture, deed, thing, word, judgment, sentence, term, play, act, mistake]  \n",
       "2       [deed, thing, act, gesture, judgment, idea, decision, object, statement, intention]  \n",
       "3       [deed, thing, act, gesture, judgment, idea, decision, object, statement, intention]  \n",
       "4          [person, man, thing, gesture, character, people, individual, human, object, act]  \n",
       "..                                                                                      ...  \n",
       "948  [object, thing, space, language, environment, universe, work, concept, planet, system]  \n",
       "949  [object, thing, space, language, environment, universe, work, concept, planet, system]  \n",
       "950      [insect, creature, animal, snake, object, fish, parasite, thing, person, organism]  \n",
       "951          [person, man, individual, reader, object, fellow, human, woman, spirit, thing]  \n",
       "952               [space, thing, work, object, land, area, gesture, place, distance, house]  \n",
       "\n",
       "[940 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()\n",
    "df[['sub_label_sg', 'obj_label', 'pred_1', 'pred_2', 'pred_3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tMRR\tP@K\n",
    "pattern_id\t\t\n",
    "1\t13.5\t23.0\n",
    "2\t16.9\t28.3\n",
    "3\t15.7\t30.8\n",
    "\n",
    "\\begin{table*}[!h]\n",
    "\\centering\n",
    "\\begin{adjustbox}{width=\\textwidth}\n",
    "\\label{tab:def_single_pattern_ablation}\n",
    "\\begin{tabular}{l|ll|ll|ll|ll|ll|ll}\n",
    "\\toprule\n",
    "dataset & \\multicolumn{2}{c|}{BLESS} \\\\\n",
    " & MRR & P@K \\\\\n",
    "pattern_id &  &  \\\\\n",
    "\\midrule\n",
    "1 & 13.5 & 23.0 \\\\\n",
    "2 & \\textbf{16.9} & 28.3 \\\\\n",
    "3 & 15.7 & \\textbf{30.8} \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    " \\end{adjustbox}\n",
    "\\caption{Experimental results on definitional single patterns.}\n",
    "\\end{table*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexico-Synatactic Patterns (DAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  2%|▏         | 10/593 [00:00<00:33, 17.20it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 593/593 [00:34<00:00, 17.09it/s]\n",
      "  0%|          | 0/593 [00:00<?, ?it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 593/593 [00:34<00:00, 17.06it/s]\n",
      "  0%|          | 0/593 [00:00<?, ?it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 593/593 [00:34<00:00, 17.01it/s]\n",
      "  0%|          | 0/593 [00:00<?, ?it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 593/593 [00:35<00:00, 16.92it/s]\n",
      "  0%|          | 0/593 [00:00<?, ?it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 593/593 [00:34<00:00, 17.02it/s]\n",
      "  0%|          | 0/593 [00:00<?, ?it/s]/home/chunhua/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "100%|██████████| 593/593 [00:34<00:00, 16.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"2\" halign=\"left\">BLESS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>MRR</th>\n",
       "      <th>P@K</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pattern_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.1</td>\n",
       "      <td>51.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.4</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.7</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.1</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23.9</td>\n",
       "      <td>47.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.2</td>\n",
       "      <td>50.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset    BLESS      \n",
       "             MRR   P@K\n",
       "pattern_id            \n",
       "1           27.1  51.6\n",
       "2           21.4  39.6\n",
       "3           21.7  40.0\n",
       "4           25.1  48.1\n",
       "5           23.9  47.4\n",
       "6           19.2  50.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "17\n",
      "\\begin{table*}[!h]\n",
      "\\centering\n",
      "\\begin{adjustbox}{width=\\textwidth}\n",
      "\\label{tab:lsp_single_pattern_ablation}\n",
      "\\begin{tabular}{l|ll|ll|ll|ll|ll|ll}\n",
      "\\toprule\n",
      "dataset & \\multicolumn{2}{c|}{BLESS} \\\\\n",
      " & MRR & P@K \\\\\n",
      "pattern_id &  &  \\\\\n",
      "\\midrule\n",
      "1 & \\textbf{27.1} & \\textbf{51.6} \\\\\n",
      "2 & 21.4 & 39.6 \\\\\n",
      "3 & 21.7 & 40.0 \\\\\n",
      "4 & 25.1 & 48.1 \\\\\n",
      "5 & 23.9 & 47.4 \\\\\n",
      "6 & 19.2 & 50.8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      " \\end{adjustbox}\n",
      "\\caption{Experimental results on lexico-syntactic single patterns.}\n",
      "\\end{table*}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<df_to_latex.DataFrame2Latex at 0x2b311489f7c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lsp_sap_id_to_patterns = {\n",
    "         \"1\": \"[Y] such as [X] and [Z].\", \n",
    "         \"2\": \"[Y], including [X] and [Z].\", \n",
    "         \"3\": \"[Y], especially [X] and [Z].\", \n",
    "         \"4\": \"[X], [Z] or other [Y].\", \n",
    "         \"5\": \"[X], [Z] and other [Y].\", \n",
    "         \"6\": \"such [Y] as [X] and [Z].\", \n",
    "        }\n",
    "\n",
    "debug =  False #True \n",
    "# debug = True \n",
    "unmasker = unmasker = pipeline('fill-mask', model= 'bert-large-uncased', device=0)\n",
    "top_k=10\n",
    "scorer_target_N_prompts = 'probAvg' #'probLogSum'\n",
    "anchor_num=5\n",
    "\n",
    "dataset_to_localpath, dataset_name_to_relpath = get_dataset_to_respath(dataset_to_respath)\n",
    "df_res_lsp = []\n",
    "for dataset, data_path in dataset_to_localpath.items():\n",
    "    if dataset !=\"BLESS\": continue\n",
    "        \n",
    "    dic_sub_to_anchors_singular,dic_sub_to_anchors_plural = read_anchors_from_swow(json_path_sg, json_path_pl)\n",
    "    dic_sub_to_anchors_plural_list = list(dic_sub_to_anchors_plural.keys()) \n",
    "\n",
    "    df = read_data(data_path)\n",
    "    df = df.query(f\"sub_label_pl in {dic_sub_to_anchors_plural_list}\")\n",
    "    \n",
    "    if debug: \n",
    "        df = df.head(5)\n",
    "    for idx, pattern in lsp_sap_id_to_patterns.items():\n",
    "        df[f'masked_sentences_{idx}'] = df['sub_label_pl'].apply(lambda x: pattern.replace(\"[Y]\", \"[MASK]\").replace(\"[X]\", x))\n",
    "        \n",
    "        df = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_plural, \n",
    "                                    df= df, \n",
    "                                    mask_col = f'masked_sentences_{idx}', \n",
    "                                    sub_col = 'sub_label_pl', \n",
    "                                    anchor_col='subj_anchors_pl', \n",
    "                                    probe_type='plural', \n",
    "                                    article_for_z=False,\n",
    "                                    anchor_num = anchor_num\n",
    "                           )\n",
    "\n",
    "    if debug: display(df)\n",
    "        \n",
    "    for idx in range(1, len(lsp_sap_id_to_patterns.keys())+1 ):\n",
    "        df[f'outputs_{idx}'] = [unmasker(x, top_k=2*top_k) for x in tqdm(df[f'masked_sentences_{idx}'].to_list())]\n",
    "        df[[f'pred_{idx}', f'pred_{idx}_score']] = filter_outputs_with_probs(df.subj_anchors_combined.to_list(), \n",
    "                                                                                                        df[f'outputs_{idx}'],  \n",
    "                                                                                                        return_probs=True, \n",
    "                                                                                                        top_k= 2* top_k, \n",
    "                                                                                                        scorer= scorer_target_N_prompts,\n",
    "                                                                                                        filter_objects_flag = True,\n",
    "                                                                                                        filter_objects_with_input = True \n",
    "                                                                                                        )\n",
    "        \n",
    "        df[f'pred_{idx}']= df[f'pred_{idx}'].apply(lambda x: merge_predictions_in_concept_level(uniform_funcion=pluralize, words=x, top_k=top_k))\n",
    "#         df['obj_label_pl'] = df['obj_label'].apply(lambda x: [pluralize(x[0])])\n",
    "        \n",
    "        df[f'p@{top_k}_{idx}'] = df[['obj_label_pl', f'pred_{idx}']].apply(lambda x: 1 if x[0][0] in x[1]  else 0, axis=1)\n",
    "        df[f'mrr@{top_k}_{idx}'] = df[['obj_label_pl', f'pred_{idx}']].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "        \n",
    "        p_at_k = df[f'p@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        mrr = df[f'mrr@{top_k}_{idx}'].sum()/len(df.index)\n",
    "        cur_res = {\"dataset\": dataset, \"pattern_id\": idx, \"P@K\": round(p_at_k, 3)*100, 'MRR': round(mrr,3)*100 }\n",
    "        df_res_lsp.append(cur_res)\n",
    "        print(cur_res)\n",
    "        \n",
    "df_res_lsp = pd.DataFrame(df_res_lsp)\n",
    "df_res_lsp_pivot = layout_table(df_res_lsp, dataset_list =['BLESS','LMDIAG', 'CLSB', 'SHWARTZ', 'EVAL', 'LEDS'])\n",
    "display(df_res_lsp_pivot)\n",
    "\n",
    "DataFrame2Latex(df= df_res_lsp_pivot , label=f'tab:lsp_single_pattern_ablation', \n",
    "            caption=f'Experimental results on lexico-syntactic single patterns.', \n",
    "            output_file= None , #'../log/paper_results/latex.test.tex',\n",
    "            adjustbox_width = 'textwidth',\n",
    "            precision = 1,\n",
    "            column_format='l|ll|ll|ll|ll|ll|ll',\n",
    "            multicolumn_format='c|'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['subj_sister'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4010dbfc2c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sub_label_sg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'obj_label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred_1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pred_3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'subj_sister'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5780\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5782\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5784\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5844\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5845\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5847\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['subj_sister'] not in index\""
     ]
    }
   ],
   "source": [
    "df[['sub_label_sg', 'obj_label', 'pred_1', 'pred_2', 'pred_3', 'subj_sister']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
