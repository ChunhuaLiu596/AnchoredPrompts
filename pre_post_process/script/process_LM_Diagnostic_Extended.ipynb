{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json \n",
    "import copy\n",
    "import re \n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import string\n",
    "from inflection import pluralize, singularize\n",
    "\n",
    "from util_wordnet import get_sister_terms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the LM-Diagnostic-Extended data into LM probing format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vegetable', 'fish', 'bird', 'insect', 'flower', 'tree', 'building', 'tool', 'vehicle'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_label_pl</th>\n",
       "      <th>relation</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A graver is a [MASK].]</td>\n",
       "      <td>[tool]</td>\n",
       "      <td>graver</td>\n",
       "      <td>gravers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[bevel, dibber, spreader, hammer, crank, float, pallet, opener, starter, marlingspike, bodkin, plunger, auger, pincer, marlinspike, pick, tweezer, dibble, threader, square, saw, awl, marlinespike, screwdriver, pitchfork, pliers, sandblaster, file, plane, spatula, pointrel, trowel, weeder, wrench, gutter, scraper, spanner, shovel, pointel, plyers, straightedge, pestle, ravehook]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[A smallmouth is a [MASK].]</td>\n",
       "      <td>[fish]</td>\n",
       "      <td>smallmouth</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[largemouth]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A pelican is a [MASK].]</td>\n",
       "      <td>[bird]</td>\n",
       "      <td>pelican</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[cormorant, snakebird, tropicbird, darter, anhinga, gannet]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A sapsucker is a [MASK].]</td>\n",
       "      <td>[bird]</td>\n",
       "      <td>sapsucker</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[wryneck, redhead, piculet, ivorybill, flicker]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A mako is a [MASK].]</td>\n",
       "      <td>[fish]</td>\n",
       "      <td>mako</td>\n",
       "      <td>makos</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[porbeagle]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              masked_sentences obj_label   sub_label sub_label_pl relation  \\\n",
       "0      [A graver is a [MASK].]    [tool]      graver      gravers      IsA   \n",
       "1  [A smallmouth is a [MASK].]    [fish]  smallmouth  smallmouths      IsA   \n",
       "2     [A pelican is a [MASK].]    [bird]     pelican     pelicans      IsA   \n",
       "3   [A sapsucker is a [MASK].]    [bird]   sapsucker   sapsuckers      IsA   \n",
       "4        [A mako is a [MASK].]    [fish]        mako        makos      IsA   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                     sub_sister  \\\n",
       "0  [bevel, dibber, spreader, hammer, crank, float, pallet, opener, starter, marlingspike, bodkin, plunger, auger, pincer, marlinspike, pick, tweezer, dibble, threader, square, saw, awl, marlinespike, screwdriver, pitchfork, pliers, sandblaster, file, plane, spatula, pointrel, trowel, weeder, wrench, gutter, scraper, spanner, shovel, pointel, plyers, straightedge, pestle, ravehook]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                  [largemouth]   \n",
       "2                                                                                                                                                                                                                                                                                                                                   [cormorant, snakebird, tropicbird, darter, anhinga, gannet]   \n",
       "3                                                                                                                                                                                                                                                                                                                                               [wryneck, redhead, piculet, ivorybill, flicker]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                   [porbeagle]   \n",
       "\n",
       "   uuid  \n",
       "0     1  \n",
       "1     2  \n",
       "2     3  \n",
       "3     4  \n",
       "4     5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Hypo 576\n",
      "#Hyper 9\n",
      "#Hypo-Hyper pairs: 576\n",
      "bird         0.229167\n",
      "vehicle      0.182292\n",
      "building     0.138889\n",
      "fish         0.111111\n",
      "tree         0.107639\n",
      "flower       0.085069\n",
      "insect       0.074653\n",
      "tool         0.065972\n",
      "vegetable    0.005208\n",
      "Name: obj_label, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b488aeff460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save ../../data/lm_diagnostic_extended//singular/IsA.jsonl with 576 lines\n",
      "{'tools', 'fish', 'insects', 'vehicles', 'birds', 'trees', 'vegetables', 'flowers', 'buildings'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_label_pl</th>\n",
       "      <th>relation</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[gravers are [MASK].]</td>\n",
       "      <td>[tools]</td>\n",
       "      <td>gravers</td>\n",
       "      <td>gravers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[bevel, dibber, spreader, hammer, crank, float, pallet, opener, starter, marlingspike, bodkin, plunger, auger, pincer, marlinspike, pick, tweezer, dibble, threader, square, saw, awl, marlinespike, screwdriver, pitchfork, pliers, sandblaster, file, plane, spatula, pointrel, trowel, weeder, wrench, graver, gutter, scraper, spanner, shovel, pointel, plyers, straightedge, pestle, ravehook]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[smallmouths are [MASK].]</td>\n",
       "      <td>[fish]</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[largemouth, smallmouth]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[pelicans are [MASK].]</td>\n",
       "      <td>[birds]</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[cormorant, snakebird, tropicbird, darter, anhinga, gannet, pelican]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sapsuckers are [MASK].]</td>\n",
       "      <td>[birds]</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[wryneck, redhead, piculet, ivorybill, flicker, sapsucker]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[makoes are [MASK].]</td>\n",
       "      <td>[fish]</td>\n",
       "      <td>makoes</td>\n",
       "      <td>makoes</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            masked_sentences obj_label    sub_label sub_label_pl relation  \\\n",
       "0      [gravers are [MASK].]   [tools]      gravers      gravers      IsA   \n",
       "1  [smallmouths are [MASK].]    [fish]  smallmouths  smallmouths      IsA   \n",
       "2     [pelicans are [MASK].]   [birds]     pelicans     pelicans      IsA   \n",
       "3   [sapsuckers are [MASK].]   [birds]   sapsuckers   sapsuckers      IsA   \n",
       "4       [makoes are [MASK].]    [fish]       makoes       makoes      IsA   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                             sub_sister  \\\n",
       "0  [bevel, dibber, spreader, hammer, crank, float, pallet, opener, starter, marlingspike, bodkin, plunger, auger, pincer, marlinspike, pick, tweezer, dibble, threader, square, saw, awl, marlinespike, screwdriver, pitchfork, pliers, sandblaster, file, plane, spatula, pointrel, trowel, weeder, wrench, graver, gutter, scraper, spanner, shovel, pointel, plyers, straightedge, pestle, ravehook]   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                              [largemouth, smallmouth]   \n",
       "2                                                                                                                                                                                                                                                                                                                                  [cormorant, snakebird, tropicbird, darter, anhinga, gannet, pelican]   \n",
       "3                                                                                                                                                                                                                                                                                                                                            [wryneck, redhead, piculet, ivorybill, flicker, sapsucker]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                    []   \n",
       "\n",
       "   uuid  \n",
       "0     1  \n",
       "1     2  \n",
       "2     3  \n",
       "3     4  \n",
       "4     5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Hypo 576\n",
      "#Hyper 9\n",
      "#Hypo-Hyper pairs: 576\n",
      "birds         0.229167\n",
      "vehicles      0.182292\n",
      "buildings     0.138889\n",
      "fish          0.111111\n",
      "trees         0.107639\n",
      "flowers       0.085069\n",
      "insects       0.074653\n",
      "tools         0.065972\n",
      "vegetables    0.005208\n",
      "Name: obj_label, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2b488aeff460>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save ../../data/lm_diagnostic_extended//singular//plural/IsA.jsonl with 576 lines\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _get_article(word):\n",
    "    if word[0] in ['a', 'e', 'i', 'o', 'u']:\n",
    "        return 'an'\n",
    "    return 'a'\n",
    "\n",
    "\n",
    "def save_dict_to_json(examples, output_path):\n",
    "    ''' \n",
    "    save a list of dicts into otuput_path, orient='records' (each line is a dict) \n",
    "    examples: a list of dicts\n",
    "    output_path: \n",
    "    '''\n",
    "\n",
    "    with open(output_path, 'w') as fout:\n",
    "        for example in examples:\n",
    "            json.dump(example, fout)\n",
    "            fout.write(\"\\n\")\n",
    "        print(f\"save {output_path} with {len(examples)} lines\")\n",
    "\n",
    "def add_period_at_the_end_of_sentence(sentence):\n",
    "    last_token = sentence[-1]\n",
    "    if last_token != '.': \n",
    "        return sentence + '.'\n",
    "    return [sentence]\n",
    "\n",
    "def process_data_to_lm():\n",
    "    data_dir = '../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/' \n",
    "    out_dir = '../../data/lm_diagnostic_extended/'\n",
    "    files = ['singular.tsv', 'plural.tsv'] #, 'contextual.tsv']\n",
    "\n",
    "    for file in files: \n",
    "        path = f\"{data_dir}/{file}\"\n",
    "        df = pd.read_csv(path, sep='\\t', names=['masked_sentences', 'obj_label'])\n",
    "        df['masked_sentences'] =  df['masked_sentences'].apply(lambda x: add_period_at_the_end_of_sentence(x))\n",
    "        vocab = set(df['obj_label'].to_list())\n",
    "        label_counter = df['obj_label'].value_counts(normalize=True)\n",
    "        print(vocab)\n",
    "        if 'singular' in file: \n",
    "             df['sub_label'] = df['masked_sentences'].apply(lambda x: x.split()[1])\n",
    "        elif 'plural' in file: \n",
    "             df['sub_label'] = df['masked_sentences'].apply(lambda x: x.split()[0])\n",
    "        \n",
    "        word_pairs = [name for name, group in df.groupby(['sub_label', 'obj_label'])]\n",
    "        hyper = set(df['obj_label'])\n",
    "        df['sub_label_pl'] =  df['sub_label'].apply(lambda x: pluralize(x))\n",
    "        df['obj_label'] =  df['obj_label'].apply(lambda x: [x])\n",
    "        df['masked_sentences'] =  df['masked_sentences'].apply(lambda x: [x])\n",
    "        df['relation'] = 'IsA'\n",
    "        df['sub_sister'] = df['sub_label'].apply(lambda x: get_sister_terms(x, distance_to_hypernym=6))\n",
    "        df['uuid'] = df.index + 1\n",
    "        display(df.head())\n",
    "        \n",
    "        \n",
    "        print(f\"#Hypo {len(set(df['sub_label']))}\")\n",
    "        print(f\"#Hyper {len(hyper)}\")\n",
    "        print(f\"#Hypo-Hyper pairs:\",len(word_pairs) )\n",
    "        print(label_counter)\n",
    "        display(label_counter.plot(kind='bar'))\n",
    "        \n",
    "        \n",
    "        out_file = file.replace(\".tsv\", \"\")\n",
    "        out_dir = f\"{out_dir}/{out_file}/\"\n",
    "        Path( out_dir ).mkdir( parents=True, exist_ok=True )\n",
    "        \n",
    "        save_dict_to_json(examples=df.to_dict(orient='records'), output_path=out_dir + 'IsA.jsonl')     \n",
    "process_data_to_lm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the singular and plural obj label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ducks', 'duck', 'chickens', 'swans', 'hen']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_anchors_in_concept_level(uniform_funcion, words, top_k):\n",
    "    '''\n",
    "    uniform_function: either signualr or plural\n",
    "    \n",
    "    '''\n",
    "    top_k_output =  []\n",
    "    for word in words:\n",
    "        uniformed_words = uniform_funcion(word) \n",
    "        if word not in top_k_output: \n",
    "            top_k_output.append(word)\n",
    "        if len(top_k_output) == top_k: \n",
    "            return top_k_output\n",
    "\n",
    "    return top_k_output[:top_k]\n",
    "\n",
    "words = ['ducks', 'duck', 'chickens', 'swans', 'hen', 'cranes', 'rabbits', 'brids', 'pigs'] \n",
    "merge_anchors_in_concept_level(singularize, words, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "      <th>sub_label_pl</th>\n",
       "      <th>sub_label_sg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>[tool, tools]</td>\n",
       "      <td>[A graver is a [MASK].]</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "      <td>gravers</td>\n",
       "      <td>graver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>[fish]</td>\n",
       "      <td>[A smallmouth is a [MASK].]</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>smallmouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>[bird, birds]</td>\n",
       "      <td>[A pelican is a [MASK].]</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>pelican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>[bird, birds]</td>\n",
       "      <td>[A sapsucker is a [MASK].]</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>sapsucker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>[fish]</td>\n",
       "      <td>[A mako is a [MASK].]</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "      <td>makos</td>\n",
       "      <td>mako</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_label      obj_label             masked_sentences  uuid relation  \\\n",
       "0      graver  [tool, tools]      [A graver is a [MASK].]     1      IsA   \n",
       "1  smallmouth         [fish]  [A smallmouth is a [MASK].]     2      IsA   \n",
       "2     pelican  [bird, birds]     [A pelican is a [MASK].]     3      IsA   \n",
       "3   sapsucker  [bird, birds]   [A sapsucker is a [MASK].]     4      IsA   \n",
       "4        mako         [fish]        [A mako is a [MASK].]     5      IsA   \n",
       "\n",
       "  sub_label_pl sub_label_sg  \n",
       "0      gravers       graver  \n",
       "1  smallmouths   smallmouth  \n",
       "2     pelicans      pelican  \n",
       "3   sapsuckers    sapsucker  \n",
       "4        makos         mako  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended//sgpl/IsA.jsonl with 576 lines\n"
     ]
    }
   ],
   "source": [
    "def merge_singular_plural_objects(singular, plural):\n",
    "    return [singular] if singular == plural else [singular, plural]\n",
    "\n",
    "def merge_singular_plural(data_dir = '../probe-generalization/Syntagmatic/LM-Diagnostic-Extended/' ):\n",
    "    \n",
    "    files = ['sgpl.tsv'] \n",
    "\n",
    "    for file in files: \n",
    "        path = f\"{data_dir}/{file}\"\n",
    "        df = pd.read_csv(path, sep='\\t', names=['masked_sentences', 'obj_label_singular', 'obj_label_plural'])\n",
    "        df['masked_sentences'] =  df['masked_sentences'].apply(lambda x: add_period_at_the_end_of_sentence(x))\n",
    "        \n",
    "        \n",
    "        df['sub_label'] = df['masked_sentences'].apply(lambda x: x.split()[1])\n",
    "        df['sub_label_pl'] =  df['sub_label'].apply(lambda x: pluralize(x))\n",
    "        df['sub_label_sg'] =  df['sub_label'].apply(lambda x: singularize(x))\n",
    "        \n",
    "        df['obj_label'] =  df[['obj_label_singular', 'obj_label_plural']].apply(lambda x: merge_singular_plural_objects(x[0], x[1]), axis=1)\n",
    "#         vocab = set(df['obj_label'].to_list())\n",
    "        df['masked_sentences'] =  df['masked_sentences'].apply(lambda x: [x])\n",
    "        df['relation'] = 'IsA'\n",
    "        df['uuid'] = df.index + 1\n",
    "        \n",
    "        df = df[['sub_label', 'obj_label', 'masked_sentences', 'uuid', 'relation', 'sub_label_pl', 'sub_label_sg']]\n",
    "        display(df.head())\n",
    "        out_file = file.replace(\".tsv\", \"\")\n",
    "        out_dir = f\"{data_dir}/{out_file}/\"\n",
    "\n",
    "        Path( out_dir ).mkdir( parents=True, exist_ok=True )\n",
    "        save_dict_to_json(examples=df.to_dict(orient='records'), output_path=out_dir+\"IsA.jsonl\") \n",
    "\n",
    "merge_singular_plural(data_dir = '../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "IsA.jsonl                                     100%  224KB   5.9MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "# !scp Syntagmatic/LM-Diagnostic-Extended/plural/IsA.jsonl spartan:/home/chunhua/cogsci/DAP/data/lm_diagnostic_extended/plural/IsA.jsonl\n",
    "!scp ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/singular/IsA.jsonl spartan:/home/chunhua/cogsci/DAP/data/lm_diagnostic_extended/singular/IsA.jsonl\n",
    "# !scp ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/sgpl/IsA.jsonl spartan:/home/chunhua/cogsci/DAP/data/lm_diagnostic_extended/sgpl/IsA.jsonl\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitive analysis on signular anchors and plural anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 576/576 [00:11<00:00, 50.38it/s]\n",
      "100%|██████████| 576/576 [00:00<00:00, 9974.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import json \n",
    "import copy\n",
    "import re \n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from inflection import singularize, pluralize \n",
    "\n",
    "\n",
    "\n",
    "def get_sister_terms(word):\n",
    "    '''\n",
    "    \"Coordinate (sister) terms: share the same hypernym\"\n",
    "    \"The sister relation is the usual one encountered when working with tree structures: sisters are word forms (either simple words or collocations) that are both immediate hyponyms of the same node\"\n",
    "    '''\n",
    "    sister_terms = set()\n",
    "    for synset in wn.synsets(word ,\"n\"):\n",
    "        for hypernym in synset.hypernyms()[:1]:\n",
    "            sister_synsets = hypernym.hyponyms()\n",
    "            for sister_synset in sister_synsets:\n",
    "                sister_names = [x.name() for x in sister_synset.lemmas()]\n",
    "                sister_names_selected = [name.lower() for name in sister_names if len(name.split(\"_\"))==1 and  len(name.split(\"-\"))==1  and name!=word]\n",
    "                sister_terms = sister_terms.union(set(sister_names_selected))\n",
    "#                 print(sister_synset)\n",
    "#                 print(sister_terms )\n",
    "#                 print()\n",
    "    return list(sister_terms)\n",
    "\n",
    "# read the singular data\n",
    "path_anchor_sg = '../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg.csv'\n",
    "query_cols = ['sub_label', 'obj_label', 'subj_anchors', 'uuid']\n",
    "df_sg  = pd.read_csv(path_anchor_sg)[query_cols]\n",
    "df_sg['subj_anchors'] = df_sg['subj_anchors'].apply(lambda x: eval(x))\n",
    "\n",
    "df_sg['subj_anchors'] = df_sg['subj_anchors'].progress_apply(lambda x: [singularize(word) for word in x])\n",
    "df_sg['subj_sisters'] = df_sg['sub_label'].progress_apply(lambda x: get_sister_terms(x))\n",
    "\n",
    "\n",
    "# read the plural data\n",
    "path_anchor_pl = '../log/bert-large-uncased/lm_diagnostic_extended/plural/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv'\n",
    "df_pl  = pd.read_csv(path_anchor_pl)[query_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       anchor_sg_in_sisters_num  anchor_pl_in_sisters_num\n",
      "count                576.000000                576.000000\n",
      "mean                   0.258681                  0.258681\n",
      "std                    0.657342                  0.657342\n",
      "min                    0.000000                  0.000000\n",
      "25%                    0.000000                  0.000000\n",
      "50%                    0.000000                  0.000000\n",
      "75%                    0.000000                  0.000000\n",
      "max                    4.000000                  4.000000\n",
      "anchor_sg_in_sisters_num    0.258681\n",
      "anchor_pl_in_sisters_num    0.258681\n",
      "dtype: float64\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../log/anchors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-56b977e0bbf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sgpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anchor_sg_in_sisters_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'anchor_pl_in_sisters_num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdf_sgpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../log/anchors/lm_diagnostic_extended.anchors.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;31m# plot(kind='hist')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3561\u001b[0m         )\n\u001b[1;32m   3562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3563\u001b[0;31m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[1;32m   3564\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3565\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         )\n\u001b[0;32m-> 1180\u001b[0;31m         \u001b[0mcsv_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \"\"\"\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# apply compression and byte/text conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         with get_handle(\n\u001b[0m\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Only for write methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mfr\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../log/anchors'"
     ]
    }
   ],
   "source": [
    "df_pl['subj_anchors'] = df_pl['subj_anchors'].apply(lambda x: eval(x))\n",
    "df_pl['subj_anchors'] = df_pl['subj_anchors'].apply(lambda x: [singularize(word) for word in x])\n",
    "\n",
    "\n",
    "# df_sgpl.columns \n",
    "df_sgpl = pd.merge(df_sg, df_pl, on ='uuid', suffixes=('_sg', '_pl'))\n",
    "df_sgpl[['sub_label_sg', 'sub_label_pl', 'obj_label_sg', 'obj_label_pl', 'subj_anchors_sg', 'subj_anchors_pl']].head(20)\n",
    "df_sgpl[['sub_label_sg', 'sub_label_pl', 'obj_label_sg', 'obj_label_pl', 'subj_anchors_sg', 'subj_anchors_pl', 'subj_sisters']].head(20)\n",
    "\n",
    "df_sgpl['anchor_sg_in_sisters'] = df_sgpl[['subj_anchors_sg', 'subj_sisters']].apply(lambda x: set(x[0]).intersection(set(x[1])), axis=1)\n",
    "df_sgpl['anchor_pl_in_sisters'] = df_sgpl[['subj_anchors_sg', 'subj_sisters']].apply(lambda x: set(x[0]).intersection(set(x[1])), axis=1)\n",
    "\n",
    "df_sgpl['anchor_sg_in_sisters_num'] =  df_sgpl['anchor_sg_in_sisters'].apply(lambda x: len(x))  \n",
    "df_sgpl['anchor_pl_in_sisters_num'] =  df_sgpl['anchor_pl_in_sisters'].apply(lambda x: len(x))  \n",
    "\n",
    "# df_sgpl.head()\n",
    "print(df_sgpl[['anchor_sg_in_sisters_num', 'anchor_pl_in_sisters_num']].describe())\n",
    "print(df_sgpl[['anchor_sg_in_sisters_num', 'anchor_pl_in_sisters_num']].mean())\n",
    "\n",
    "df_sgpl.to_csv(\"../log/anchors/lm_diagnostic_extended.anchors.csv\")\n",
    "# plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp spartan:~/cogsci/DAP/log/anchors/lm_diagnostic_extended.anchors.csv ../log/bert-large-uncased/lm_diagnostic_extended/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = ['shovel', 'digger', 'deeper', 'grave', 'hammer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       anchor_sg_in_sisters_num  anchor_pl_in_sisters_num\n",
      "count                576.000000                576.000000\n",
      "mean                   0.255208                  0.526042\n",
      "std                    0.650731                  1.061262\n",
      "min                    0.000000                  0.000000\n",
      "25%                    0.000000                  0.000000\n",
      "50%                    0.000000                  0.000000\n",
      "75%                    0.000000                  1.000000\n",
      "max                    4.000000                  5.000000\n",
      "anchor_sg_in_sisters_num    0.255208\n",
      "anchor_pl_in_sisters_num    0.526042\n",
      "dtype: float64\n",
      "96\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "df_sgpl = pd.read_csv('../log/bert-large-uncased/lm_diagnostic_extended/lm_diagnostic_extended.anchors.csv')\n",
    "# for x in df_sgpl['subj_anchors_pl']:\n",
    "#     print(type(eval(x)), eval(x))\n",
    "# # df_sgpl.head()\n",
    "\n",
    "\n",
    "for col in ['subj_anchors_sg', 'subj_sisters', 'subj_anchors_pl' ] :#'obj_label_sg', 'subj_anchors_sg',\n",
    "#        'subj_sisters', 'obj_label_pl', 'subj_anchors_pl']:\n",
    "#     print(col)\n",
    "    df_sgpl[col] = df_sgpl[col].apply(lambda x: eval(x))\n",
    " \n",
    "\n",
    "df_sgpl['anchor_sg_in_sisters'] = df_sgpl[['subj_anchors_sg', 'subj_sisters']].apply(lambda x: set(x[0]).intersection(set(x[1])), axis=1)\n",
    "df_sgpl['anchor_pl_in_sisters'] = df_sgpl[['subj_anchors_pl', 'subj_sisters']].apply(lambda x: set(x[0]).intersection(set(x[1])), axis=1)\n",
    "\n",
    "\n",
    "df_sgpl['anchor_sg_in_sisters_num'] =  df_sgpl['anchor_sg_in_sisters'].apply(lambda x: len(x))  \n",
    "df_sgpl['anchor_pl_in_sisters_num'] =  df_sgpl['anchor_pl_in_sisters'].apply(lambda x: len(x))  \n",
    "\n",
    "\n",
    "print(df_sgpl[['anchor_sg_in_sisters_num', 'anchor_pl_in_sisters_num']].describe())\n",
    "print(df_sgpl[['anchor_sg_in_sisters_num', 'anchor_pl_in_sisters_num']].mean())\n",
    "\n",
    "df_sgpl1 = df_sgpl.query(\"anchor_sg_in_sisters_num>0\")\n",
    "df_sgpl2 = df_sgpl.query(\"anchor_pl_in_sisters_num>0\")\n",
    "# df.columns\n",
    "# df_sgpl[['subj_sisters', 'subj_anchors_sg', 'subj_anchors_pl', 'anchor_sg_in_sisters','anchor_pl_in_sisters',\n",
    "#        'anchor_sg_in_sisters_num', 'anchor_pl_in_sisters_num']].head(50)\n",
    "print(len(df_sgpl1))\n",
    "print(len(df_sgpl2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prcess data for consitency pair check\n",
    "\n",
    "1. DEF-SAP '\n",
    "`A(a) X is a(n) Y.`\n",
    "\n",
    "\n",
    "2. X are Y.\n",
    "DEF-DAP\n",
    "\n",
    "A(n) X or Z is a(n) Y.\n",
    "X or Z are Y.\n",
    "\n",
    "LSP-SAP\n",
    "Y such as X.\n",
    "Y such as X.\n",
    "LSP-DAP\n",
    "Y such as X or Z.\n",
    "Y such as X or Z.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def definition_sap_singular_plural(data_dir, file):\n",
    "   \n",
    "    path = f\"{data_dir}/{file}\"\n",
    "    df = pd.read_csv(path, sep='\\t', names=['mask_sentences_singular', 'obj_label_singular', \n",
    "                                            'mask_sentences_plural', 'obj_label_plural'])\n",
    "    \n",
    "    df['mask_sentences_singular'] =  df['mask_sentences_singular'].apply(lambda x: add_period_at_the_end_of_sentence(x))\n",
    "    df['mask_sentences_plural'] =  df['mask_sentences_plural'].apply(lambda x: add_period_at_the_end_of_sentence(x))\n",
    "\n",
    "\n",
    "    df['sub_label_singular'] = df['mask_sentences_singular'].apply(lambda x: x.split()[1])\n",
    "    df['sub_label_plural'] = df['mask_sentences_plural'].apply(lambda x: x.split()[0])\n",
    "\n",
    "\n",
    "    df['relation'] = 'IsA'\n",
    "    df['uuid'] = df.index + 1\n",
    "\n",
    "\n",
    "    df = df[['sub_label_singular', 'obj_label_singular', 'mask_sentences_singular', \n",
    "             'sub_label_plural', 'obj_label_plural', 'mask_sentences_plural', \n",
    "             'uuid', 'relation']]\n",
    "    display(df.head())\n",
    "    out_file = file.replace(\".tsv\", \"\")\n",
    "    out_dir = f\"{data_dir}/{out_file}/\"\n",
    "\n",
    "    Path( out_dir ).mkdir( parents=True, exist_ok=True )\n",
    "    save_dict_to_json(examples=df.to_dict(orient='records'), output_path=out_dir+\"IsA.jsonl\") \n",
    "    return df \n",
    "\n",
    "\n",
    "\n",
    "def definition_dap_singular_plural(df):\n",
    "    df['mask_sentences_singular'] = df[['sub_label_singular', 'mask_sentences_singular']].apply(lambda x: x[1].replace(x[0], f\"{x[0]} or [Z]\"), axis=1)\n",
    "    df['mask_sentences_plural'] = df[['sub_label_plural', 'mask_sentences_plural']].apply(lambda x: x[1].replace(x[0], f\"{x[0]} or [Z]\"), axis=1)\n",
    "\n",
    "    df = df[['sub_label_singular', 'obj_label_singular', 'mask_sentences_singular', \n",
    "            'sub_label_plural', 'obj_label_plural', 'mask_sentences_plural', \n",
    "             'uuid', 'relation']]\n",
    "\n",
    "    return df \n",
    "\n",
    "def lsp_sap_singular_plural(df):\n",
    "    '''\n",
    "    sap: Y such as X \n",
    "\n",
    "    '''\n",
    "    \n",
    "    df['mask_sentences_singular'] = df['sub_label_singular'].apply(lambda x: f\"[MASK] such as {_get_article(x)} {x}.\")\n",
    "   \n",
    "    df['mask_sentences_plural'] = df['sub_label_plural'].apply(lambda x:f\"[MASK] such as {x}.\")\n",
    "\n",
    "    df = df[['sub_label_singular', 'obj_label_singular', 'mask_sentences_singular', \n",
    "            'sub_label_plural', 'obj_label_plural', 'mask_sentences_plural', \n",
    "             'uuid', 'relation']]\n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "def lsp_dap_singular_plural(df):\n",
    "    '''\n",
    "    sap: Y such as X \n",
    "\n",
    "    '''\n",
    "    df['mask_sentences_singular'] = df['sub_label_singular'].apply(lambda x: f\"[MASK] such as {_get_article(x)} {x} or [Z].\")\n",
    "\n",
    "    df['mask_sentences_plural'] = df['sub_label_plural'].apply(lambda x:f\"[MASK] such as {x} or [Z].\")\n",
    "\n",
    "    df = df[['sub_label_singular', 'obj_label_singular', 'mask_sentences_singular', \n",
    "            'sub_label_plural', 'obj_label_plural', 'mask_sentences_plural', \n",
    "             'uuid', 'relation']]\n",
    "\n",
    "    return df \n",
    "\n",
    "def read_anchors(path, uniform_function=None):\n",
    "    df = pd.read_csv(path)\n",
    "    df['subj_anchors'] = df['subj_anchors'].apply(lambda x: eval(x))\n",
    "    \n",
    "    if uniform_function is not None: \n",
    "        df['subj_anchors'] = df['subj_anchors'].progress_apply(lambda x: [uniform_function(word) for word in x])\n",
    "    return dict(zip(df['sub_label'], df['subj_anchors']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 253/576 [00:05<00:06, 46.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-608b56887784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mpath_anchor_pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../log/bert-large-uncased/lm_diagnostic_extended/plural/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mdic_sub_to_anchors_singular\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdic_sub_to_anchors_plural\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_anchors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_anchor_sg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_anchor_pl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor_source\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'plural'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-608b56887784>\u001b[0m in \u001b[0;36mread_anchors\u001b[0;34m(path_sg, path_pl, anchor_source, debug)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manchor_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plural'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#convert the singular anchors into singular format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subj_anchors_sg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subj_anchors_pl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msingularize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0manchor_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'singular'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#convert the plural anchors into singular format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4431\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4432\u001b[0m         \"\"\"\n\u001b[0;32m-> 4433\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4435\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1135\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1138\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m                     \u001b[0;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-608b56887784>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manchor_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plural'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#convert the singular anchors into singular format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subj_anchors_sg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subj_anchors_pl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msingularize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0manchor_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'singular'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#convert the plural anchors into singular format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-608b56887784>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manchor_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plural'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m#convert the singular anchors into singular format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subj_anchors_sg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subj_anchors_pl'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msingularize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0manchor_source\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'singular'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#convert the plural anchors into singular format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/OneDrive/OneDrive - The University of Melbourne/1.ResearchInUoM-NLP/0.Project/SW-Relation/Anchored_Prompts/DAP/script/inflection.py\u001b[0m in \u001b[0;36msingularize\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     '''\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msg\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minflect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msg\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1012\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;31m# This typically happens if a component is not initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/pipeline/trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/spacy/pipeline/tok2vec.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtok2vec\u001b[0m\u001b[0;31m#predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \"\"\"\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtokvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mbatch_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTok2VecListener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlistener\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisteners\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \"\"\"\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, Xseq, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/with_array.py\u001b[0m in \u001b[0;36m_list_forward\u001b[0;34m(model, Xs, is_train)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray1i\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mXf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mYf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_dXf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdYs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList2d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/residual.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0md_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/chain.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, X, is_train)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[1;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Model\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/layernorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(model, X, is_train)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mXhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_begin_update_scale_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/thinc/layers/layernorm.py\u001b[0m in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloats2d\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFloats2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloats2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloats2d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m# TODO: Do mean methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mmu\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloats2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFloats2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-08\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFloats2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         ret = um.true_divide(\n\u001b[0m\u001b[1;32m    163\u001b[0m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from inflection import singularize, pluralize\n",
    "\n",
    "\n",
    "\n",
    "def read_anchors(path_sg, path_pl, anchor_source, debug=False):\n",
    "    '''\n",
    "    read the anchor files mined from singualr and plural\n",
    "    \n",
    "    args: \n",
    "        anchor_soure: using the anchors mined from singular probe or plural probe\n",
    "        \n",
    "    return: \n",
    "        dic_sub_to_anchors_singular: both sub_label and subj_anchors are singular \n",
    "        dic_sub_to_anchors_plural: both sub_label and subj_anchors are plural \n",
    "    '''\n",
    "    dfsg = pd.read_csv(path_sg)\n",
    "    dfsg['subj_anchors'] = dfsg['subj_anchors'].apply(lambda x: eval(x))\n",
    "    \n",
    "    dfpl = pd.read_csv(path_pl)\n",
    "    dfpl['subj_anchors'] = dfpl['subj_anchors'].apply(lambda x: eval(x))\n",
    "    \n",
    "    df = pd.merge(dfsg, dfpl, on = 'uuid', suffixes=('_sg', '_pl'))\n",
    "    \n",
    "    if debug: df = df.head(5)\n",
    "        \n",
    "    if anchor_source == 'plural':\n",
    "        #convert the singular anchors into singular format\n",
    "        df['subj_anchors_sg'] = df['subj_anchors_pl'].progress_apply(lambda x: [singularize(word) for word in x])\n",
    "    elif anchor_source == 'singular':\n",
    "        #convert the plural anchors into singular format\n",
    "        df['subj_anchors_pl'] = df['subj_anchors_sg'].progress_apply(lambda x: [pluralize(word) for word in x])\n",
    "\n",
    "    dic_sub_to_anchors_singular = dict(zip(df['sub_label_sg'], df['subj_anchors_sg']))\n",
    "    dic_sub_to_anchors_plural = dict(zip(df['sub_label_pl'], df['subj_anchors_pl']))\n",
    "    \n",
    "    return dic_sub_to_anchors_singular, dic_sub_to_anchors_plural\n",
    "\n",
    "\n",
    "path_anchor_sg = '../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg.csv'\n",
    "\n",
    "path_anchor_pl = '../log/bert-large-uncased/lm_diagnostic_extended/plural/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv'\n",
    "\n",
    "dic_sub_to_anchors_singular,dic_sub_to_anchors_plural = read_anchors(path_anchor_sg, path_anchor_pl, anchor_source='plural', debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>mask_sentences_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>mask_sentences_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>A graver is a [MASK].</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>gravers are [MASK].</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>A smallmouth is a [MASK].</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouths are [MASK].</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>A pelican is a [MASK].</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>pelicans are [MASK].</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>A sapsucker is a [MASK].</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>sapsuckers are [MASK].</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>A mako is a [MASK].</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>makoes are [MASK].</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular    mask_sentences_singular  \\\n",
       "0             graver               tool      A graver is a [MASK].   \n",
       "1         smallmouth               fish  A smallmouth is a [MASK].   \n",
       "2            pelican               bird     A pelican is a [MASK].   \n",
       "3          sapsucker               bird   A sapsucker is a [MASK].   \n",
       "4               mako               fish        A mako is a [MASK].   \n",
       "\n",
       "  sub_label_plural obj_label_plural    mask_sentences_plural  uuid relation  \n",
       "0          gravers            tools      gravers are [MASK].     1      IsA  \n",
       "1      smallmouths             fish  smallmouths are [MASK].     2      IsA  \n",
       "2         pelicans            birds     pelicans are [MASK].     3      IsA  \n",
       "3       sapsuckers            birds   sapsuckers are [MASK].     4      IsA  \n",
       "4           makoes             fish       makoes are [MASK].     5      IsA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended//singular_plural/IsA.jsonl with 576 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>mask_sentences_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>mask_sentences_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>A graver is a [MASK].</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>gravers are [MASK].</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>A smallmouth is a [MASK].</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouths are [MASK].</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>A pelican is a [MASK].</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>pelicans are [MASK].</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>A sapsucker is a [MASK].</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>sapsuckers are [MASK].</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>A mako is a [MASK].</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>makoes are [MASK].</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular    mask_sentences_singular  \\\n",
       "0             graver               tool      A graver is a [MASK].   \n",
       "1         smallmouth               fish  A smallmouth is a [MASK].   \n",
       "2            pelican               bird     A pelican is a [MASK].   \n",
       "3          sapsucker               bird   A sapsucker is a [MASK].   \n",
       "4               mako               fish        A mako is a [MASK].   \n",
       "\n",
       "  sub_label_plural obj_label_plural    mask_sentences_plural  uuid relation  \n",
       "0          gravers            tools      gravers are [MASK].     1      IsA  \n",
       "1      smallmouths             fish  smallmouths are [MASK].     2      IsA  \n",
       "2         pelicans            birds     pelicans are [MASK].     3      IsA  \n",
       "3       sapsuckers            birds   sapsuckers are [MASK].     4      IsA  \n",
       "4           makoes             fish       makoes are [MASK].     5      IsA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>mask_sentences_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>mask_sentences_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>A graver or [Z] is a [MASK].</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>gravers or [Z] are [MASK].</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>A smallmouth or [Z] is a [MASK].</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouths or [Z] are [MASK].</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>A pelican or [Z] is a [MASK].</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>pelicans or [Z] are [MASK].</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>A sapsucker or [Z] is a [MASK].</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>sapsuckers or [Z] are [MASK].</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>A mako or [Z] is a [MASK].</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>makoes or [Z] are [MASK].</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular           mask_sentences_singular  \\\n",
       "0             graver               tool      A graver or [Z] is a [MASK].   \n",
       "1         smallmouth               fish  A smallmouth or [Z] is a [MASK].   \n",
       "2            pelican               bird     A pelican or [Z] is a [MASK].   \n",
       "3          sapsucker               bird   A sapsucker or [Z] is a [MASK].   \n",
       "4               mako               fish        A mako or [Z] is a [MASK].   \n",
       "\n",
       "  sub_label_plural obj_label_plural           mask_sentences_plural  uuid  \\\n",
       "0          gravers            tools      gravers or [Z] are [MASK].     1   \n",
       "1      smallmouths             fish  smallmouths or [Z] are [MASK].     2   \n",
       "2         pelicans            birds     pelicans or [Z] are [MASK].     3   \n",
       "3       sapsuckers            birds   sapsuckers or [Z] are [MASK].     4   \n",
       "4           makoes             fish       makoes or [Z] are [MASK].     5   \n",
       "\n",
       "  relation  \n",
       "0      IsA  \n",
       "1      IsA  \n",
       "2      IsA  \n",
       "3      IsA  \n",
       "4      IsA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>mask_sentences_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>mask_sentences_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>[MASK] such as a graver.</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>[MASK] such as gravers.</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as a smallmouth.</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as smallmouths.</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>[MASK] such as a pelican.</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>[MASK] such as pelicans.</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>[MASK] such as a sapsucker.</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>[MASK] such as sapsuckers.</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as a mako.</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as makoes.</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular       mask_sentences_singular  \\\n",
       "0             graver               tool      [MASK] such as a graver.   \n",
       "1         smallmouth               fish  [MASK] such as a smallmouth.   \n",
       "2            pelican               bird     [MASK] such as a pelican.   \n",
       "3          sapsucker               bird   [MASK] such as a sapsucker.   \n",
       "4               mako               fish        [MASK] such as a mako.   \n",
       "\n",
       "  sub_label_plural obj_label_plural        mask_sentences_plural  uuid  \\\n",
       "0          gravers            tools      [MASK] such as gravers.     1   \n",
       "1      smallmouths             fish  [MASK] such as smallmouths.     2   \n",
       "2         pelicans            birds     [MASK] such as pelicans.     3   \n",
       "3       sapsuckers            birds   [MASK] such as sapsuckers.     4   \n",
       "4           makoes             fish       [MASK] such as makoes.     5   \n",
       "\n",
       "  relation  \n",
       "0      IsA  \n",
       "1      IsA  \n",
       "2      IsA  \n",
       "3      IsA  \n",
       "4      IsA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>mask_sentences_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>mask_sentences_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>[MASK] such as a graver or [Z].</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>[MASK] such as gravers or [Z].</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as a smallmouth or [Z].</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as smallmouths or [Z].</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>[MASK] such as a pelican or [Z].</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>[MASK] such as pelicans or [Z].</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>[MASK] such as a sapsucker or [Z].</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>[MASK] such as sapsuckers or [Z].</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as a mako or [Z].</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>[MASK] such as makoes or [Z].</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular              mask_sentences_singular  \\\n",
       "0             graver               tool      [MASK] such as a graver or [Z].   \n",
       "1         smallmouth               fish  [MASK] such as a smallmouth or [Z].   \n",
       "2            pelican               bird     [MASK] such as a pelican or [Z].   \n",
       "3          sapsucker               bird   [MASK] such as a sapsucker or [Z].   \n",
       "4               mako               fish        [MASK] such as a mako or [Z].   \n",
       "\n",
       "  sub_label_plural obj_label_plural               mask_sentences_plural  uuid  \\\n",
       "0          gravers            tools      [MASK] such as gravers or [Z].     1   \n",
       "1      smallmouths             fish  [MASK] such as smallmouths or [Z].     2   \n",
       "2         pelicans            birds     [MASK] such as pelicans or [Z].     3   \n",
       "3       sapsuckers            birds   [MASK] such as sapsuckers or [Z].     4   \n",
       "4           makoes             fish       [MASK] such as makoes or [Z].     5   \n",
       "\n",
       "  relation  \n",
       "0      IsA  \n",
       "1      IsA  \n",
       "2      IsA  \n",
       "3      IsA  \n",
       "4      IsA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency/IsA.def_sap.jsonl with 576 lines\n",
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency/IsA.def_dap.jsonl with 576 lines\n",
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency/IsA.lsp_sap.jsonl with 576 lines\n",
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency/IsA.lsp_dap.jsonl with 576 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>mask_sentences_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>mask_sentences_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "      <th>subj_anchors_singular</th>\n",
       "      <th>subj_anchors_plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>[[MASK] such as a graver or marker., [MASK] such as a graver or tomb., [MASK] such as a graver or grave., [MASK] such as a graver or body., [MASK] such as a graver or murderer.]</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>[[MASK] such as gravers or markers., [MASK] such as gravers or tombs., [MASK] such as gravers or graves., [MASK] such as gravers or bodies., [MASK] such as gravers or murderers.]</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[marker, tomb, grave, body, murderer]</td>\n",
       "      <td>[markers, tombs, graves, bodies, murderers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>[[MASK] such as a smallmouth or catfish., [MASK] such as a smallmouth or carp., [MASK] such as a smallmouth or bass., [MASK] such as a smallmouth or pike., [MASK] such as a smallmouth or perch.]</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>[[MASK] such as smallmouths or catfish., [MASK] such as smallmouths or carp., [MASK] such as smallmouths or bass., [MASK] such as smallmouths or pike., [MASK] such as smallmouths or perch.]</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[catfish, carp, bass, pike, perch]</td>\n",
       "      <td>[catfish, carp, bass, pike, perch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>[[MASK] such as a pelican or dolphin., [MASK] such as a pelican or penguin., [MASK] such as a pelican or duck., [MASK] such as a pelican or crane., [MASK] such as a pelican or eagle.]</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>[[MASK] such as pelicans or dolphins., [MASK] such as pelicans or penguins., [MASK] such as pelicans or ducks., [MASK] such as pelicans or cranes., [MASK] such as pelicans or eagles.]</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[dolphin, penguin, duck, crane, eagle]</td>\n",
       "      <td>[dolphins, penguins, ducks, cranes, eagles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>[[MASK] such as a sapsucker or snake., [MASK] such as a sapsucker or spider., [MASK] such as a sapsucker or frog., [MASK] such as a sapsucker or monster., [MASK] such as a sapsucker or lizard.]</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>[[MASK] such as sapsuckers or snakes., [MASK] such as sapsuckers or spiders., [MASK] such as sapsuckers or frogs., [MASK] such as sapsuckers or monsters., [MASK] such as sapsuckers or lizards.]</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[snake, spider, frog, monster, lizard]</td>\n",
       "      <td>[snakes, spiders, frogs, monsters, lizards]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>[[MASK] such as a mako or human., [MASK] such as a mako or tribe., [MASK] such as a mako or slave., [MASK] such as a mako or man., [MASK] such as a mako or peter.]</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>[[MASK] such as makoes or human., [MASK] such as makoes or tribe., [MASK] such as makoes or slaves., [MASK] such as makoes or man., [MASK] such as makoes or peter.]</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[human, tribe, slave, man, peter]</td>\n",
       "      <td>[human, tribe, slaves, man, peter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular  \\\n",
       "0             graver               tool   \n",
       "1         smallmouth               fish   \n",
       "2            pelican               bird   \n",
       "3          sapsucker               bird   \n",
       "4               mako               fish   \n",
       "\n",
       "                                                                                                                                                                              mask_sentences_singular  \\\n",
       "0                   [[MASK] such as a graver or marker., [MASK] such as a graver or tomb., [MASK] such as a graver or grave., [MASK] such as a graver or body., [MASK] such as a graver or murderer.]   \n",
       "1  [[MASK] such as a smallmouth or catfish., [MASK] such as a smallmouth or carp., [MASK] such as a smallmouth or bass., [MASK] such as a smallmouth or pike., [MASK] such as a smallmouth or perch.]   \n",
       "2             [[MASK] such as a pelican or dolphin., [MASK] such as a pelican or penguin., [MASK] such as a pelican or duck., [MASK] such as a pelican or crane., [MASK] such as a pelican or eagle.]   \n",
       "3   [[MASK] such as a sapsucker or snake., [MASK] such as a sapsucker or spider., [MASK] such as a sapsucker or frog., [MASK] such as a sapsucker or monster., [MASK] such as a sapsucker or lizard.]   \n",
       "4                                 [[MASK] such as a mako or human., [MASK] such as a mako or tribe., [MASK] such as a mako or slave., [MASK] such as a mako or man., [MASK] such as a mako or peter.]   \n",
       "\n",
       "  sub_label_plural obj_label_plural  \\\n",
       "0          gravers            tools   \n",
       "1      smallmouths             fish   \n",
       "2         pelicans            birds   \n",
       "3       sapsuckers            birds   \n",
       "4           makoes             fish   \n",
       "\n",
       "                                                                                                                                                                               mask_sentences_plural  \\\n",
       "0                 [[MASK] such as gravers or markers., [MASK] such as gravers or tombs., [MASK] such as gravers or graves., [MASK] such as gravers or bodies., [MASK] such as gravers or murderers.]   \n",
       "1      [[MASK] such as smallmouths or catfish., [MASK] such as smallmouths or carp., [MASK] such as smallmouths or bass., [MASK] such as smallmouths or pike., [MASK] such as smallmouths or perch.]   \n",
       "2            [[MASK] such as pelicans or dolphins., [MASK] such as pelicans or penguins., [MASK] such as pelicans or ducks., [MASK] such as pelicans or cranes., [MASK] such as pelicans or eagles.]   \n",
       "3  [[MASK] such as sapsuckers or snakes., [MASK] such as sapsuckers or spiders., [MASK] such as sapsuckers or frogs., [MASK] such as sapsuckers or monsters., [MASK] such as sapsuckers or lizards.]   \n",
       "4                               [[MASK] such as makoes or human., [MASK] such as makoes or tribe., [MASK] such as makoes or slaves., [MASK] such as makoes or man., [MASK] such as makoes or peter.]   \n",
       "\n",
       "   uuid relation                   subj_anchors_singular  \\\n",
       "0     1      IsA   [marker, tomb, grave, body, murderer]   \n",
       "1     2      IsA      [catfish, carp, bass, pike, perch]   \n",
       "2     3      IsA  [dolphin, penguin, duck, crane, eagle]   \n",
       "3     4      IsA  [snake, spider, frog, monster, lizard]   \n",
       "4     5      IsA       [human, tribe, slave, man, peter]   \n",
       "\n",
       "                           subj_anchors_plural  \n",
       "0  [markers, tombs, graves, bodies, murderers]  \n",
       "1           [catfish, carp, bass, pike, perch]  \n",
       "2  [dolphins, penguins, ducks, cranes, eagles]  \n",
       "3  [snakes, spiders, frogs, monsters, lizards]  \n",
       "4           [human, tribe, slaves, man, peter]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insert_anchors(dic_sub_to_anchors, df, mask_col, sub_col, anchor_col, probe_type, article_for_z=False):\n",
    "    df[mask_col].head()\n",
    "    df[anchor_col] = df[sub_col].apply(lambda x: dic_sub_to_anchors.get(x) )\n",
    "    \n",
    "    if probe_type =='plural':\n",
    "        df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', anchor)  for anchor in x[0]], axis=1)\n",
    "    elif probe_type == 'singular':\n",
    "        if article_for_z: \n",
    "           df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', \"{} {}\".format(_get_article(anchor), anchor))  for anchor in x[0]], axis=1) \n",
    "        else:\n",
    "            df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', anchor)  for anchor in x[0]], axis=1) \n",
    "            \n",
    "    return df \n",
    "\n",
    "\n",
    "# create the dataset \n",
    "data_dir = '../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/' \n",
    "file = 'singular_plural.tsv'\n",
    "df_def_sap = definition_sap_singular_plural(data_dir, file)\n",
    "df_def_dap = definition_dap_singular_plural(deepcopy(df_def_sap))\n",
    "df_lsp_sap = lsp_sap_singular_plural(deepcopy(df_def_sap))\n",
    "df_lsp_dap = lsp_dap_singular_plural(deepcopy(df_def_sap))\n",
    "\n",
    "display(df_def_sap.head())\n",
    "display(df_def_dap.head())\n",
    "display(df_lsp_sap.head())\n",
    "display(df_lsp_dap.head())\n",
    "\n",
    "df_def_dap = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_singular, df= df_def_dap, mask_col = 'mask_sentences_singular', sub_col = 'sub_label_singular', anchor_col='subj_anchors_singular', probe_type='singular',article_for_z=False)\n",
    "\n",
    "df_lsp_dap = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_singular, df= df_lsp_dap, mask_col = 'mask_sentences_singular', sub_col = 'sub_label_singular', anchor_col='subj_anchors_singular', probe_type = 'singular', article_for_z=False)\n",
    "\n",
    "df_lsp_dap[['sub_label_singular', 'subj_anchors_singular', 'mask_sentences_singular']].head() #''\n",
    "\n",
    "\n",
    "\n",
    "# dic_sub_to_anchors_plural = read_anchors(path_anchor_pl)\n",
    "df_def_dap = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_plural, df= df_def_dap, mask_col = 'mask_sentences_plural', sub_col = 'sub_label_plural', anchor_col='subj_anchors_plural', probe_type='plural')\n",
    "\n",
    "df_lsp_dap = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_plural, df= df_lsp_dap, mask_col = 'mask_sentences_plural', sub_col = 'sub_label_plural', anchor_col='subj_anchors_plural', probe_type='plural')\n",
    "\n",
    "df_lsp_dap[['sub_label_plural', 'subj_anchors_plural', 'mask_sentences_plural']].head() #''\n",
    "\n",
    "\n",
    "# save files \n",
    "out_dir = '../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency/'\n",
    "save_dict_to_json(examples=df_def_sap.to_dict(orient='records'), output_path=out_dir + 'IsA.def_sap.jsonl') \n",
    "save_dict_to_json(examples=df_def_dap.to_dict(orient='records'), output_path=out_dir + 'IsA.def_dap.jsonl') \n",
    "save_dict_to_json(examples=df_lsp_sap.to_dict(orient='records'), output_path=out_dir + 'IsA.lsp_sap.jsonl') \n",
    "save_dict_to_json(examples=df_lsp_dap.to_dict(orient='records'), output_path=out_dir + 'IsA.lsp_dap.jsonl') \n",
    "\n",
    "\n",
    "df_def_sap.to_csv(out_dir + 'IsA.def_sap.csv') \n",
    "df_def_dap.to_csv(out_dir + 'IsA.def_dap.csv') \n",
    "df_lsp_sap.to_csv(out_dir + 'IsA.lsp_sap.csv') \n",
    "df_lsp_dap.to_csv(out_dir + 'IsA.lsp_dap.csv')\n",
    "df_lsp_dap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "IsA.def_sap.csv                               100%   50KB   5.7MB/s   00:00    \n",
      "IsA.lsp_dap.jsonl                             100%  422KB  65.5MB/s   00:00    \n",
      "IsA.lsp_sap.csv                               100%   53KB  32.7MB/s   00:00    \n",
      "IsA.def_sap.jsonl                             100%  148KB  60.3MB/s   00:00    \n",
      "IsA.def_dap.jsonl                             100%  403KB  69.7MB/s   00:00    \n",
      "IsA.lsp_sap.jsonl                             100%  152KB  69.2MB/s   00:00    \n",
      "IsA.lsp_dap-checkpoint.csv                    100%  298KB  68.0MB/s   00:00    \n",
      "IsA.def_dap-checkpoint.csv                    100%  284KB  72.9MB/s   00:00    \n",
      "IsA.lsp_dap-checkpoint.jsonl                  100%  418KB  77.3MB/s   00:00    \n",
      "IsA.lsp_sap-checkpoint.csv                    100%  148   156.9KB/s   00:00    \n",
      "IsA.def_dap-checkpoint.jsonl                  100%  405KB  77.2MB/s   00:00    \n",
      "IsA.lsp_dap.csv                               100%  303KB  62.4MB/s   00:00    \n",
      "IsA.def_dap.csv                               100%  283KB  61.5MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "!scp -r ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency spartan:/home/chunhua/cogsci/DAP/data/lm_diagnostic_extended/\n",
    "# !ls ../\n",
    "# df_lsp_sap.head()\n",
    "# df_lsp_dap.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for checking group consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>mask_sentences_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>mask_sentences_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>A graver is a [MASK].</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>gravers are [MASK].</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>A smallmouth is a [MASK].</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouths are [MASK].</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>A pelican is a [MASK].</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>pelicans are [MASK].</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>A sapsucker is a [MASK].</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>sapsuckers are [MASK].</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>A mako is a [MASK].</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>makoes are [MASK].</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular    mask_sentences_singular  \\\n",
       "0             graver               tool      A graver is a [MASK].   \n",
       "1         smallmouth               fish  A smallmouth is a [MASK].   \n",
       "2            pelican               bird     A pelican is a [MASK].   \n",
       "3          sapsucker               bird   A sapsucker is a [MASK].   \n",
       "4               mako               fish        A mako is a [MASK].   \n",
       "\n",
       "  sub_label_plural obj_label_plural    mask_sentences_plural  uuid relation  \n",
       "0          gravers            tools      gravers are [MASK].     1      IsA  \n",
       "1      smallmouths             fish  smallmouths are [MASK].     2      IsA  \n",
       "2         pelicans            birds     pelicans are [MASK].     3      IsA  \n",
       "3       sapsuckers            birds   sapsuckers are [MASK].     4      IsA  \n",
       "4           makoes             fish       makoes are [MASK].     5      IsA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended//singular_plural/IsA.jsonl with 576 lines\n",
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency_group/IsA.lsp_sap.jsonl with 576 lines\n",
      "save ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency_group/IsA.lsp_dap.jsonl with 576 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "      <th>mask_sentences_singular_1</th>\n",
       "      <th>mask_sentences_singular_2</th>\n",
       "      <th>mask_sentences_singular_3</th>\n",
       "      <th>mask_sentences_singular_4</th>\n",
       "      <th>mask_sentences_singular_5</th>\n",
       "      <th>mask_sentences_singular_6</th>\n",
       "      <th>mask_sentences_plural_1</th>\n",
       "      <th>mask_sentences_plural_2</th>\n",
       "      <th>mask_sentences_plural_3</th>\n",
       "      <th>mask_sentences_plural_4</th>\n",
       "      <th>mask_sentences_plural_5</th>\n",
       "      <th>mask_sentences_plural_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as a graver.</td>\n",
       "      <td>[MASK], including a graver.</td>\n",
       "      <td>[MASK], especially a graver.</td>\n",
       "      <td>a graver or other [MASK].</td>\n",
       "      <td>a graver and other [MASK].</td>\n",
       "      <td>such [MASK] as a graver.</td>\n",
       "      <td>[MASK] such as gravers.</td>\n",
       "      <td>[MASK], including gravers.</td>\n",
       "      <td>[MASK], especially gravers.</td>\n",
       "      <td>gravers or other [MASK].</td>\n",
       "      <td>gravers and other [MASK].</td>\n",
       "      <td>such [MASK] as gravers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as a smallmouth.</td>\n",
       "      <td>[MASK], including a smallmouth.</td>\n",
       "      <td>[MASK], especially a smallmouth.</td>\n",
       "      <td>a smallmouth or other [MASK].</td>\n",
       "      <td>a smallmouth and other [MASK].</td>\n",
       "      <td>such [MASK] as a smallmouth.</td>\n",
       "      <td>[MASK] such as smallmouths.</td>\n",
       "      <td>[MASK], including smallmouths.</td>\n",
       "      <td>[MASK], especially smallmouths.</td>\n",
       "      <td>smallmouths or other [MASK].</td>\n",
       "      <td>smallmouths and other [MASK].</td>\n",
       "      <td>such [MASK] as smallmouths.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as a pelican.</td>\n",
       "      <td>[MASK], including a pelican.</td>\n",
       "      <td>[MASK], especially a pelican.</td>\n",
       "      <td>a pelican or other [MASK].</td>\n",
       "      <td>a pelican and other [MASK].</td>\n",
       "      <td>such [MASK] as a pelican.</td>\n",
       "      <td>[MASK] such as pelicans.</td>\n",
       "      <td>[MASK], including pelicans.</td>\n",
       "      <td>[MASK], especially pelicans.</td>\n",
       "      <td>pelicans or other [MASK].</td>\n",
       "      <td>pelicans and other [MASK].</td>\n",
       "      <td>such [MASK] as pelicans.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as a sapsucker.</td>\n",
       "      <td>[MASK], including a sapsucker.</td>\n",
       "      <td>[MASK], especially a sapsucker.</td>\n",
       "      <td>a sapsucker or other [MASK].</td>\n",
       "      <td>a sapsucker and other [MASK].</td>\n",
       "      <td>such [MASK] as a sapsucker.</td>\n",
       "      <td>[MASK] such as sapsuckers.</td>\n",
       "      <td>[MASK], including sapsuckers.</td>\n",
       "      <td>[MASK], especially sapsuckers.</td>\n",
       "      <td>sapsuckers or other [MASK].</td>\n",
       "      <td>sapsuckers and other [MASK].</td>\n",
       "      <td>such [MASK] as sapsuckers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as a mako.</td>\n",
       "      <td>[MASK], including a mako.</td>\n",
       "      <td>[MASK], especially a mako.</td>\n",
       "      <td>a mako or other [MASK].</td>\n",
       "      <td>a mako and other [MASK].</td>\n",
       "      <td>such [MASK] as a mako.</td>\n",
       "      <td>[MASK] such as makoes.</td>\n",
       "      <td>[MASK], including makoes.</td>\n",
       "      <td>[MASK], especially makoes.</td>\n",
       "      <td>makoes or other [MASK].</td>\n",
       "      <td>makoes and other [MASK].</td>\n",
       "      <td>such [MASK] as makoes.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular sub_label_plural obj_label_plural  \\\n",
       "0             graver               tool          gravers            tools   \n",
       "1         smallmouth               fish      smallmouths             fish   \n",
       "2            pelican               bird         pelicans            birds   \n",
       "3          sapsucker               bird       sapsuckers            birds   \n",
       "4               mako               fish           makoes             fish   \n",
       "\n",
       "   uuid relation     mask_sentences_singular_1  \\\n",
       "0     1      IsA      [MASK] such as a graver.   \n",
       "1     2      IsA  [MASK] such as a smallmouth.   \n",
       "2     3      IsA     [MASK] such as a pelican.   \n",
       "3     4      IsA   [MASK] such as a sapsucker.   \n",
       "4     5      IsA        [MASK] such as a mako.   \n",
       "\n",
       "         mask_sentences_singular_2         mask_sentences_singular_3  \\\n",
       "0      [MASK], including a graver.      [MASK], especially a graver.   \n",
       "1  [MASK], including a smallmouth.  [MASK], especially a smallmouth.   \n",
       "2     [MASK], including a pelican.     [MASK], especially a pelican.   \n",
       "3   [MASK], including a sapsucker.   [MASK], especially a sapsucker.   \n",
       "4        [MASK], including a mako.        [MASK], especially a mako.   \n",
       "\n",
       "       mask_sentences_singular_4       mask_sentences_singular_5  \\\n",
       "0      a graver or other [MASK].      a graver and other [MASK].   \n",
       "1  a smallmouth or other [MASK].  a smallmouth and other [MASK].   \n",
       "2     a pelican or other [MASK].     a pelican and other [MASK].   \n",
       "3   a sapsucker or other [MASK].   a sapsucker and other [MASK].   \n",
       "4        a mako or other [MASK].        a mako and other [MASK].   \n",
       "\n",
       "      mask_sentences_singular_6      mask_sentences_plural_1  \\\n",
       "0      such [MASK] as a graver.      [MASK] such as gravers.   \n",
       "1  such [MASK] as a smallmouth.  [MASK] such as smallmouths.   \n",
       "2     such [MASK] as a pelican.     [MASK] such as pelicans.   \n",
       "3   such [MASK] as a sapsucker.   [MASK] such as sapsuckers.   \n",
       "4        such [MASK] as a mako.       [MASK] such as makoes.   \n",
       "\n",
       "          mask_sentences_plural_2          mask_sentences_plural_3  \\\n",
       "0      [MASK], including gravers.      [MASK], especially gravers.   \n",
       "1  [MASK], including smallmouths.  [MASK], especially smallmouths.   \n",
       "2     [MASK], including pelicans.     [MASK], especially pelicans.   \n",
       "3   [MASK], including sapsuckers.   [MASK], especially sapsuckers.   \n",
       "4       [MASK], including makoes.       [MASK], especially makoes.   \n",
       "\n",
       "        mask_sentences_plural_4        mask_sentences_plural_5  \\\n",
       "0      gravers or other [MASK].      gravers and other [MASK].   \n",
       "1  smallmouths or other [MASK].  smallmouths and other [MASK].   \n",
       "2     pelicans or other [MASK].     pelicans and other [MASK].   \n",
       "3   sapsuckers or other [MASK].   sapsuckers and other [MASK].   \n",
       "4       makoes or other [MASK].       makoes and other [MASK].   \n",
       "\n",
       "       mask_sentences_plural_6  \n",
       "0      such [MASK] as gravers.  \n",
       "1  such [MASK] as smallmouths.  \n",
       "2     such [MASK] as pelicans.  \n",
       "3   such [MASK] as sapsuckers.  \n",
       "4       such [MASK] as makoes.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "      <th>mask_sentences_singular_1</th>\n",
       "      <th>mask_sentences_singular_2</th>\n",
       "      <th>mask_sentences_singular_3</th>\n",
       "      <th>mask_sentences_singular_4</th>\n",
       "      <th>mask_sentences_singular_5</th>\n",
       "      <th>mask_sentences_singular_6</th>\n",
       "      <th>mask_sentences_plural_1</th>\n",
       "      <th>mask_sentences_plural_2</th>\n",
       "      <th>mask_sentences_plural_3</th>\n",
       "      <th>mask_sentences_plural_4</th>\n",
       "      <th>mask_sentences_plural_5</th>\n",
       "      <th>mask_sentences_plural_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graver</td>\n",
       "      <td>tool</td>\n",
       "      <td>gravers</td>\n",
       "      <td>tools</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[[MASK] such as a graver and marker., [MASK] such as a graver and tomb., [MASK] such as a graver and grafe., [MASK] such as a graver and body., [MASK] such as a graver and murderer.]</td>\n",
       "      <td>[[MASK], including a graver and marker., [MASK], including a graver and tomb., [MASK], including a graver and grafe., [MASK], including a graver and body., [MASK], including a graver and murderer.]</td>\n",
       "      <td>[[MASK], especially a graver and marker., [MASK], especially a graver and tomb., [MASK], especially a graver and grafe., [MASK], especially a graver and body., [MASK], especially a graver and murderer.]</td>\n",
       "      <td>[a graver, marker and other [MASK]., a graver, tomb and other [MASK]., a graver, grafe and other [MASK]., a graver, body and other [MASK]., a graver, murderer and other [MASK].]</td>\n",
       "      <td>[a graver, marker or other [MASK]., a graver, tomb or other [MASK]., a graver, grafe or other [MASK]., a graver, body or other [MASK]., a graver, murderer or other [MASK].]</td>\n",
       "      <td>[such [MASK] as a graver and marker., such [MASK] as a graver and tomb., such [MASK] as a graver and grafe., such [MASK] as a graver and body., such [MASK] as a graver and murderer.]</td>\n",
       "      <td>[[MASK] such as gravers and markers., [MASK] such as gravers and tombs., [MASK] such as gravers and graves., [MASK] such as gravers and bodies., [MASK] such as gravers and murderers.]</td>\n",
       "      <td>[[MASK], including gravers and markers., [MASK], including gravers and tombs., [MASK], including gravers and graves., [MASK], including gravers and bodies., [MASK], including gravers and murderers.]</td>\n",
       "      <td>[[MASK], especially gravers and markers., [MASK], especially gravers and tombs., [MASK], especially gravers and graves., [MASK], especially gravers and bodies., [MASK], especially gravers and murderers.]</td>\n",
       "      <td>[gravers, markers and other [MASK]., gravers, tombs and other [MASK]., gravers, graves and other [MASK]., gravers, bodies and other [MASK]., gravers, murderers and other [MASK].]</td>\n",
       "      <td>[gravers, markers or other [MASK]., gravers, tombs or other [MASK]., gravers, graves or other [MASK]., gravers, bodies or other [MASK]., gravers, murderers or other [MASK].]</td>\n",
       "      <td>[such [MASK] as gravers and markers., such [MASK] as gravers and tombs., such [MASK] as gravers and graves., such [MASK] as gravers and bodies., such [MASK] as gravers and murderers.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smallmouth</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>fish</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[[MASK] such as a smallmouth and catfish., [MASK] such as a smallmouth and carp., [MASK] such as a smallmouth and bass., [MASK] such as a smallmouth and pike., [MASK] such as a smallmouth and perch.]</td>\n",
       "      <td>[[MASK], including a smallmouth and catfish., [MASK], including a smallmouth and carp., [MASK], including a smallmouth and bass., [MASK], including a smallmouth and pike., [MASK], including a smallmouth and perch.]</td>\n",
       "      <td>[[MASK], especially a smallmouth and catfish., [MASK], especially a smallmouth and carp., [MASK], especially a smallmouth and bass., [MASK], especially a smallmouth and pike., [MASK], especially a smallmouth and perch.]</td>\n",
       "      <td>[a smallmouth, catfish and other [MASK]., a smallmouth, carp and other [MASK]., a smallmouth, bass and other [MASK]., a smallmouth, pike and other [MASK]., a smallmouth, perch and other [MASK].]</td>\n",
       "      <td>[a smallmouth, catfish or other [MASK]., a smallmouth, carp or other [MASK]., a smallmouth, bass or other [MASK]., a smallmouth, pike or other [MASK]., a smallmouth, perch or other [MASK].]</td>\n",
       "      <td>[such [MASK] as a smallmouth and catfish., such [MASK] as a smallmouth and carp., such [MASK] as a smallmouth and bass., such [MASK] as a smallmouth and pike., such [MASK] as a smallmouth and perch.]</td>\n",
       "      <td>[[MASK] such as smallmouths and catfish., [MASK] such as smallmouths and carp., [MASK] such as smallmouths and bass., [MASK] such as smallmouths and pike., [MASK] such as smallmouths and perch.]</td>\n",
       "      <td>[[MASK], including smallmouths and catfish., [MASK], including smallmouths and carp., [MASK], including smallmouths and bass., [MASK], including smallmouths and pike., [MASK], including smallmouths and perch.]</td>\n",
       "      <td>[[MASK], especially smallmouths and catfish., [MASK], especially smallmouths and carp., [MASK], especially smallmouths and bass., [MASK], especially smallmouths and pike., [MASK], especially smallmouths and perch.]</td>\n",
       "      <td>[smallmouths, catfish and other [MASK]., smallmouths, carp and other [MASK]., smallmouths, bass and other [MASK]., smallmouths, pike and other [MASK]., smallmouths, perch and other [MASK].]</td>\n",
       "      <td>[smallmouths, catfish or other [MASK]., smallmouths, carp or other [MASK]., smallmouths, bass or other [MASK]., smallmouths, pike or other [MASK]., smallmouths, perch or other [MASK].]</td>\n",
       "      <td>[such [MASK] as smallmouths and catfish., such [MASK] as smallmouths and carp., such [MASK] as smallmouths and bass., such [MASK] as smallmouths and pike., such [MASK] as smallmouths and perch.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pelican</td>\n",
       "      <td>bird</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>birds</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[[MASK] such as a pelican and dolphin., [MASK] such as a pelican and penguin., [MASK] such as a pelican and duck., [MASK] such as a pelican and crane., [MASK] such as a pelican and eagle.]</td>\n",
       "      <td>[[MASK], including a pelican and dolphin., [MASK], including a pelican and penguin., [MASK], including a pelican and duck., [MASK], including a pelican and crane., [MASK], including a pelican and eagle.]</td>\n",
       "      <td>[[MASK], especially a pelican and dolphin., [MASK], especially a pelican and penguin., [MASK], especially a pelican and duck., [MASK], especially a pelican and crane., [MASK], especially a pelican and eagle.]</td>\n",
       "      <td>[a pelican, dolphin and other [MASK]., a pelican, penguin and other [MASK]., a pelican, duck and other [MASK]., a pelican, crane and other [MASK]., a pelican, eagle and other [MASK].]</td>\n",
       "      <td>[a pelican, dolphin or other [MASK]., a pelican, penguin or other [MASK]., a pelican, duck or other [MASK]., a pelican, crane or other [MASK]., a pelican, eagle or other [MASK].]</td>\n",
       "      <td>[such [MASK] as a pelican and dolphin., such [MASK] as a pelican and penguin., such [MASK] as a pelican and duck., such [MASK] as a pelican and crane., such [MASK] as a pelican and eagle.]</td>\n",
       "      <td>[[MASK] such as pelicans and dolphins., [MASK] such as pelicans and penguins., [MASK] such as pelicans and ducks., [MASK] such as pelicans and cranes., [MASK] such as pelicans and eagles.]</td>\n",
       "      <td>[[MASK], including pelicans and dolphins., [MASK], including pelicans and penguins., [MASK], including pelicans and ducks., [MASK], including pelicans and cranes., [MASK], including pelicans and eagles.]</td>\n",
       "      <td>[[MASK], especially pelicans and dolphins., [MASK], especially pelicans and penguins., [MASK], especially pelicans and ducks., [MASK], especially pelicans and cranes., [MASK], especially pelicans and eagles.]</td>\n",
       "      <td>[pelicans, dolphins and other [MASK]., pelicans, penguins and other [MASK]., pelicans, ducks and other [MASK]., pelicans, cranes and other [MASK]., pelicans, eagles and other [MASK].]</td>\n",
       "      <td>[pelicans, dolphins or other [MASK]., pelicans, penguins or other [MASK]., pelicans, ducks or other [MASK]., pelicans, cranes or other [MASK]., pelicans, eagles or other [MASK].]</td>\n",
       "      <td>[such [MASK] as pelicans and dolphins., such [MASK] as pelicans and penguins., such [MASK] as pelicans and ducks., such [MASK] as pelicans and cranes., such [MASK] as pelicans and eagles.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sapsucker</td>\n",
       "      <td>bird</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>birds</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[[MASK] such as a sapsucker and snake., [MASK] such as a sapsucker and spider., [MASK] such as a sapsucker and frog., [MASK] such as a sapsucker and monster., [MASK] such as a sapsucker and lizard.]</td>\n",
       "      <td>[[MASK], including a sapsucker and snake., [MASK], including a sapsucker and spider., [MASK], including a sapsucker and frog., [MASK], including a sapsucker and monster., [MASK], including a sapsucker and lizard.]</td>\n",
       "      <td>[[MASK], especially a sapsucker and snake., [MASK], especially a sapsucker and spider., [MASK], especially a sapsucker and frog., [MASK], especially a sapsucker and monster., [MASK], especially a sapsucker and lizard.]</td>\n",
       "      <td>[a sapsucker, snake and other [MASK]., a sapsucker, spider and other [MASK]., a sapsucker, frog and other [MASK]., a sapsucker, monster and other [MASK]., a sapsucker, lizard and other [MASK].]</td>\n",
       "      <td>[a sapsucker, snake or other [MASK]., a sapsucker, spider or other [MASK]., a sapsucker, frog or other [MASK]., a sapsucker, monster or other [MASK]., a sapsucker, lizard or other [MASK].]</td>\n",
       "      <td>[such [MASK] as a sapsucker and snake., such [MASK] as a sapsucker and spider., such [MASK] as a sapsucker and frog., such [MASK] as a sapsucker and monster., such [MASK] as a sapsucker and lizard.]</td>\n",
       "      <td>[[MASK] such as sapsuckers and snakes., [MASK] such as sapsuckers and spiders., [MASK] such as sapsuckers and frogs., [MASK] such as sapsuckers and monsters., [MASK] such as sapsuckers and lizards.]</td>\n",
       "      <td>[[MASK], including sapsuckers and snakes., [MASK], including sapsuckers and spiders., [MASK], including sapsuckers and frogs., [MASK], including sapsuckers and monsters., [MASK], including sapsuckers and lizards.]</td>\n",
       "      <td>[[MASK], especially sapsuckers and snakes., [MASK], especially sapsuckers and spiders., [MASK], especially sapsuckers and frogs., [MASK], especially sapsuckers and monsters., [MASK], especially sapsuckers and lizards.]</td>\n",
       "      <td>[sapsuckers, snakes and other [MASK]., sapsuckers, spiders and other [MASK]., sapsuckers, frogs and other [MASK]., sapsuckers, monsters and other [MASK]., sapsuckers, lizards and other [MASK].]</td>\n",
       "      <td>[sapsuckers, snakes or other [MASK]., sapsuckers, spiders or other [MASK]., sapsuckers, frogs or other [MASK]., sapsuckers, monsters or other [MASK]., sapsuckers, lizards or other [MASK].]</td>\n",
       "      <td>[such [MASK] as sapsuckers and snakes., such [MASK] as sapsuckers and spiders., such [MASK] as sapsuckers and frogs., such [MASK] as sapsuckers and monsters., such [MASK] as sapsuckers and lizards.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mako</td>\n",
       "      <td>fish</td>\n",
       "      <td>makoes</td>\n",
       "      <td>fish</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[[MASK] such as a mako and human., [MASK] such as a mako and tribe., [MASK] such as a mako and slafe., [MASK] such as a mako and man., [MASK] such as a mako and peter.]</td>\n",
       "      <td>[[MASK], including a mako and human., [MASK], including a mako and tribe., [MASK], including a mako and slafe., [MASK], including a mako and man., [MASK], including a mako and peter.]</td>\n",
       "      <td>[[MASK], especially a mako and human., [MASK], especially a mako and tribe., [MASK], especially a mako and slafe., [MASK], especially a mako and man., [MASK], especially a mako and peter.]</td>\n",
       "      <td>[a mako, human and other [MASK]., a mako, tribe and other [MASK]., a mako, slafe and other [MASK]., a mako, man and other [MASK]., a mako, peter and other [MASK].]</td>\n",
       "      <td>[a mako, human or other [MASK]., a mako, tribe or other [MASK]., a mako, slafe or other [MASK]., a mako, man or other [MASK]., a mako, peter or other [MASK].]</td>\n",
       "      <td>[such [MASK] as a mako and human., such [MASK] as a mako and tribe., such [MASK] as a mako and slafe., such [MASK] as a mako and man., such [MASK] as a mako and peter.]</td>\n",
       "      <td>[[MASK] such as makoes and human., [MASK] such as makoes and tribe., [MASK] such as makoes and slaves., [MASK] such as makoes and man., [MASK] such as makoes and peter.]</td>\n",
       "      <td>[[MASK], including makoes and human., [MASK], including makoes and tribe., [MASK], including makoes and slaves., [MASK], including makoes and man., [MASK], including makoes and peter.]</td>\n",
       "      <td>[[MASK], especially makoes and human., [MASK], especially makoes and tribe., [MASK], especially makoes and slaves., [MASK], especially makoes and man., [MASK], especially makoes and peter.]</td>\n",
       "      <td>[makoes, human and other [MASK]., makoes, tribe and other [MASK]., makoes, slaves and other [MASK]., makoes, man and other [MASK]., makoes, peter and other [MASK].]</td>\n",
       "      <td>[makoes, human or other [MASK]., makoes, tribe or other [MASK]., makoes, slaves or other [MASK]., makoes, man or other [MASK]., makoes, peter or other [MASK].]</td>\n",
       "      <td>[such [MASK] as makoes and human., such [MASK] as makoes and tribe., such [MASK] as makoes and slaves., such [MASK] as makoes and man., such [MASK] as makoes and peter.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label_singular obj_label_singular sub_label_plural obj_label_plural  \\\n",
       "0             graver               tool          gravers            tools   \n",
       "1         smallmouth               fish      smallmouths             fish   \n",
       "2            pelican               bird         pelicans            birds   \n",
       "3          sapsucker               bird       sapsuckers            birds   \n",
       "4               mako               fish           makoes             fish   \n",
       "\n",
       "   uuid relation  \\\n",
       "0     1      IsA   \n",
       "1     2      IsA   \n",
       "2     3      IsA   \n",
       "3     4      IsA   \n",
       "4     5      IsA   \n",
       "\n",
       "                                                                                                                                                                                 mask_sentences_singular_1  \\\n",
       "0                   [[MASK] such as a graver and marker., [MASK] such as a graver and tomb., [MASK] such as a graver and grafe., [MASK] such as a graver and body., [MASK] such as a graver and murderer.]   \n",
       "1  [[MASK] such as a smallmouth and catfish., [MASK] such as a smallmouth and carp., [MASK] such as a smallmouth and bass., [MASK] such as a smallmouth and pike., [MASK] such as a smallmouth and perch.]   \n",
       "2             [[MASK] such as a pelican and dolphin., [MASK] such as a pelican and penguin., [MASK] such as a pelican and duck., [MASK] such as a pelican and crane., [MASK] such as a pelican and eagle.]   \n",
       "3   [[MASK] such as a sapsucker and snake., [MASK] such as a sapsucker and spider., [MASK] such as a sapsucker and frog., [MASK] such as a sapsucker and monster., [MASK] such as a sapsucker and lizard.]   \n",
       "4                                 [[MASK] such as a mako and human., [MASK] such as a mako and tribe., [MASK] such as a mako and slafe., [MASK] such as a mako and man., [MASK] such as a mako and peter.]   \n",
       "\n",
       "                                                                                                                                                                                                mask_sentences_singular_2  \\\n",
       "0                   [[MASK], including a graver and marker., [MASK], including a graver and tomb., [MASK], including a graver and grafe., [MASK], including a graver and body., [MASK], including a graver and murderer.]   \n",
       "1  [[MASK], including a smallmouth and catfish., [MASK], including a smallmouth and carp., [MASK], including a smallmouth and bass., [MASK], including a smallmouth and pike., [MASK], including a smallmouth and perch.]   \n",
       "2             [[MASK], including a pelican and dolphin., [MASK], including a pelican and penguin., [MASK], including a pelican and duck., [MASK], including a pelican and crane., [MASK], including a pelican and eagle.]   \n",
       "3   [[MASK], including a sapsucker and snake., [MASK], including a sapsucker and spider., [MASK], including a sapsucker and frog., [MASK], including a sapsucker and monster., [MASK], including a sapsucker and lizard.]   \n",
       "4                                 [[MASK], including a mako and human., [MASK], including a mako and tribe., [MASK], including a mako and slafe., [MASK], including a mako and man., [MASK], including a mako and peter.]   \n",
       "\n",
       "                                                                                                                                                                                                     mask_sentences_singular_3  \\\n",
       "0                   [[MASK], especially a graver and marker., [MASK], especially a graver and tomb., [MASK], especially a graver and grafe., [MASK], especially a graver and body., [MASK], especially a graver and murderer.]   \n",
       "1  [[MASK], especially a smallmouth and catfish., [MASK], especially a smallmouth and carp., [MASK], especially a smallmouth and bass., [MASK], especially a smallmouth and pike., [MASK], especially a smallmouth and perch.]   \n",
       "2             [[MASK], especially a pelican and dolphin., [MASK], especially a pelican and penguin., [MASK], especially a pelican and duck., [MASK], especially a pelican and crane., [MASK], especially a pelican and eagle.]   \n",
       "3   [[MASK], especially a sapsucker and snake., [MASK], especially a sapsucker and spider., [MASK], especially a sapsucker and frog., [MASK], especially a sapsucker and monster., [MASK], especially a sapsucker and lizard.]   \n",
       "4                                 [[MASK], especially a mako and human., [MASK], especially a mako and tribe., [MASK], especially a mako and slafe., [MASK], especially a mako and man., [MASK], especially a mako and peter.]   \n",
       "\n",
       "                                                                                                                                                                            mask_sentences_singular_4  \\\n",
       "0                   [a graver, marker and other [MASK]., a graver, tomb and other [MASK]., a graver, grafe and other [MASK]., a graver, body and other [MASK]., a graver, murderer and other [MASK].]   \n",
       "1  [a smallmouth, catfish and other [MASK]., a smallmouth, carp and other [MASK]., a smallmouth, bass and other [MASK]., a smallmouth, pike and other [MASK]., a smallmouth, perch and other [MASK].]   \n",
       "2             [a pelican, dolphin and other [MASK]., a pelican, penguin and other [MASK]., a pelican, duck and other [MASK]., a pelican, crane and other [MASK]., a pelican, eagle and other [MASK].]   \n",
       "3   [a sapsucker, snake and other [MASK]., a sapsucker, spider and other [MASK]., a sapsucker, frog and other [MASK]., a sapsucker, monster and other [MASK]., a sapsucker, lizard and other [MASK].]   \n",
       "4                                 [a mako, human and other [MASK]., a mako, tribe and other [MASK]., a mako, slafe and other [MASK]., a mako, man and other [MASK]., a mako, peter and other [MASK].]   \n",
       "\n",
       "                                                                                                                                                                       mask_sentences_singular_5  \\\n",
       "0                   [a graver, marker or other [MASK]., a graver, tomb or other [MASK]., a graver, grafe or other [MASK]., a graver, body or other [MASK]., a graver, murderer or other [MASK].]   \n",
       "1  [a smallmouth, catfish or other [MASK]., a smallmouth, carp or other [MASK]., a smallmouth, bass or other [MASK]., a smallmouth, pike or other [MASK]., a smallmouth, perch or other [MASK].]   \n",
       "2             [a pelican, dolphin or other [MASK]., a pelican, penguin or other [MASK]., a pelican, duck or other [MASK]., a pelican, crane or other [MASK]., a pelican, eagle or other [MASK].]   \n",
       "3   [a sapsucker, snake or other [MASK]., a sapsucker, spider or other [MASK]., a sapsucker, frog or other [MASK]., a sapsucker, monster or other [MASK]., a sapsucker, lizard or other [MASK].]   \n",
       "4                                 [a mako, human or other [MASK]., a mako, tribe or other [MASK]., a mako, slafe or other [MASK]., a mako, man or other [MASK]., a mako, peter or other [MASK].]   \n",
       "\n",
       "                                                                                                                                                                                 mask_sentences_singular_6  \\\n",
       "0                   [such [MASK] as a graver and marker., such [MASK] as a graver and tomb., such [MASK] as a graver and grafe., such [MASK] as a graver and body., such [MASK] as a graver and murderer.]   \n",
       "1  [such [MASK] as a smallmouth and catfish., such [MASK] as a smallmouth and carp., such [MASK] as a smallmouth and bass., such [MASK] as a smallmouth and pike., such [MASK] as a smallmouth and perch.]   \n",
       "2             [such [MASK] as a pelican and dolphin., such [MASK] as a pelican and penguin., such [MASK] as a pelican and duck., such [MASK] as a pelican and crane., such [MASK] as a pelican and eagle.]   \n",
       "3   [such [MASK] as a sapsucker and snake., such [MASK] as a sapsucker and spider., such [MASK] as a sapsucker and frog., such [MASK] as a sapsucker and monster., such [MASK] as a sapsucker and lizard.]   \n",
       "4                                 [such [MASK] as a mako and human., such [MASK] as a mako and tribe., such [MASK] as a mako and slafe., such [MASK] as a mako and man., such [MASK] as a mako and peter.]   \n",
       "\n",
       "                                                                                                                                                                                  mask_sentences_plural_1  \\\n",
       "0                 [[MASK] such as gravers and markers., [MASK] such as gravers and tombs., [MASK] such as gravers and graves., [MASK] such as gravers and bodies., [MASK] such as gravers and murderers.]   \n",
       "1      [[MASK] such as smallmouths and catfish., [MASK] such as smallmouths and carp., [MASK] such as smallmouths and bass., [MASK] such as smallmouths and pike., [MASK] such as smallmouths and perch.]   \n",
       "2            [[MASK] such as pelicans and dolphins., [MASK] such as pelicans and penguins., [MASK] such as pelicans and ducks., [MASK] such as pelicans and cranes., [MASK] such as pelicans and eagles.]   \n",
       "3  [[MASK] such as sapsuckers and snakes., [MASK] such as sapsuckers and spiders., [MASK] such as sapsuckers and frogs., [MASK] such as sapsuckers and monsters., [MASK] such as sapsuckers and lizards.]   \n",
       "4                               [[MASK] such as makoes and human., [MASK] such as makoes and tribe., [MASK] such as makoes and slaves., [MASK] such as makoes and man., [MASK] such as makoes and peter.]   \n",
       "\n",
       "                                                                                                                                                                                                 mask_sentences_plural_2  \\\n",
       "0                 [[MASK], including gravers and markers., [MASK], including gravers and tombs., [MASK], including gravers and graves., [MASK], including gravers and bodies., [MASK], including gravers and murderers.]   \n",
       "1      [[MASK], including smallmouths and catfish., [MASK], including smallmouths and carp., [MASK], including smallmouths and bass., [MASK], including smallmouths and pike., [MASK], including smallmouths and perch.]   \n",
       "2            [[MASK], including pelicans and dolphins., [MASK], including pelicans and penguins., [MASK], including pelicans and ducks., [MASK], including pelicans and cranes., [MASK], including pelicans and eagles.]   \n",
       "3  [[MASK], including sapsuckers and snakes., [MASK], including sapsuckers and spiders., [MASK], including sapsuckers and frogs., [MASK], including sapsuckers and monsters., [MASK], including sapsuckers and lizards.]   \n",
       "4                               [[MASK], including makoes and human., [MASK], including makoes and tribe., [MASK], including makoes and slaves., [MASK], including makoes and man., [MASK], including makoes and peter.]   \n",
       "\n",
       "                                                                                                                                                                                                      mask_sentences_plural_3  \\\n",
       "0                 [[MASK], especially gravers and markers., [MASK], especially gravers and tombs., [MASK], especially gravers and graves., [MASK], especially gravers and bodies., [MASK], especially gravers and murderers.]   \n",
       "1      [[MASK], especially smallmouths and catfish., [MASK], especially smallmouths and carp., [MASK], especially smallmouths and bass., [MASK], especially smallmouths and pike., [MASK], especially smallmouths and perch.]   \n",
       "2            [[MASK], especially pelicans and dolphins., [MASK], especially pelicans and penguins., [MASK], especially pelicans and ducks., [MASK], especially pelicans and cranes., [MASK], especially pelicans and eagles.]   \n",
       "3  [[MASK], especially sapsuckers and snakes., [MASK], especially sapsuckers and spiders., [MASK], especially sapsuckers and frogs., [MASK], especially sapsuckers and monsters., [MASK], especially sapsuckers and lizards.]   \n",
       "4                               [[MASK], especially makoes and human., [MASK], especially makoes and tribe., [MASK], especially makoes and slaves., [MASK], especially makoes and man., [MASK], especially makoes and peter.]   \n",
       "\n",
       "                                                                                                                                                                             mask_sentences_plural_4  \\\n",
       "0                 [gravers, markers and other [MASK]., gravers, tombs and other [MASK]., gravers, graves and other [MASK]., gravers, bodies and other [MASK]., gravers, murderers and other [MASK].]   \n",
       "1      [smallmouths, catfish and other [MASK]., smallmouths, carp and other [MASK]., smallmouths, bass and other [MASK]., smallmouths, pike and other [MASK]., smallmouths, perch and other [MASK].]   \n",
       "2            [pelicans, dolphins and other [MASK]., pelicans, penguins and other [MASK]., pelicans, ducks and other [MASK]., pelicans, cranes and other [MASK]., pelicans, eagles and other [MASK].]   \n",
       "3  [sapsuckers, snakes and other [MASK]., sapsuckers, spiders and other [MASK]., sapsuckers, frogs and other [MASK]., sapsuckers, monsters and other [MASK]., sapsuckers, lizards and other [MASK].]   \n",
       "4                               [makoes, human and other [MASK]., makoes, tribe and other [MASK]., makoes, slaves and other [MASK]., makoes, man and other [MASK]., makoes, peter and other [MASK].]   \n",
       "\n",
       "                                                                                                                                                                        mask_sentences_plural_5  \\\n",
       "0                 [gravers, markers or other [MASK]., gravers, tombs or other [MASK]., gravers, graves or other [MASK]., gravers, bodies or other [MASK]., gravers, murderers or other [MASK].]   \n",
       "1      [smallmouths, catfish or other [MASK]., smallmouths, carp or other [MASK]., smallmouths, bass or other [MASK]., smallmouths, pike or other [MASK]., smallmouths, perch or other [MASK].]   \n",
       "2            [pelicans, dolphins or other [MASK]., pelicans, penguins or other [MASK]., pelicans, ducks or other [MASK]., pelicans, cranes or other [MASK]., pelicans, eagles or other [MASK].]   \n",
       "3  [sapsuckers, snakes or other [MASK]., sapsuckers, spiders or other [MASK]., sapsuckers, frogs or other [MASK]., sapsuckers, monsters or other [MASK]., sapsuckers, lizards or other [MASK].]   \n",
       "4                               [makoes, human or other [MASK]., makoes, tribe or other [MASK]., makoes, slaves or other [MASK]., makoes, man or other [MASK]., makoes, peter or other [MASK].]   \n",
       "\n",
       "                                                                                                                                                                                  mask_sentences_plural_6  \n",
       "0                 [such [MASK] as gravers and markers., such [MASK] as gravers and tombs., such [MASK] as gravers and graves., such [MASK] as gravers and bodies., such [MASK] as gravers and murderers.]  \n",
       "1      [such [MASK] as smallmouths and catfish., such [MASK] as smallmouths and carp., such [MASK] as smallmouths and bass., such [MASK] as smallmouths and pike., such [MASK] as smallmouths and perch.]  \n",
       "2            [such [MASK] as pelicans and dolphins., such [MASK] as pelicans and penguins., such [MASK] as pelicans and ducks., such [MASK] as pelicans and cranes., such [MASK] as pelicans and eagles.]  \n",
       "3  [such [MASK] as sapsuckers and snakes., such [MASK] as sapsuckers and spiders., such [MASK] as sapsuckers and frogs., such [MASK] as sapsuckers and monsters., such [MASK] as sapsuckers and lizards.]  \n",
       "4                               [such [MASK] as makoes and human., such [MASK] as makoes and tribe., such [MASK] as makoes and slaves., such [MASK] as makoes and man., such [MASK] as makoes and peter.]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsp_sap = [\n",
    "         \"[Y] such as [X].\", \n",
    "         \"[Y], including [X].\", \n",
    "         \"[Y], especially [X].\", \n",
    "         \"[X] or other [Y].\", \n",
    "         \"[X] and other [Y].\", \n",
    "         \"such [Y] as [X].\", \n",
    "        ]\n",
    "\n",
    "lsp_dap = [\n",
    "         \"[Y] such as [X] and [Z].\", \n",
    "         \"[Y], including [X] and [Z].\", \n",
    "         \"[Y], especially [X] and [Z].\", \n",
    "         \"[X], [Z] and other [Y].\", \n",
    "         \"[X], [Z] or other [Y].\", \n",
    "         \"such [Y] as [X] and [Z].\"]\n",
    "\n",
    "def insert_anchors(dic_sub_to_anchors, df, mask_col, sub_col, anchor_col):\n",
    "    df[mask_col].head()\n",
    "    df[anchor_col] = df[sub_col].apply(lambda x: dic_sub_to_anchors.get(x) )\n",
    "    df[mask_col] =  df[[anchor_col, mask_col]].apply(lambda x: [ x[1].replace('[Z]', anchor)  for anchor in x[0]], axis=1)\n",
    "    return df\n",
    "\n",
    "def fill_x_into_patterns(df, patterns, ):\n",
    "    '''\n",
    "    sap: Y such as X \n",
    "\n",
    "    '''\n",
    "    \n",
    "    for (i, pattern) in enumerate(patterns):\n",
    "        pattern_id = i+1\n",
    "        df[f'mask_sentences_singular_{pattern_id}'] = df['sub_label_singular'].apply(lambda x: pattern.replace(\"[X]\", f\"{_get_article(x)} {x}\").replace(\"[Y]\", '[MASK]'))\n",
    "        df[f'mask_sentences_plural_{pattern_id}'] = df['sub_label_plural'].apply(lambda x: pattern.replace(\"[X]\", x).replace(\"[Y]\", '[MASK]'))\n",
    "        \n",
    "    mask_sentences_sg_cols = [x for x in df.columns if 'mask_sentences_singular_' in x]\n",
    "    mask_sentences_pl_cols = [x for x in df.columns if 'mask_sentences_plural_' in x]\n",
    "    return df, mask_sentences_sg_cols, mask_sentences_pl_cols\n",
    "\n",
    "\n",
    "\n",
    "# read the data, fill x into the placeholder and fill Y with [MASK]\n",
    "data_dir = '../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/' \n",
    "file = 'singular_plural.tsv'\n",
    "\n",
    "df_def_sap = definition_sap_singular_plural(data_dir, file)\n",
    "df_lsp_sap,mask_sentences_sg_cols, mask_sentences_pl_cols = fill_x_into_patterns(deepcopy(df_def_sap), patterns=lsp_sap)\n",
    "df_lsp_dap,mask_sentences_sg_cols, mask_sentences_pl_cols = fill_x_into_patterns(deepcopy(df_def_sap), patterns=lsp_dap)\n",
    "\n",
    "# read the anchors \n",
    "# path = '../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg.csv'\n",
    "\n",
    "# dic_sub_to_anchors_singular = read_anchors(path)\n",
    "\n",
    "# path = '../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/anchors.plural.csv'\n",
    "# dic_sub_to_anchors_plural = read_anchors(path_anchor_pl)\n",
    "\n",
    "# fill Z with real anchors \n",
    "for mask_col in mask_sentences_sg_cols:\n",
    "    df_lsp_dap = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_singular, df= df_lsp_dap, mask_col = mask_col, sub_col = 'sub_label_singular', anchor_col='subj_anchors_singular')\n",
    "\n",
    "for mask_col in mask_sentences_pl_cols:\n",
    "    df_lsp_dap = insert_anchors(dic_sub_to_anchors=dic_sub_to_anchors_plural, df= df_lsp_dap, mask_col = mask_col, sub_col = 'sub_label_plural', anchor_col='subj_anchors_plural')\n",
    "\n",
    "# # save files \n",
    "output_cols = ['sub_label_singular', 'obj_label_singular','sub_label_plural', 'obj_label_plural',  'uuid',\n",
    "       'relation', \n",
    "       'mask_sentences_singular_1', 'mask_sentences_singular_2', 'mask_sentences_singular_3', \n",
    "       'mask_sentences_singular_4', 'mask_sentences_singular_5', 'mask_sentences_singular_6',\n",
    "       'mask_sentences_plural_1', 'mask_sentences_plural_2', 'mask_sentences_plural_3', \n",
    "       'mask_sentences_plural_4', 'mask_sentences_plural_5',  'mask_sentences_plural_6']\n",
    "\n",
    "df_lsp_sap = df_lsp_sap[output_cols]\n",
    "df_lsp_dap = df_lsp_dap[output_cols]\n",
    "out_dir = '../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency_group/'\n",
    "save_dict_to_json(examples=df_lsp_sap.to_dict(orient='records'), output_path=out_dir + 'IsA.lsp_sap.jsonl') \n",
    "save_dict_to_json(examples=df_lsp_dap.to_dict(orient='records'), output_path=out_dir + 'IsA.lsp_dap.jsonl') \n",
    "df_lsp_sap.to_csv(out_dir + 'IsA.lsp_sap.csv')\n",
    "df_lsp_dap.to_csv(out_dir + 'IsA.lsp_dap.csv')\n",
    "display(df_lsp_sap.head())\n",
    "display(df_lsp_dap.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "IsA.lsp_dap.jsonl                             100% 1650KB  60.6MB/s   00:00    \n",
      "IsA.lsp_sap.csv                               100%  215KB  38.0MB/s   00:00    \n",
      "IsA.lsp_sap.jsonl                             100%  485KB  28.5MB/s   00:00    \n",
      "IsA.lsp_sap-checkpoint.jsonl                  100%  536KB  64.6MB/s   00:00    \n",
      "IsA.lsp_dap-checkpoint.jsonl                  100% 1762KB  85.4MB/s   00:00    \n",
      "IsA.lsp_sap-checkpoint.csv                    100%  240KB  47.7MB/s   00:00    \n",
      "IsA.lsp_dap.csv                               100% 1402KB  56.8MB/s   00:00    \n"
     ]
    }
   ],
   "source": [
    "# !mkdir ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency_group/\n",
    "!scp -r ../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/consistency_group spartan:/home/chunhua/cogsci/DAP/data/lm_diagnostic_extended/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
