{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis on consistency\n",
    "- inspect cases where w/o an anchor model goes wrong, while with an anchor the model gave correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"BLESS\": \"../../log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.HYPERNYMSUITE.csv\",\n",
      "    \"DIAG\": \"../../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv\",\n",
      "    \"CLSB\": \"../../log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.CLSB.csv\",\n",
      "    \"LEDS\": \"../../log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.HYPERNYMSUITE.csv\",\n",
      "    \"EVAL\": \"../../log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.HYPERNYMSUITE.csv\",\n",
      "    \"SHWARTZ\": \"../../log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.HYPERNYMSUITE.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "from collections import Counter, defaultdict \n",
    "from utils_path import dataset_to_respath\n",
    "from inflection import singularize, pluralize \n",
    "\n",
    "pd.set_option('display.max.columns', 100)\n",
    "pd.set_option('display.max.colwidth', 500)\n",
    "\n",
    "def get_dataset_to_respath(dataset_to_respath, print_flag=False):\n",
    "    # remote path \n",
    "    source_dir = 'spartan:~/cogsci/DAP/'\n",
    "    target_dir = '../../'\n",
    "    dataset_to_localpath = defaultdict()\n",
    "    dataset_rename = {\n",
    "        'hypernymsuite-BLESS': 'BLESS', 'lm_diagnostic_extended-singular': 'DIAG', 'clsb-singular':'CLSB', 'hypernymsuite-LEDS': 'LEDS', 'hypernymsuite-EVAL': 'EVAL', 'hypernymsuite-SHWARTZ': \n",
    "        \"SHWARTZ\"\n",
    "    }\n",
    "    dataset_name_to_relpath = defaultdict()\n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        path = path.replace(\".tsv\", \".csv\")\n",
    "        source_path = source_dir + path \n",
    "        dataset_l1 = dataset.split(\"-\")[0]\n",
    "        dataset_l2 = dataset.split(\"-\")[1] \n",
    "        target_path = target_dir + path\n",
    "        \n",
    "        scp_string = f\"!scp {source_path} {target_path}\"\n",
    "        if print_flag:\n",
    "            print(scp_string)\n",
    "            print()\n",
    "#         print(target_path)\n",
    "        dataset_to_localpath[dataset_rename[dataset]] = target_path \n",
    "        dataset_name_to_relpath[dataset_rename[dataset]] = \"/\".join(dataset.split('-'))\n",
    "#     print(dataset_to_localpath)\n",
    "    return dataset_to_localpath, dataset_name_to_relpath\n",
    "\n",
    "dataset_to_localpath, dataset_name_to_relpath = get_dataset_to_respath(dataset_to_respath)\n",
    "print(json.dumps(dataset_to_localpath, indent=4))\n",
    "# print(dataset_name_to_relpath)\n",
    "\n",
    "def read_anchors(path_pl, anchor_source, debug=False):\n",
    "    '''\n",
    "    read the anchor files mined from singualr and plural\n",
    "    \n",
    "    args: \n",
    "        anchor_soure: using the anchors mined from singular probe or plural probe\n",
    "        \n",
    "    return: \n",
    "        dic_sub_to_anchors_singular: both sub_label and subj_anchors are singular \n",
    "        dic_sub_to_anchors_plural: both sub_label and subj_anchors are plural \n",
    "    '''\n",
    "#     dfsg = pd.read_csv(path_sg)\n",
    "#     dfsg['subj_anchors'] = dfsg['subj_anchors'].apply(lambda x: eval(x))\n",
    "    \n",
    "#     dfpl = pd.read_csv(path_pl)\n",
    "#     dfpl['subj_anchors'] = dfpl['subj_anchors'].apply(lambda x: eval(x))\n",
    "#     df = pd.merge(dfsg, dfpl, on = 'uuid', suffixes=('_sg', '_pl'))\n",
    "# if anchor_source == 'plural':\n",
    "#         #convert the singular anchors into singular format\n",
    "#         df['subj_anchors_sg'] = df['subj_anchors_pl'].progress_apply(lambda x: [singularize(word) for word in x])\n",
    "#     elif anchor_source == 'singular':\n",
    "#         #convert the plural anchors into singular format\n",
    "#         df['subj_anchors_pl'] = df['subj_anchors_sg'].progress_apply(lambda x: [pluralize(word) for word in x])\n",
    "\n",
    "    df = pd.read_csv(path_pl)\n",
    "    \n",
    "    if debug: df = df.head(5)\n",
    "    df['subj_anchors_sg'] = df['subj_anchors_sg'].apply(lambda x: eval(x))\n",
    "    df['subj_anchors_pl'] = df['subj_anchors_pl'].apply(lambda x: eval(x))\n",
    "        \n",
    "    dic_sub_to_anchors_singular = dict(zip(df['sub_label_sg'], df['subj_anchors_sg']))\n",
    "    dic_sub_to_anchors_plural = dict(zip(df['sub_label_pl'], df['subj_anchors_pl']))\n",
    "    \n",
    "    return dic_sub_to_anchors_singular, dic_sub_to_anchors_plural\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_path import dataset_to_respath\n",
    "dataset_to_localpath, dataset_name_to_relpath = get_dataset_to_respath(dataset_to_respath)\n",
    "\n",
    "# for dataset, data_path in dataset_to_localpath.items():\n",
    "#     dic_sub_to_anchors_singular,dic_sub_to_anchors_plural = read_anchors(data_path, data_path, anchor_source='plural', debug=False)\n",
    "\n",
    "\n",
    "def concept_evaluation(label, pred):\n",
    "    '''\n",
    "    \n",
    "    label: a list with the singualr and plural labels (e.g., ['tool', 'tools'])\n",
    "    pred: the top K prediction list \n",
    "\n",
    "    return:\n",
    "        1 if label share with pred else 0  \n",
    "    '''\n",
    "    if not isinstance(label, list):\n",
    "        # label = eval(label)\n",
    "        label = [label]\n",
    "        \n",
    "    if not isinstance(pred, list):\n",
    "        print(type(pred), pred)\n",
    "        pred = eval(pred)\n",
    "\n",
    "    shared = set(label).intersection(set(pred))\n",
    "    return 1 if len(shared)>0 else 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pair Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lsp_sap', 'lsp_dap']\n",
      "['def_sap', 'def_dap']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats \n",
    "dataset_to_respath={\n",
    "    \"CLSB\": \"../../log/bert-large-uncased/clsb/singular/consistency/\",\n",
    "    \"BLESS\": \"../../log/bert-large-uncased/hypernymsuite/BLESS/consistency/\",\n",
    "    \"EVAL\": \"../../log/bert-large-uncased/hypernymsuite/EVAL/consistency/\",\n",
    "    \"LEDS\": \"../../log/bert-large-uncased/hypernymsuite/LEDS/consistency/\",\n",
    "    \"DIAG\": \"../../log/bert-large-uncased/lm_diagnostic_extended/singular/consistency/\",\n",
    "    \"SHWARTZ\": \"../../log/bert-large-uncased/hypernymsuite/SHWARTZ/consistency/\"\n",
    "}\n",
    "\n",
    "\n",
    "out_cols_pl = ['sub_label_singular', 'obj_label_singular',\n",
    "               'obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2',\n",
    "       'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4',\n",
    "       'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6', \n",
    "       'p1_pl_1','p1_pl_2',  'p1_pl_3', \n",
    "       'p1_pl_4', 'p1_pl_5', 'p1_pl_6', 'p1_pl', 'subj_anchors_pl',\n",
    "       'mask_sentences_plural_1', 'mask_sentences_plural_2',\n",
    "       'mask_sentences_plural_3', 'mask_sentences_plural_4',\n",
    "       'mask_sentences_plural_5', 'mask_sentences_plural_6', \n",
    "                'sub_label_plural', 'obj_label_plural', 'uuid', 'relation',\n",
    "       ]\n",
    "#  'obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2',\n",
    "#        'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4',\n",
    "#        'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6', \n",
    "\n",
    "\n",
    "out_cols_sg = ['sub_label_singular', 'obj_label_singular',\n",
    "       'obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', \n",
    "       'p1_sg_1','p1_sg_2',  'p1_sg_3', 'p1_sg', 'subj_anchors_sg',\n",
    "       'mask_sentences_singular_1', 'mask_sentences_singular_2', 'mask_sentences_singular_3',\n",
    "       'sub_label_plural', 'obj_label_plural', 'uuid', 'relation',\n",
    "              ]\n",
    "\n",
    "min_pvalue = 0.05\n",
    "df_res_all = []\n",
    "col_gains = []\n",
    "for mask_type in [['lsp_sap', 'lsp_dap'], ['def_sap', 'def_dap']]: \n",
    "# for mask_type in [['lsp_sap', 'lsp_dap']]: #, ]: #, \n",
    "    print(mask_type)\n",
    "    pattern_num = 6 if 'lsp' in mask_type[0] else 3\n",
    "    metric = 'p1_pl' if 'lsp' in mask_type[0] else 'p1_sg'\n",
    "    out_cols = out_cols_pl if 'lsp' in mask_type[0] else out_cols_sg\n",
    "    \n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        #if dataset!='CLSB': continue \n",
    "        dic_sub_to_anchors_singular, dic_sub_to_anchors_plural = read_anchors(dataset_to_localpath[dataset] , anchor_source='plural', debug=False)\n",
    "        \n",
    "        suffix1 = f'IsA.{mask_type[0]}.csv'\n",
    "        suffix2 = f'IsA.{mask_type[1]}.csv'\n",
    "\n",
    "        df1 = pd.read_csv(path+suffix1).sort_values(by='uuid')\n",
    "        #display(df1)\n",
    "        \n",
    "#         df1['subj_anchors_sg'] = df1['sub_label_singular'].apply(lambda x: dic_sub_to_anchors_singular.get(x))\n",
    "#         df1['subj_anchors_pl'] = df1['sub_label_plural'].apply(lambda x: dic_sub_to_anchors_plural.get(x))\n",
    "#         display(df1)\n",
    "        \n",
    "#         df2 = pd.read_csv(path+suffix2).sort_values(by='uuid')\n",
    "       \n",
    "#         statistic, pvalue = stats.ttest_rel(df1[metric], df2[metric])\n",
    "#         reject_np = True if pvalue < min_pvalue else False\n",
    "#         print(dataset, reject_np) #, statistic, pvalue, len(df1.index), len(df2.index))\n",
    "        \n",
    "#         df2['subj_anchors_sg'] = df2['sub_label_singular'].apply(lambda x: dic_sub_to_anchors_singular.get(x))\n",
    "#         df2['subj_anchors_pl'] = df2['sub_label_plural'].apply(lambda x: dic_sub_to_anchors_plural.get(x))\n",
    "        \n",
    "#         df1[metric+'_anchor'] = df2[metric]\n",
    "#         df2[metric+'_no_anchor'] = df1[metric]\n",
    "            \n",
    "#         #display(df1.columns)\n",
    "#         #display(df1[['sub_label_plural', 'obj_label_plural','p1_sgpl', 'uuid' ]])\n",
    "#         #display(df2[['sub_label_plural', 'obj_label_plural','p1_sgpl', 'uuid' ]])\n",
    "#         dfg=df1.query(f\"{metric}==0\")#[['sub_label_plural', 'obj_label_plural', 'subj_anchors_pl']] #, 'subj_anchors']]\n",
    "       \n",
    "#         group_cols = ['sub_label_plural', 'obj_label_plural'] if 'lsp' in mask_type[0] else ['sub_label_singular', 'obj_label_singular']\n",
    "#         for name, group in dfg.groupby(group_cols):\n",
    "#             #display(group.col)\n",
    "#             df2g =df2.query(f\"{group_cols[0]}=='{name[0]}' and {group_cols[1]}=='{name[1]}' and {metric}==1\")\n",
    "#             if len(df2g.index)>0:\n",
    "#                 df1q = df1.query(f\"{group_cols[0]}=='{name[0]}' and {group_cols[1]}=='{name[1]}'\")[out_cols]\n",
    "#                 df2q = df2g[out_cols]\n",
    "#                 display(pd.concat([df1q, df2q]))\n",
    "#         cols= ['p1_pl_1', 'p1_pl_2', 'p1_pl_3', 'p1_pl_4', 'p1_pl_5', 'p1_pl_6'] if 'lsp' in mask_type[0] else ['p1_sg_1', 'p1_sg_2', 'p1_sg_3']\n",
    "        \n",
    "#         for col in cols:\n",
    "#             grain_ratio = 0\n",
    "#             for y1, y2 in zip(df1[col], df2[col]):\n",
    "#                 if y1==0 and y2==1: grain_ratio +=1\n",
    "#             grain_ratio = grain_ratio/len(df1.query(f\"{col}==0\").index)\n",
    "#             #print(col, grain_ratio)\n",
    "#             col_gains.append({'dataset': dataset, 'mask_type': mask_type[0], 'col':col, 'gains_from_anchor': grain_ratio})\n",
    "# #         display(\"-\"*40)\n",
    "# #     print(\"-\"*80)\n",
    "# col_gains = pd.DataFrame(col_gains)\n",
    "# display(col_gains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lsp_sap', 'lsp_dap']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats \n",
    "dataset_to_respath={\n",
    "    \"CLSB\": \"../../log/bert-large-uncased/clsb/singular/consistency_group/\",\n",
    "    \"BLESS\": \"../../log/bert-large-uncased/hypernymsuite/BLESS/consistency_group/\",\n",
    "    \"EVAL\": \"../../log/bert-large-uncased/hypernymsuite/EVAL/consistency_group/\",\n",
    "    \"LEDS\": \"../../log/bert-large-uncased/hypernymsuite/LEDS/consistency_group/\",\n",
    "    \"DIAG\": \"../../log/bert-large-uncased/lm_diagnostic_extended/singular/consistency_group/\",\n",
    "    \"SHWARTZ\": \"../../log/bert-large-uncased/hypernymsuite/SHWARTZ/consistency_group/\"\n",
    "}\n",
    "\n",
    "\n",
    "out_cols_pl = ['sub_label_singular', 'obj_label_singular',\n",
    "               'obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2',\n",
    "       'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4',\n",
    "       'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6', \n",
    "       'p1_pl_1','p1_pl_2',  'p1_pl_3', \n",
    "       'p1_pl_4', 'p1_pl_5', 'p1_pl_6', 'p1_pl', 'subj_anchors_pl',\n",
    "       'mask_sentences_plural_1', 'mask_sentences_plural_2',\n",
    "       'mask_sentences_plural_3', 'mask_sentences_plural_4',\n",
    "       'mask_sentences_plural_5', 'mask_sentences_plural_6', \n",
    "                'sub_label_plural', 'obj_label_plural', 'uuid', 'relation',\n",
    "       ]\n",
    "#  'obj_mask_sentence_pl_1', 'obj_mask_sentence_pl_2',\n",
    "#        'obj_mask_sentence_pl_3', 'obj_mask_sentence_pl_4',\n",
    "#        'obj_mask_sentence_pl_5', 'obj_mask_sentence_pl_6', \n",
    "\n",
    "\n",
    "out_cols_sg = ['sub_label_singular', 'obj_label_singular',\n",
    "       'obj_mask_sentence_sg_1', 'obj_mask_sentence_sg_2', 'obj_mask_sentence_sg_3', \n",
    "       'p1_sg_1','p1_sg_2',  'p1_sg_3', 'p1_sg', 'subj_anchors_sg',\n",
    "       'mask_sentences_singular_1', 'mask_sentences_singular_2', 'mask_sentences_singular_3',\n",
    "       'sub_label_plural', 'obj_label_plural', 'uuid', 'relation',\n",
    "              ]\n",
    "\n",
    "\n",
    "def evaluate(df, pattern_num, mask_type, dataset):\n",
    "    df_res=[]\n",
    "    for k in [10]:\n",
    "        # for i, (pred_col_sg, pred_col_pl) in enumerate(zip(pred_col_sg, pred_col_pl), start=1):\n",
    "        for i in range(1, pattern_num+1):\n",
    "            df[f'p1_sg_{i}'] = df[['obj_label_singular', f'obj_mask_sentence_sg_{i}']].apply(lambda x: concept_evaluation(x[0], eval(x[1])[:k]), axis=1 )\n",
    "            df[f'p1_pl_{i}'] = df[['obj_label_plural', f'obj_mask_sentence_pl_{i}']].apply(lambda x: concept_evaluation(x[0], eval(x[1])[:k]), axis=1 )\n",
    "\n",
    "        pred_col_sg_p1 = [x for x in df.columns if 'p1_sg_' in x ]\n",
    "        pred_col_pl_p1 = [x for x in df.columns if 'p1_pl_' in x ]\n",
    "\n",
    "\n",
    "        df['p1_sg'] = df[pred_col_sg_p1].apply(lambda x: int(all(ele == 1 for ele in x)), axis=1)\n",
    "        df['p1_pl'] = df[pred_col_pl_p1].apply(lambda x: int(all(ele == 1 for ele in x)), axis=1)\n",
    "\n",
    "        df['p1_sgpl'] = df[['p1_sg', 'p1_pl']].apply(lambda x: 1 if x[0]==1 and x[1]==1 else 0, axis=1)\n",
    "\n",
    "        acc_sg = round(df['p1_sg'].sum()/len(df.index) * 100, 1)\n",
    "        acc_pl = round(df['p1_pl'].sum()/len(df.index)* 100, 1) \n",
    "        acc_sgpl = round(df['p1_sgpl'].sum()/len(df.index)* 100, 1) \n",
    "        \n",
    "        acc_consistency = acc_pl if 'lsp' in mask_type else acc_sg \n",
    "        df_res.append({\"dataset\":dataset, \"mask_type\":mask_type, \"K\":k, 'Consistency': acc_consistency})\n",
    "        #df_res.append({\"K\":k, 'Singular': acc_sg, 'Plural': acc_pl, 'Paired Singular-Plural': acc_sgpl})\n",
    "    print(df_res)\n",
    "    return  df, df_res \n",
    "    \n",
    "\n",
    "min_pvalue = 0.05\n",
    "df_res_all = []\n",
    "col_gains = []\n",
    "vocab_hyper = set()\n",
    "vocab_hyper_wrong_all = set()\n",
    "vocab_hyper_all = set()\n",
    "dfs_no_anchor = []\n",
    "dfs_anchor = []\n",
    "# for mask_type in [['lsp_sap', 'lsp_dap'], ['def_sap', 'def_dap']]: \n",
    "for mask_type in [['lsp_sap', 'lsp_dap']]: #, ]: #, \n",
    "# for mask_type in [['def_sap', 'def_dap']]: #, ]: #, \n",
    "    print(mask_type)\n",
    "    pattern_num = 6 if 'lsp' in mask_type[0] else 3\n",
    "    metric = 'p1_pl' if 'lsp' in mask_type[0] else 'p1_sg'\n",
    "    out_cols = out_cols_pl if 'lsp' in mask_type[0] else out_cols_sg\n",
    "    \n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        #if dataset!='CLSB': continue \n",
    "        dic_sub_to_anchors_singular, dic_sub_to_anchors_plural = read_anchors(dataset_to_localpath[dataset] , anchor_source='plural', debug=False)\n",
    "        \n",
    "        suffix1 = f'IsA.{mask_type[0]}.csv'\n",
    "        suffix2 = f'IsA.{mask_type[1]}.csv'\n",
    "\n",
    "        df1 = pd.read_csv(path+suffix1).sort_values(by='uuid')\n",
    "        df1['subj_anchors_sg'] = df1['sub_label_singular'].apply(lambda x: dic_sub_to_anchors_singular.get(x))\n",
    "        df1['subj_anchors_pl'] = df1['sub_label_plural'].apply(lambda x: dic_sub_to_anchors_plural.get(x))\n",
    "        df1['obj_label_singular'] = df1['obj_label_singular'].apply(lambda x: eval(x)[0])\n",
    "        vocab_hyper_all.update(set(df1['obj_label_singular']))\n",
    "        \n",
    "        df2 = pd.read_csv(path+suffix2).sort_values(by='uuid')\n",
    "        \n",
    "        \n",
    "        df2['subj_anchors_sg'] = df2['sub_label_singular'].apply(lambda x: dic_sub_to_anchors_singular.get(x))\n",
    "        df2['subj_anchors_pl'] = df2['sub_label_plural'].apply(lambda x: dic_sub_to_anchors_plural.get(x))\n",
    "        df2['obj_label_singular'] = df2['obj_label_singular'].apply(lambda x: eval(x)[0])\n",
    "       \n",
    "        df1[metric+'_anchor'] = df2[metric]\n",
    "        df2[metric+'_no_anchor'] = df1[metric]\n",
    "            \n",
    "        dfs_no_anchor.append(df1)\n",
    "        dfs_anchor.append(df2)\n",
    "        \n",
    "dfs_no_anchor = pd.concat(dfs_no_anchor)\n",
    "dfs_anchor = pd.concat(dfs_anchor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth in WordNet and their consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5 20.0 20.0\n",
      "2 104 1.0 7.7\n",
      "3 352 2.8 3.7\n",
      "4 1335 8.5 12.2\n",
      "5 1572 6.7 11.1\n",
      "6 4829 8.4 11.5\n",
      "7 1017 29.7 41.5\n",
      "8 1773 9.4 14.8\n",
      "9 1110 32.0 36.2\n",
      "10 348 28.2 32.5\n",
      "11 15 6.7 6.7\n",
      "12 12 16.7 25.0\n",
      "13 55 5.5 9.1\n",
      "14 54 7.4 7.4\n",
      "16 2 50.0 100.0\n",
      "17 2 0.0 0.0\n",
      "{'jewelry', 'constellation', 'payment', 'soil', 'crop', 'movement', 'service', 'stick', 'software', 'accessory', 'prejudice', 'wall', 'grape', 'science', 'gene', 'country', 'sensation', 'state', 'school', 'article', 'instrument', 'house', 'berry', 'satellite', 'pet', 'deity', 'rule', 'vessel', 'suburb', 'box', 'letter', 'clothes', 'vehicle', 'criminal', 'cosmetic', 'dish', 'tool', 'church', 'plant', 'enclosure', 'garment', 'finger', 'predator', 'sweet', 'snack', 'skirt', 'passageway', 'bishop', 'restaurant', 'hope', 'site', 'hormone', 'furniture', 'hair', 'highway', 'craft', 'prophet', 'protest', 'limb', 'female', 'sport', 'machine'}\n",
      "\\begin{tabular}{rrrrrl}\n",
      "\\toprule\n",
      " depth &  #instances &  \\lsp &  lspa &  gains &                                           examples \\\\\n",
      "\\midrule\n",
      "     1 &           5 &  20.0 &  20.0 &    0.0 &                            (transaction, conflict) \\\\\n",
      "     2 &         104 &   1.0 &   7.7 &    6.7 &      (object, group, relation, proceeding, battle) \\\\\n",
      "     3 &         352 &   2.8 &   3.7 &    0.9 &       (person, language, event, collection, trait) \\\\\n",
      "     4 &        1335 &   8.5 &  12.2 &    3.7 &           (band, organization, island, food, lake) \\\\\n",
      "     5 &        1572 &   6.7 &  11.1 &    4.4 & (place, river, mountain, organisation, settlement) \\\\\n",
      "     6 &        4829 &   8.4 &  11.5 &    3.1 &             (film, village, company, animal, work) \\\\\n",
      "     7 &        1017 &  29.7 &  41.5 &   11.8 &             (vehicle, tool, country, plant, sport) \\\\\n",
      "     8 &        1773 &   9.4 &  14.8 &    5.4 &               (city, town, fruit, weapon, illness) \\\\\n",
      "     9 &        1110 &  32.0 &  36.2 &    4.2 &               (book, bird, magazine, mammal, tree) \\\\\n",
      "    10 &         348 &  28.2 &  32.5 &    4.3 &                (fish, ship, flower, airline, word) \\\\\n",
      "    11 &          15 &   6.7 &   6.7 &    0.0 &           (airplane, hawk, plane, vulture, murder) \\\\\n",
      "    12 &          12 &  16.7 &  25.0 &    8.3 &                     (cancer, lizard, falcon, pine) \\\\\n",
      "    13 &          55 &   5.5 &   9.1 &    3.6 &                                 (human, pest, cat) \\\\\n",
      "    14 &          54 &   7.4 &   7.4 &    0.0 &                                            (horse) \\\\\n",
      "    16 &           2 &  50.0 & 100.0 &   50.0 &                                           (cattle) \\\\\n",
      "    17 &           2 &   0.0 &   0.0 &    0.0 &                                              (cow) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-440279232b8f>:20: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(pd.DataFrame(df_results).to_latex(index=False, escape=False))\n"
     ]
    }
   ],
   "source": [
    "# query = ['sport', 'beverage', 'sweet', 'garment']\n",
    "\n",
    "df_word_depth = pd.read_csv('../log/word_depth_wn.csv')\n",
    "df_results =[]\n",
    "for name, group in df_word_depth.groupby('depth'):\n",
    "    query = list(set(group['word']))\n",
    "    dfq1 = dfs_no_anchor.query(f'obj_label_singular in {query}')\n",
    "    dfq2 = dfs_anchor.query(f'obj_label_singular in {query}')\n",
    "    consistency1 = round(dfq1['p1_pl'].mean()*100, 1)\n",
    "    consistency2 = round(dfq2['p1_pl'].mean()*100, 1)\n",
    "    gains = round(consistency2-consistency1, 1)\n",
    "    examples = dict(Counter(dfq1['obj_label_singular'].values).most_common(5)).keys()\n",
    "    #print(name, len(dfq1), len(dfq1.query('p1_pl==0').index)/len(dfq1.index), len(dfq2.query('p1_pl==0').index)/len(dfq2.index))\n",
    "    print(name, len(dfq1), consistency1,consistency2,  )\n",
    "#     print(name, len(dfq2), )\n",
    "    df_results.append({'depth': name, '#instances': len(dfq1.index), r'\\lsp': consistency1, r'lspa': consistency2, \"gains\": gains, 'examples':examples })\n",
    "df_word_depth = pd.read_csv('../log/word_depth_wn.csv')\n",
    "query_depth = [7] #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17]\n",
    "print( set(df_word_depth.query(f'depth in {query_depth}')['word']))\n",
    "print(pd.DataFrame(df_results).to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agreement',\n",
       " 'airplane',\n",
       " 'alcohol',\n",
       " 'algae',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'battle',\n",
       " 'carriage',\n",
       " 'change',\n",
       " 'citizen',\n",
       " 'competition',\n",
       " 'continent',\n",
       " 'count',\n",
       " 'county',\n",
       " 'court',\n",
       " 'digit',\n",
       " 'facility',\n",
       " 'finger',\n",
       " 'genre',\n",
       " 'gift',\n",
       " 'group',\n",
       " 'hair',\n",
       " 'hormone',\n",
       " 'implement',\n",
       " 'jewelry',\n",
       " 'letter',\n",
       " 'literature',\n",
       " 'meat',\n",
       " 'memorial',\n",
       " 'month',\n",
       " 'monument',\n",
       " 'noise',\n",
       " 'pattern',\n",
       " 'pest',\n",
       " 'politician',\n",
       " 'proceeding',\n",
       " 'prophet',\n",
       " 'publisher',\n",
       " 'question',\n",
       " 'rapid',\n",
       " 'relative',\n",
       " 'saint',\n",
       " 'seed',\n",
       " 'sibling',\n",
       " 'snack',\n",
       " 'soil',\n",
       " 'spice',\n",
       " 'suburb',\n",
       " 'sweet',\n",
       " 'symbol',\n",
       " 'vampire',\n",
       " 'variety',\n",
       " 'waste',\n",
       " 'wetland'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set1 = set (dfs_no_anchor.query(\"p1_pl == 1\")['obj_label_singular'] ) \n",
    "set2 = set (dfs_anchor.query(\"p1_pl == 1\")['obj_label_singular'] ) \n",
    "set2 - set1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_pl_1 0.8057103064066853\n",
      "p1_pl_2 0.897125854646746\n",
      "p1_pl_3 0.9213724993669283\n",
      "p1_pl_4 0.8503418586984046\n",
      "p1_pl_5 0.8502152443656622\n",
      "p1_pl_6 0.865662192960243\n"
     ]
    }
   ],
   "source": [
    "# dfs_no_anchor.head()\n",
    "# dfs_no_anchor.query()\n",
    "for col in ['p1_pl_1', 'p1_pl_2', 'p1_pl_3', 'p1_pl_4', 'p1_pl_5', 'p1_pl_6']:\n",
    "    numerator = dfs_no_anchor.query(f\"{col}==0\") #, dfs[dfs_anchor]\n",
    "    denominator = dfs_no_anchor.query(f\"p1_pl==0\")\n",
    "    ratio = len(numerator.index)/ len(denominator.index)\n",
    "    print(col, ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010572296783995948\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "out = dfs_no_anchor[['p1_pl_1', 'p1_pl_2', 'p1_pl_4', 'p1_pl_5', 'p1_pl_6',  'p1_pl_3']].apply(lambda x: 1 if int(all(ele == 1 for ele in x[:-1]))==1 and x[-1]==0 else 0, axis=1)\n",
    "# for x in dfs_no_anchor.query(\"p1_pl==0\")[['p1_pl_1', 'p1_pl_2', 'p1_pl_3', 'p1_pl_4', 'p1_pl_5', 'p1_pl_6']].iterrows():\n",
    "#     break\n",
    "wrong= sum(out)/len(dfs_no_anchor.query('p1_pl==0').index)\n",
    "print(wrong)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted hypernyms is Co-hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_no_anchor.head()\n",
    "df_cohypo = pd.read_csv('../log/word_to_cohyponyms.txt')\n",
    "word_to_cohyponyms = dict(zip(df_cohypo['word'].to_list(), df_cohypo['cohyponyms'].to_list()))\n",
    "\n",
    "dfs_no_anchor['sub_sister'] = dfs_no_anchor['sub_label_singular'].apply(lambda x: eval(word_to_cohyponyms.get(x)))\n",
    "\n",
    "dfs_no_anchor['obj_mask_sentence_sg_1'] = dfs_no_anchor['obj_mask_sentence_sg_1'].apply(lambda x: eval(x))\n",
    "def get_shared(x, y):\n",
    "    shared = set(x).intersection(set(y))\n",
    "    return 1 if len(shared)>0 else 0\n",
    "dfs_no_anchor['obj_in_sub_sister'] = dfs_no_anchor[['obj_mask_sentence_sg_1', 'sub_sister']].apply(lambda x: get_shared(x[0], x[1]), axis=1)\n",
    "# dfs_no_anchor[['sub_label_singular','obj_mask_sentence_sg_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33977979348508186"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_no_anchor['obj_in_sub_sister'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predator', 'protest', 'service', 'sweet', 'constellation', 'school', 'house', 'movement', 'stick', 'restaurant', 'vehicle', 'skirt', 'berry', 'site', 'sensation', 'limb', 'clothes', 'hope', 'vessel', 'enclosure', 'article', 'payment', 'gene', 'highway', 'sport', 'bishop', 'wall', 'jewelry', 'software', 'snack', 'cosmetic', 'grape', 'box', 'state', 'plant', 'suburb', 'female', 'prophet', 'criminal', 'craft', 'country', 'rule', 'church', 'science', 'pet', 'hair', 'instrument', 'satellite', 'tool', 'garment', 'finger', 'passageway', 'machine', 'soil', 'furniture', 'crop', 'prejudice', 'dish', 'accessory', 'hormone', 'deity', 'letter'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267</td>\n",
       "      <td>conflict</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249</td>\n",
       "      <td>transaction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329</td>\n",
       "      <td>proceeding</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205</td>\n",
       "      <td>relation</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>239</td>\n",
       "      <td>group</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>139</td>\n",
       "      <td>pest</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>188</td>\n",
       "      <td>human</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>324</td>\n",
       "      <td>horse</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>176</td>\n",
       "      <td>cattle</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>283</td>\n",
       "      <td>cow</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0         word  depth\n",
       "0           267     conflict      1\n",
       "1           249  transaction      1\n",
       "2           329   proceeding      2\n",
       "3           205     relation      2\n",
       "4           239        group      2\n",
       "..          ...          ...    ...\n",
       "327         139         pest     13\n",
       "328         188        human     13\n",
       "329         324        horse     14\n",
       "330         176       cattle     16\n",
       "331         283          cow     17\n",
       "\n",
       "[332 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import wn, wn.taxonomy\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "\n",
    "\n",
    "results = defaultdict()\n",
    "vocab_depths = defaultdict()\n",
    "names = [ 'wrong_hyper_no_anchor', 'corrcted_by_anchor', 'all_hyper',]\n",
    "vocabs = [vocab_hyper_wrong_all, vocab_hyper, vocab_hyper_all] \n",
    "res_oov = defaultdict()\n",
    "for name, vocab in zip(names, vocabs):\n",
    "    vocab_depth = defaultdict()\n",
    "    vocab_oov  =  set()\n",
    "    print(len(vocab))\n",
    "    for word in vocab: #['concept', 'thought', 'living thing', 'whole', 'psychological feature', 'unit', 'artifact', 'abstraction', 'object','physical entity', 'entity']:\n",
    "        #word = eval(word)[0] if \n",
    "        synset = wn.synsets(word, pos='n')\n",
    "        if len(synset)==0:\n",
    "            vocab_oov.add(word)\n",
    "            continue \n",
    "            \n",
    "        synset = synset[0]\n",
    "        min_depth = wn.taxonomy.min_depth(synset, simulate_root=False)\n",
    "        #print(word, min_depth)\n",
    "        vocab_depth[word] = min_depth\n",
    "\n",
    "    print(Counter(vocab_depth.values()).most_common())\n",
    "    df_depth = pd.DataFrame(vocab_depth.items(), columns=['word', 'depth']).sort_values('depth')\n",
    "    query_depth = [5, 6, 7, 8, 9]\n",
    "    display(df_depth.query(f\"depth in {query_depth}\").sample(5))\n",
    "    results[name] = df_depth\n",
    "    res_oov[name] = vocab_oov\n",
    "    vocab_depths[name] = vocab_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "dict1 = dict(results['corrcted_by_anchor']['depth'].value_counts())\n",
    "dict2 = dict(results['wrong_hyper_no_anchor']['depth'].value_counts())\n",
    "dict3 = dict(results['all_hyper']['depth'].value_counts())\n",
    "\n",
    "df_correct = []\n",
    "for k,v in dict1.items():\n",
    "    df_correct.append({'depth':k, 'corrected_ratio': round(v/dict2[k], 3) ,'wrong': dict2[k], 'correct': v, 'all': dict3[k]})\n",
    "print(\"-\"*80)\n",
    "df_correct = pd.DataFrame(df_correct)\n",
    "df_correct.sort_values(['wrong', 'corrected_ratio'], ascending=False)\n",
    "# display(results['all_hyper']['depth'].value_counts(normalize=True).plot(kind='bar', title='distribution overall'))\n",
    "# plt.show()\n",
    "# display(results['wrong_hyper_no_anchor']['depth'].value_counts(normalize=True).plot(kind='bar', title='distribution of wrong w/o anchors'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict1 = dict(results['corrcted_by_anchor']['depth'].value_counts())\n",
    "# dict2 = dict(results['wrong_hyper_no_anchor']['depth'].value_counts())\n",
    "# dict3 = dict(results['all_hyper']['depth'].value_counts())\n",
    "query_depth = [5, 6, 7, 8]\n",
    "dfq =results['corrcted_by_anchor'].query(f'depth in {query_depth}')\n",
    "for name, group in dfq.groupby('depth'):\n",
    "    display(name, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['corrcted_by_anchor']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
