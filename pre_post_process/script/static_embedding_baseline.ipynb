{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypernym in KNN (Word2Vec trained on 300d GoogleNews)\n",
    "\n",
    "Pointer: \n",
    "- Word2Vec (Home Page) https://code.google.com/archive/p/word2vec/ \n",
    "- GoogleNews word2vec: The archive is available here: GoogleNews-vectors-negative300.bin.gz.  https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy \n",
    "from tqdm import tqdm \n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec, KeyedVectors \n",
    "tqdm.pandas()\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_article(word):\n",
    "    if word[0] in ['a', 'e', 'i', 'o', 'u']:\n",
    "        return 'an'\n",
    "    return 'a'\n",
    "\n",
    "\n",
    "def save_dict_to_json(examples, output_path):\n",
    "    ''' \n",
    "    save a list of dicts into otuput_path, orient='records' (each line is a dict) \n",
    "    examples: a list of dicts\n",
    "    output_path: \n",
    "    '''\n",
    "\n",
    "    with open(output_path, 'w') as fout:\n",
    "        for example in examples:\n",
    "            json.dump(example, fout)\n",
    "            fout.write(\"\\n\")\n",
    "        print(f\"save {output_path} with {len(examples)} lines\")\n",
    "\n",
    "def add_period_at_the_end_of_sentence(sentence):\n",
    "    last_token = sentence[-1]\n",
    "    if last_token != '.': \n",
    "        return sentence + '.'\n",
    "    return [sentence]\n",
    "\n",
    "def get_unmasker(model, device, targets=None):\n",
    "    if targets is None: \n",
    "        unmasker = pipeline('fill-mask', model=model)# 'bert-large-uncased') #initialize the masker\n",
    "    else:\n",
    "        unmasker = pipeline('fill-mask', model=model, targets=targets )# 'bert-large-uncased') #initialize the masker\n",
    "    return unmasker\n",
    "\n",
    "\n",
    "\n",
    "def remove_noisy_test_data(df):\n",
    "  ''' \n",
    "  relation=\"hasproperty\"\n",
    "  why? some data points don't belong to this relation types \n",
    "  case1., sub_label=number, such as \"10 is ten.\"  We don't say ten is the property of 10\n",
    "  case2, sub_label = 'person_name' and obj_label = 'nuts;, such as \"\"Andrew is [MASK].\", [MASK]=nuts\n",
    "  '''\n",
    "  sub_labels_to_exclude = ['10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '30', '5', '50', '60', '7', '70', '70s', '80', '9', '90']\n",
    "  obj_labels_to_exclude  = ['nuts']\n",
    "  df = df.query(f\"sub_label not in {sub_labels_to_exclude}\")\n",
    "  df = df.query(f\"sub_label not in {obj_labels_to_exclude}\")\n",
    "  return  df.reset_index(drop=True)\n",
    "\n",
    "def locate_sub_obj_position(ent, sentence, index_not_in) :\n",
    "  ''' \n",
    "  function: find the index of ent in a sentence, the result will be used to filter instances whose ent cannot be find at their sentences\n",
    "  args: \n",
    "    sentence: the sentnces to mask, could be the string or a list of tokens \n",
    "    ent: the ent to be found (sub_label) \n",
    "    index_not_in: the default index for failed instances (an ent not in a sentence)\n",
    "  ''' \n",
    "\n",
    "  if isinstance(sentence, list):\n",
    "    if ent not in sentence:\n",
    "      return index_not_in\n",
    "    return sentence.index(ent)  \n",
    "  else:\n",
    "    sentence = copy.deepcopy(sentence).lower()\n",
    "    if isinstance(sentence, str):\n",
    "      try:\n",
    "        index = sentence.index(ent)\n",
    "        return  index \n",
    "      except: \n",
    "        print(f\"NOT FOUND sub_label: {ent} -> in sentence: {sentence}\")\n",
    "        return index_not_in\n",
    "      \n",
    "        print(ent, sentence)\n",
    "        return index_not_in\n",
    "\n",
    "\n",
    "\n",
    "def get_unmasker(model, targets=None):\n",
    "    if targets is None: \n",
    "        unmasker = pipeline('fill-mask', model=model)# 'bert-large-uncased') #initialize the masker\n",
    "    else:\n",
    "        unmasker = pipeline('fill-mask', model=model, targets=targets )# 'bert-large-uncased') #initialize the masker\n",
    "    return unmasker\n",
    "\n",
    "\n",
    "def get_highest_mrr_among_labels(label, pred):\n",
    "    '''\n",
    "    return the highest rank among the multiple labels. This is applicable to single labels as well, if we the single label is put in a list\n",
    "\n",
    "    pred: a list of words (candidates)\n",
    "    label: the true labels, which is a list (different forms of a word, e.g., singular or plurs, like animal and animals)\n",
    "    '''\n",
    "    mrr = 0 \n",
    "    if pred is None: return mrr \n",
    "\n",
    "    rank_list = [ pred.index(item) + 1 for item in label if item in pred] \n",
    "    if len(rank_list)>0:\n",
    "        mrr = 1/min(rank_list)\n",
    "    return mrr \n",
    "\n",
    "\n",
    "def get_predictions(input_words, outputs, filter_objects_flag=True, filter_objects_with_input=True):\n",
    "    '''\n",
    "    excluding x from outputs\n",
    "    '''\n",
    "    filled_tokens = list()\n",
    "    filled_scores = defaultdict()\n",
    "    for i, output in enumerate(outputs):\n",
    "#         print(output)\n",
    "        filled_token = output['token_str'].strip().lower()\n",
    "        filled_score = output['score']\n",
    "        if filter_objects_flag:\n",
    "            \n",
    "            #####Add conditions to filter unwanted ################\n",
    "            # filter the repetation of a concept in the explanation. See the the following example\n",
    "            # [MASK] is the capability to do a particular job . -> capacity \n",
    "            if not filled_token.isalpha(): continue\n",
    "            if filled_token in STOP_WORDS: continue \n",
    "            if len(filled_token)<=1: continue \n",
    "            if filter_objects_with_input:\n",
    "                if filled_token in [input_words]: continue\n",
    "                # [re.sub(\"\\s+\", '', x) for x in input_word.split()]: continue #filter out the target in input  \n",
    "            if filled_token.startswith(\"#\"): continue\n",
    "            #####Add conditions to filter unwanted ################\n",
    "\n",
    "            filled_tokens.append(filled_token)\n",
    "            filled_scores[filled_token] = filled_score\n",
    "        else:\n",
    "            filled_tokens.append(filled_token)\n",
    "            filled_scores[filled_token] = filled_score\n",
    "    \n",
    "    return pd.Series((filled_tokens, filled_scores))\n",
    "\n",
    "\n",
    "\n",
    "def load_data(filepath, clean_test=True, tokenize=False):\n",
    "  '''\n",
    "  return the cleaned data\n",
    "  args:\n",
    "    tokenize: if True: the maksed_sentences will be tokenzied (this is slwoers); \n",
    "            otherwise, we use the string match to filter the failed sentences\n",
    "    clean_test: default is True. We filter out some noisy samples spoted by huamns \n",
    "               Note that this is relation specific \n",
    "\n",
    "  '''\n",
    "  index_not_in = 10000\n",
    "\n",
    "  with open(filepath, 'r', encoding='utf-8') as fin:\n",
    "    data_raw = fin.readlines()\n",
    "    data = []\n",
    "    for x in data_raw:\n",
    "        x = eval(x)\n",
    "        if not x['sub_label'] in model.key_to_index: continue  ### exluding OOV; or if word not in model\n",
    "        data.append(x)\n",
    "        #data = [eval(x) for x in data]\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df['obj_label'] = df['obj_label'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "\n",
    "  if tokenize:\n",
    "    df['masked_sentence_tokens'] = df['masked_sentences'].apply(lambda x: tokenize_sentence(x[0]))\n",
    "    df['sub_position'] = df[['sub_label', 'masked_sentence_tokens']].apply(lambda x: locate_sub_obj_position(x[0], x[1], index_not_in=index_not_in), axis=1)\n",
    "\n",
    "  if clean_test: \n",
    "    df = remove_noisy_test_data(df)\n",
    "    df['sub_position'] = df[['sub_label', 'masked_sentences']].apply(lambda x: locate_sub_obj_position(x[0], x[1][0], index_not_in), axis=1)\n",
    "    df = df.query(f\"sub_position !={index_not_in}\") #.reset_index() #cue can not be matched in the sentence\n",
    "\n",
    "  print(f\"#Test_instances: {len(df.index)}\")\n",
    "  return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def layout_table(df, dataset_list = ['BLESS','LMDIAG', 'CLSB',  'SHWARTZ', 'EVAL', 'LEDS']):\n",
    "    '''\n",
    "    format the output with desired dataset layout and metrics \n",
    "    '''\n",
    "    df_groups = []\n",
    "    for dataset in dataset_list: \n",
    "       \n",
    "        df_group = df.query(f\"dataset == '{dataset}'\")\n",
    "        df_group = df_group.pivot(index=\"pattern_id\", columns=['dataset'], values=['MRR', 'P@K'])\n",
    "        df_group = df_group.swaplevel(0, 1, axis=1)\n",
    "        df_groups.append(df_group)\n",
    "\n",
    "    df_groups = pd.concat(df_groups, axis=1)\n",
    "    return df_groups\n",
    "\n",
    "dataset_to_jsonl_path={\n",
    "    \"EVAL\": \"../data/hypernymysuite/data/hypernymsuite/EVAL/IsA.jsonl\",\n",
    "    \"BLESS\": \"../data/hypernymysuite/data/hypernymsuite/BLESS/IsA.jsonl\",\n",
    "    \"LEDS\": \"../data/hypernymysuite/data/hypernymsuite/LEDS/IsA.jsonl\",\n",
    "    \"LMDIAG\": \"../data/probe-generalization/Syntagmatic/LM-Diagnostic-Extended/singular/IsA.jsonl\",\n",
    "    \"CLSB\": \"../data/CLSB/single_label/IsA.jsonl\",\n",
    "    \"SHWARTZ\": \"../data/hypernymysuite/data/hypernymsuite/SHWARTZ/IsA.jsonl\",\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Hypernyms in KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dogs', 'puppy', 'pit_bull', 'pooch', 'cat', 'golden_retriever', 'German_shepherd', 'Rottweiler', 'beagle', 'pup']\n"
     ]
    }
   ],
   "source": [
    "def get_knn(model, word, topn=10, return_score=False):\n",
    "    neighbours = model.most_similar([model[word]], topn=topn+1)[1:]\n",
    "    if return_score: \n",
    "        return neighbours\n",
    "    return [x[0] for x in neighbours]\n",
    "\n",
    "neighbours = get_knn(model, 'dog')\n",
    "print(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL\n",
      "#Test_instances: 957\n",
      "#Test_instances: 957 (excluding OOV)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 957/957 [10:11<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K: 0.04597701149425287 MRR:0.019862002620623313\n",
      "\n",
      "BLESS\n",
      "#Test_instances: 1329\n",
      "#Test_instances: 1329 (excluding OOV)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1329/1329 [10:04<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K: 0.0398796087283672 MRR:0.012590323312670942\n",
      "\n",
      "LEDS\n",
      "#Test_instances: 1370\n",
      "#Test_instances: 1370 (excluding OOV)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1370/1370 [10:23<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K: 0.06715328467153285 MRR:0.022570675472135326\n",
      "\n",
      "LMDIAG\n",
      "#Test_instances: 483\n",
      "#Test_instances: 483 (excluding OOV)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 483/483 [03:48<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K: 0.051759834368530024 MRR:0.015279831739459068\n",
      "\n",
      "CLSB\n",
      "#Test_instances: 1285\n",
      "#Test_instances: 1285 (excluding OOV)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1285/1285 [19:02<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@K: 0.10894941634241245 MRR:0.038597677722191345\n",
      "\n",
      "SHWARTZ\n",
      "#Test_instances: 7242\n",
      "#Test_instances: 7242 (excluding OOV)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 6940/7242 [57:31<02:05,  2.41it/s]  "
     ]
    }
   ],
   "source": [
    "\n",
    "df_res = []\n",
    "top_k = 10\n",
    "debug=False #True\n",
    "\n",
    "for dataset, filepath in dataset_to_jsonl_path.items():\n",
    "    print(dataset)\n",
    "    df = load_data(filepath)\n",
    "    print(f\"#Test_instances: {len(df.index)} (excluding OOV)\")\n",
    "    if debug:\n",
    "        df = df.head(5)\n",
    "        \n",
    "    df['sub_neighbours'] = df['sub_label'].progress_apply(lambda x: get_knn(model=model, word=x, topn=top_k))\n",
    "    df[f'p@{top_k}'] = df[['obj_label', 'sub_neighbours']].apply(lambda x: 1 if x[0][0] in x[1]  else 0, axis=1)\n",
    "    df[f'mrr@{top_k}'] = df[['obj_label', 'sub_neighbours']].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "\n",
    "    p_at_k = df[f'p@{top_k}'].sum()/len(df.index)\n",
    "    mrr = df[f'mrr@{top_k}'].sum()/len(df.index)\n",
    "    df_res.append({\"dataset\": dataset, \"P@K\": p_at_k, 'MRR': mrr})\n",
    "    print(f\"P@K: {p_at_k} MRR:{mrr}\")\n",
    "    print()\n",
    "df_res = pd.DataFrame(df_res)\n",
    "display(df_res)\n",
    "df_res.to_csv(\"../log/221217_baseline_word2vec.csv\")\n",
    "\n",
    "\n",
    "DataFrame2Latex(df= df_res , label=f'tab:baseline_word2vec', \n",
    "            caption=f'Experimental results on extracting hypernyms with word2vec.', \n",
    "            output_file= None , #'../log/paper_results/latex.test.tex',\n",
    "            adjustbox_width = 'textwidth',\n",
    "            precision = 1,\n",
    "            column_format='l|ll|ll|ll|ll|ll|ll',\n",
    "            multicolumn_format='c|'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dog = model['dog']\n",
    "# print(dog.shape)\n",
    "# print(dog[:10])\n",
    "\n",
    "# # Deal with an out of dictionary word: Михаил (Michail)\n",
    "# if 'Михаил' in model:\n",
    "#     print(model['Михаил'].shape)\n",
    "# else:\n",
    "#     print('{0} is an out of dictionary word'.format('Михаил'))\n",
    "\n",
    "# # Some predefined functions that show content related information for given words\n",
    "# print(model.most_similar(positive=['woman', 'king'], negative=['man']))\n",
    "# print(model.doesnt_match(\"breakfast cereal dinner lunch\".split()))\n",
    "# print(model.similarity('woman', 'man'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
