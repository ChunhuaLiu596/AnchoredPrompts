{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d541f55-85dd-438d-a1c7-b74e5a6d2252",
   "metadata": {},
   "source": [
    "# Check vocab overlap (SW + hypernym datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a79d19-5d91-4428-9ad7-517eadfe787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug False\n",
      "dataset BLESS\n",
      "200\n",
      "dataset DIAG\n",
      "758\n",
      "dataset CLSB\n",
      "1087\n",
      "dataset LEDS\n",
      "1987\n",
      "dataset EVAL\n",
      "2450\n",
      "dataset SHWARTZ\n",
      "12826\n"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "import pandas as pd\n",
    "pd.options.display.max_columns=500\n",
    "pd.options.display.max_colwidth=1000\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "import re \n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from tabulate import tabulate, simple_separated_format\n",
    "from inflection import singularize, pluralize\n",
    "from df_to_latex import DataFrame2Latex\n",
    "from collections import Counter, defaultdict\n",
    "from inflection import singularize, pluralize\n",
    "\n",
    "from utils_path import dataset_to_respath\n",
    "# # Using WN, WN.taxonomy to retrieve path distance \n",
    "# - Pointers: \n",
    "#     - https://wn.readthedocs.io/en/latest/setup.html\n",
    "#     - https://wn.readthedocs.io/en/latest/api/wn.html\n",
    "# \n",
    "# - Installation: \n",
    "# ```\n",
    "# !pip install wn\n",
    "# !pip install wn[web]\n",
    "# wn.download('ewn:2020')\n",
    "# ```\n",
    "\n",
    "# get the co-hyponyms from WordNet (Shick and Schutze, 2020)\n",
    "# - get the hypernyms, maxinum d(x,y) is 2\n",
    "# - get the top 2 most frequent senses of each hypernym \n",
    "# - get hyponyms of each hypernyms, maxinum distance d(y,z) is 4 \n",
    "# - constrain the depeth of hypernyms to be 6\n",
    "\n",
    "# In[201]:\n",
    "\n",
    "\n",
    "import re \n",
    "import wn, wn.taxonomy\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "\n",
    "def test_min_depth():\n",
    "    for word in ['concept', 'thought', 'living thing', 'whole', 'psychological feature', 'unit', 'artifact', 'abstraction', 'object','physical entity', 'entity']:\n",
    "        synset = wn.synsets(word, pos='n')[0]\n",
    "        min_depth = wn.taxonomy.min_depth(synset, simulate_root=False)\n",
    "        print(word, min_depth)\n",
    "\n",
    "\n",
    "def get_inherited_hypernyms(word, k_synset, max_path_hyper, min_taxo_depth=6, print_flag=False):\n",
    "    '''\n",
    "    k_synset: the most frequent k_synset of word\n",
    "    max_path_hyper: up to k level of hypernyms, e.g., 2 level higher than word \n",
    "    min_taxo_depth=6: concept, exluded hypernyms: unit, object, artifact, entity\n",
    "    '''\n",
    "    \n",
    "    hyper_synsets = []\n",
    "    for i, synset in enumerate(wn.synsets(word, pos='n')[:k_synset]): #top K senses of word \n",
    "        #print(f\"{word} synset {i+1}\")\n",
    "        for j, path in enumerate(wn.taxonomy.hypernym_paths(synset)): #retrieve the hyper path for each synset \n",
    "            #print(f\"path {j}\")\n",
    "            for i, ss in enumerate(path[:max_path_hyper]): # get the hypernyms within max_path_hyper\n",
    "                ss_min_txo_depth = wn.taxonomy.min_depth(ss, simulate_root=False)\n",
    "                \n",
    "                if ss_min_txo_depth< min_taxo_depth: continue  #remove general concepts like \"entity\", 'physical entity'\n",
    "                hyper_synsets.append(ss)\n",
    "                if print_flag: \n",
    "                    print(' ' * i, ss, ss.lemmas()[0], ss_min_txo_depth)\n",
    "                    \n",
    "    return hyper_synsets\n",
    "\n",
    "def get_direct_hyonyms(synsets):\n",
    "    '''\n",
    "    Return the direct hyponyms of a given list of synsets\n",
    "    ''' \n",
    "    sister_synsets = []\n",
    "    for synset in synsets: \n",
    "        sister_synsets.extend(synset.hyponyms() )\n",
    "    return sister_synsets\n",
    "\n",
    "\n",
    "def get_inherited_hyponyms(initial_synsets, max_path_hypo):\n",
    "    synsets = initial_synsets\n",
    "    synsets_hyponyms = []\n",
    "    \n",
    "    while max_path_hypo>0:\n",
    "        synsets = get_direct_hyonyms(synsets)\n",
    "        synsets_hyponyms.extend(synsets)\n",
    "        max_path_hypo -=1\n",
    "        #print(dist)\n",
    "        #print(synsets)\n",
    "        #print(\"-\"*80)\n",
    "    #print(Counter(synsets_all).most_common())\n",
    "    return synsets_hyponyms\n",
    "\n",
    "\n",
    "def filter_cohyponyms(word, synsets_cohyponyms, top_k=50):\n",
    "    cohyponyms = []\n",
    "    for synset in synsets_cohyponyms:\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma == word: continue \n",
    "            if len(lemma.split(\" \")) >1 or len(lemma.split(\"-\")) >1: continue \n",
    "            cohyponyms.append(lemma.lower())\n",
    "    cohyponyms = Counter(cohyponyms)\n",
    "     #if top_k !=None:        \n",
    "    return cohyponyms.most_common(top_k)\n",
    "    #else:\n",
    "    #    return dict(cohyponyms.most_common())\n",
    "\n",
    "    \n",
    "def get_cohyponyms(word, top_k_cohyonyms=50, top_k_word_synset=2, max_path_hyper=2, max_path_hypo =4, print_flag=False):\n",
    "    \n",
    "    hyper_synsets = get_inherited_hypernyms(word, k_synset=top_k_word_synset, max_path_hyper = max_path_hyper)\n",
    "    if print_flag:\n",
    "        for synset in hyper_synsets:\n",
    "            print(synset, synset.lemmas())\n",
    "\n",
    "    synsets_cohyponyms = get_inherited_hyponyms(hyper_synsets, max_path_hypo= max_path_hypo)\n",
    "\n",
    "    concept_cohyponyms = filter_cohyponyms(word, synsets_cohyponyms, top_k=top_k_cohyonyms)\n",
    "    return list(dict(concept_cohyponyms).keys())\n",
    "   \n",
    "\n",
    "def test_get_cohyponyms(word, test_cohyponyms):\n",
    "    '''\n",
    "    word = 'corn'\n",
    "    test_cohyponyms = ['bean', 'potato', 'barley', 'wheat', 'pea'] \n",
    "    word = 'train'\n",
    "    test_cohyponyms = ['bus', 'plane', 'car', 'tram', 'truck']\n",
    "    test_get_cohyponyms(word,test_cohyponyms )\n",
    "    '''\n",
    "    top_k_cohyonyms = None #200 \n",
    "    top_k_word_synset = 2\n",
    "    max_path_hyper = 2\n",
    "    max_path_hypo = 4\n",
    "\n",
    "    concept_cohyponyms  = get_cohyponyms(word, top_k_cohyonyms=top_k_cohyonyms, \n",
    "                                         top_k_word_synset=top_k_word_synset, \n",
    "                                         max_path_hyper=max_path_hyper, max_path_hypo = max_path_hypo)\n",
    "    \n",
    "    for query in test_cohyponyms:\n",
    "        if query in concept_cohyponyms:\n",
    "            print(query, 'yes')\n",
    "        else:\n",
    "            print(query, 'no')\n",
    "    print(len(concept_cohyponyms), concept_cohyponyms)\n",
    "\n",
    "\n",
    "\n",
    "# # Evaluation \n",
    "\n",
    "# In[225]:\n",
    "\n",
    "\n",
    "def merge_predictions_in_concept_level(words, uniform_funcion=None, top_k=None ):\n",
    "    '''\n",
    "    uniform_function: either signualarize or pluralize \n",
    "    '''\n",
    "    words_uniformed = [uniform_funcion(word) for word in words] if uniform_funcion !=None else words\n",
    "    concepts = list(OrderedDict.fromkeys(words_uniformed))\n",
    "    return concepts[:top_k] if top_k is not None else concepts\n",
    "\n",
    "def concept_evaluation(label, pred):\n",
    "    '''\n",
    "    \n",
    "    label: a list with the singualr and plural labels (e.g., ['tool', 'tools'])\n",
    "    pred: the top K prediction list \n",
    "\n",
    "    return:\n",
    "        1 if label share with pred else 0  \n",
    "    '''\n",
    "    if not isinstance(label, list):\n",
    "        label = eval(label)\n",
    "        \n",
    "    if not isinstance(pred, list):\n",
    "        pred = eval(pred)\n",
    "\n",
    "    shared = set(label).intersection(set(pred))\n",
    "    return 1 if len(shared)>0 else 0 \n",
    "    # return len(shared)/len(pred)\n",
    "    \n",
    "\n",
    "def get_precision_at_k_concept(df, relation, pred_cols, label_col, k_list, pred_col_suffix='obj_mask_'):\n",
    "    '''\n",
    "    evalaute model predictions in concept level, ignoring the morphology affects (singular, plural)\n",
    "    '''\n",
    "\n",
    "    p_at_x = [] #defaultdict() \n",
    "    for pred_col in pred_cols: \n",
    "        suffix = pred_col.replace(pred_col_suffix, \"\")\n",
    "        prec_cur = defaultdict()\n",
    "        prec_cur['mask_type'] = suffix\n",
    "        for k in k_list: \n",
    "            df[f'p{k}_{suffix}'] = df[[label_col, pred_col]].apply(lambda x: concept_evaluation(x[0], eval(x[1])[:k] if isinstance(x[1], str) else x[1][:k]), axis=1 )\n",
    "            prec_cur[f'p@{k}'] = round(df[f'p{k}_{suffix}'].mean() , 3)*100\n",
    "\n",
    "        p_at_x.append(prec_cur)  \n",
    "        \n",
    "\n",
    "    # aggregate the average precision across k \n",
    "    df_res = pd.DataFrame(p_at_x) #, columns=['mask_type', 'mAP'])\n",
    "    df_res['relation'] = [relation]*len(df_res)\n",
    "    return df_res\n",
    "\n",
    "def get_highest_mrr_among_labels(label, pred):\n",
    "    '''\n",
    "    return the highest rank among the multiple labels. This is applicable to single labels as well, if we the single label is put in a list\n",
    "\n",
    "    pred: a list of words (candidates)\n",
    "    label: the true labels, which is a list (different forms of a word, e.g., singular or plurs, like animal and animals)\n",
    "    '''\n",
    "    mrr = 0 \n",
    "    if pred is None: return mrr \n",
    "\n",
    "    rank_list = [ pred.index(item) + 1 for item in label if item in pred] \n",
    "    if len(rank_list)>0:\n",
    "        mrr = 1/min(rank_list)\n",
    "\n",
    "    return mrr \n",
    "\n",
    "\n",
    "def get_mrr(df, relation, pred_cols, label_col, pred_col_suffix):\n",
    "    '''\n",
    "    mrr is calculated based on the top_k rank, all elements in obj_col are used\n",
    "    '''\n",
    "\n",
    "    mrr = [] \n",
    "    for i, pred_col in enumerate(pred_cols):\n",
    "        cur_mrr = defaultdict()\n",
    "        suffix = pred_col.replace(pred_col_suffix, \"\")\n",
    "\n",
    "        df[f'mrr_{suffix}'] = df[[label_col, pred_col]].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1 ) \n",
    "        \n",
    "        cur_mrr['mask_type'] = suffix\n",
    "        cur_mrr[f\"mrr\"] = round(df[f'mrr_{suffix}'].mean(), 3)*100\n",
    "        mrr.append(cur_mrr)\n",
    "\n",
    "    mrr_df =  pd.DataFrame(data = mrr) #, columns=['mask_type', 'mrr'])\n",
    "    # mrr_df['mask_type']= mrr_df['mask_type'].apply(lambda x: x.replace(\"\"))\n",
    "    mrr_df['relation'] = relation\n",
    "    return mrr_df \n",
    "\n",
    "\n",
    "# In[202]:\n",
    "\n",
    "\n",
    "def get_dataset_to_respath(dataset_to_respath, print_flag=False):\n",
    "    # remote path \n",
    "#     dataset_to_respath = {'hypernymsuite-BLESS': 'log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'lm_diagnostic_extended-singular': 'log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv', 'clsb-singular': 'log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv', 'hypernymsuite-LEDS': 'log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-EVAL': 'log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-SHWARTZ': 'log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv'}\n",
    "\n",
    "    source_dir = 'spartan:~/cogsci/DAP/'\n",
    "    target_dir = '../../'\n",
    "    dataset_to_localpath = defaultdict()\n",
    "    dataset_rename = {\n",
    "        'hypernymsuite-BLESS': 'BLESS', 'lm_diagnostic_extended-singular': 'DIAG', 'clsb-singular':'CLSB', 'hypernymsuite-LEDS': 'LEDS', 'hypernymsuite-EVAL': 'EVAL', 'hypernymsuite-SHWARTZ': \n",
    "        \"SHWARTZ\"\n",
    "    }\n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        path = path.replace(\".tsv\", \".csv\")\n",
    "        source_path = source_dir + path \n",
    "        dataset_l1 = dataset.split(\"-\")[0]\n",
    "        dataset_l2 = dataset.split(\"-\")[1] \n",
    "        target_path = target_dir + path\n",
    "        scp_string = f\"!scp {source_path} {target_path}\"\n",
    "        if print_flag:\n",
    "            print(scp_string)\n",
    "            print()\n",
    "#         print(target_path)\n",
    "        dataset_to_localpath[dataset_rename[dataset]] = target_path \n",
    "#     print(dataset_to_localpath)\n",
    "    return dataset_to_localpath\n",
    "dataset_to_localpath = get_dataset_to_respath(dataset_to_respath)\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet \n",
    "wn_lemmas = set(wordnet.all_lemma_names())\n",
    "def check_word_in_wordnet(word, wn_lemmas):\n",
    "    '''\n",
    "    1 if word in wordnet else 0\n",
    "    '''\n",
    "    return 1 if word in wn_lemmas else 0 \n",
    "\n",
    "\n",
    "def get_all_vocab(dataset_to_localpath):\n",
    "    dataset_to_df = defaultdict()\n",
    "    vocab_sub = set()\n",
    "    for dataset, path in dataset_to_localpath.items(): \n",
    "        if debug:\n",
    "           if dataset!='DIAG': continue \n",
    "        print(\"dataset\", dataset)\n",
    "        df = pd.read_csv(path)\n",
    "        vocab_sub.update(df['sub_label_sg'].to_list())\n",
    "        print(len(vocab_sub))\n",
    "    return list(vocab_sub)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Config for getting co-hyponyms from WordNet\n",
    "top_k_cohyonyms = None #200 \n",
    "top_k_word_synset = 2\n",
    "max_path_hyper = 2\n",
    "max_path_hypo = 4\n",
    "\n",
    "#config for evaluation \n",
    "pred_col_suffix=''\n",
    "label_col = 'sub_sister_new'\n",
    "pred_cols = ['subj_anchors_all_sg']\n",
    "relation='co-hyponyms'\n",
    "debug= False #True #eval(sys.argv[1])\n",
    "print(\"debug\", debug)\n",
    "\n",
    "\n",
    "vocab_sub = get_all_vocab(dataset_to_localpath)\n",
    "word_to_cohyponyms = defaultdict(list)\n",
    "\n",
    "# for i, word in enumerate(vocab_sub):\n",
    "#     if i%10==0: print(i)\n",
    "#     if not check_word_in_wordnet(word, wn_lemmas):\n",
    "#         word_to_cohyponyms[word] = []\n",
    "#     else:\n",
    "#         cohyponyms = get_cohyponyms(word, top_k_cohyonyms=top_k_cohyonyms, \n",
    "#                                  top_k_word_synset=top_k_word_synset, \n",
    "#                                  max_path_hyper=max_path_hyper, \n",
    "#                                  max_path_hypo = max_path_hypo)\n",
    "#         word_to_cohyponyms[word] = cohyponyms\n",
    "#     if debug:\n",
    "#         print(word, cohyponyms)\n",
    "# df = pd.DataFrame(word_to_cohyponyms.items(), columns=['word', 'cohyponyms'])\n",
    "# output_path = '../log/word_to_cohyponyms.txt'\n",
    "# df.to_csv(output_path, index=False)\n",
    "# print(f\"save {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c383b6-ad51-4744-a9a8-2fb1ea6318b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "query_words = ['dog','grain', 'mountains' ]\n",
    "for word in query_words: \n",
    "    cohyponyms = get_cohyponyms(word, top_k_cohyonyms=top_k_cohyonyms, \n",
    "                                      top_k_word_synset=top_k_word_synset, \n",
    "                                     max_path_hyper=max_path_hyper, \n",
    "                                     max_path_hypo = max_path_hypo)\n",
    "    word_to_cohyponyms[word] = cohyponyms\n",
    "print(word_to_cohyponyms[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42b02d7-8b1c-4678-97c4-c61ef795c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:21:45\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bb9b37-4989-40de-8b28-f74238220cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_word_in_wordnet('mountain', wn_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2333544-02eb-4285-926f-b61126a43d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict \n",
    "import json \n",
    "import wn\n",
    "from inflection import singularize, pluralize \n",
    "import os, sys\n",
    "from wn.similarity import path\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "\n",
    "\n",
    "def read_cohyponyms(path = '../log/word_to_cohyponyms.txt'):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"reading cohyponyms: {path}\")\n",
    "        df = pd.read_csv(path)\n",
    "        word_to_cohyponym = dict(zip(df['word'], df['cohyponyms']))\n",
    "        return word_to_cohyponym\n",
    "    print(f\"{path} not found\")\n",
    "\n",
    "    \n",
    "\n",
    "def write_cohyponym_scores(word_to_cohyponyms_score, output_path):\n",
    "    with open(output_path, 'w') as fout:\n",
    "        json.dump(word_to_cohyponyms_score, fout, indent=4)\n",
    "    print(output_path)\n",
    "\n",
    "def get_path_score_for_cohyponyms(word_to_cohyponyms, debug=False):\n",
    "    word_to_cohyponyms_score = defaultdict()\n",
    "    if debug:    \n",
    "        query_words = ['dog', 'wolf', 'corn', 'car']\n",
    "    else: \n",
    "        query_words = word_to_cohyponyms.keys()\n",
    "        \n",
    "    for k in query_words: \n",
    "        k_pl = pluralize(k)\n",
    "        cur_cohyponyms_to_score = defaultdict()\n",
    "        if len(word_to_cohyponyms[k])==0: continue \n",
    "        for v in eval(word_to_cohyponyms[k]):\n",
    "            score = get_shortest_path_score(k, v)\n",
    "            v = pluralize(v)\n",
    "            cur_cohyponyms_to_score[v] = round(score, 4)\n",
    "        cur_cohyponyms_to_score = dict(sorted(cur_cohyponyms_to_score.items(), key=lambda x: x[1], reverse=True))\n",
    "        word_to_cohyponyms_score[k_pl] = cur_cohyponyms_to_score\n",
    "    return word_to_cohyponyms_score\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    debug=False \n",
    "    # debug=True \n",
    "    word_to_cohyponyms = read_cohyponyms()\n",
    "    word_to_cohyponyms_score = get_path_score_for_cohyponyms(word_to_cohyponyms, debug=debug)\n",
    "#     output_path = '../log/word_to_cohyponyms_score_pl.json'\n",
    "#     write_cohyponym_scores(word_to_cohyponyms_score, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c275726f-761c-478a-bfd1-37fb2249ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shortest_path_score(word1, word2):\n",
    "    synsets1 = ewn.synsets(word1, pos='n')    \n",
    "    synsets2 = ewn.synsets(word2, pos='n')\n",
    "    if len(synsets1)==0 or len(synsets2)==0: return 0 \n",
    "    scores = []\n",
    "    for synset1 in synsets1:\n",
    "        for synset2 in synsets2:\n",
    "            scores.append(path(synset1, synset2  ))\n",
    "    return max(scores) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f8c670d-4e7e-4918-8def-83a5f2e6ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "k='tiger'\n",
    "v= 'lion'\n",
    "score = get_shortest_path_score(k, v)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11d0c9ad-30c3-4b30-ac2e-dc6422a968b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# path = \"../../log/bert-large-uncased/ALL/SWOWStrength/df_all_use_global_dap_True_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_anchor_source_WordNet_wns_False_wnf_False_swow_score_source_None.ALLSWOW.csv\"\n",
    "path = \"../../log/bert-large-uncased/ALL/SWOWStrength/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_SWOW_swow_score_source_None.HYPERNYMSUITE.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed920663-aa32-440b-b421-6b179ae31a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"['citrus']\", \"['food']\", \"['produce']\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.query(\"sub_label_sg == 'lime'\")['obj_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cd68a32-1e8c-408b-900b-1f5d2c0a701c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('castle', 11),\n",
       " ('robe', 11),\n",
       " ('blouse', 11),\n",
       " ('sweater', 10),\n",
       " ('television', 10),\n",
       " ('vest', 10),\n",
       " ('shirt', 9),\n",
       " ('scarf', 9),\n",
       " ('phone', 9),\n",
       " ('jacket', 9),\n",
       " ('missile', 8),\n",
       " ('cannon', 8),\n",
       " ('library', 8),\n",
       " ('bowl', 7),\n",
       " ('spear', 7),\n",
       " ('radio', 7),\n",
       " ('pistol', 7),\n",
       " ('book', 7),\n",
       " ('rifle', 6),\n",
       " ('toaster', 6),\n",
       " ('revolver', 6),\n",
       " ('cathedral', 6),\n",
       " ('bed', 6),\n",
       " ('jet', 6),\n",
       " ('stove', 6),\n",
       " ('trumpet', 6),\n",
       " ('washer', 6),\n",
       " ('stereo', 6),\n",
       " ('tea', 6),\n",
       " ('sport', 6),\n",
       " ('catfish', 5),\n",
       " ('rabbit', 5),\n",
       " ('sieve', 5),\n",
       " ('oven', 5),\n",
       " ('bomb', 5),\n",
       " ('bomber', 5),\n",
       " ('violin', 5),\n",
       " ('chair', 5),\n",
       " ('box', 5),\n",
       " ('sofa', 5),\n",
       " ('mug', 5),\n",
       " ('spade', 5),\n",
       " ('onion', 5),\n",
       " ('sword', 5),\n",
       " ('car', 5),\n",
       " ('chestnut', 5),\n",
       " ('machete', 5),\n",
       " ('puppet', 5),\n",
       " ('baby', 5),\n",
       " ('man', 5),\n",
       " ('son', 5),\n",
       " ('iron', 5),\n",
       " ('water', 5),\n",
       " ('turtle', 4),\n",
       " ('piano', 4),\n",
       " ('pub', 4),\n",
       " ('beet', 4),\n",
       " ('clarinet', 4),\n",
       " ('cello', 4),\n",
       " ('spinach', 4),\n",
       " ('celery', 4),\n",
       " ('turnip', 4),\n",
       " ('shovel', 4),\n",
       " ('vulture', 4),\n",
       " ('apple', 4),\n",
       " ('saxophone', 4),\n",
       " ('rat', 4),\n",
       " ('wrench', 4),\n",
       " ('bear', 4),\n",
       " ('yacht', 4),\n",
       " ('bottle', 4),\n",
       " ('tuna', 4),\n",
       " ('train', 4),\n",
       " ('arrow', 4),\n",
       " ('badge', 4),\n",
       " ('balloon', 4),\n",
       " ('bean', 4),\n",
       " ('brandy', 4),\n",
       " ('caravan', 4),\n",
       " ('chicken', 4),\n",
       " ('chipmunk', 4),\n",
       " ('chocolate', 4),\n",
       " ('leopard', 4),\n",
       " ('milk', 4),\n",
       " ('mosquito', 4),\n",
       " ('mouse', 4),\n",
       " ('panther', 4),\n",
       " ('peanut', 4),\n",
       " ('raisin', 4),\n",
       " ('rocket', 4),\n",
       " ('rose', 4),\n",
       " ('slug', 4),\n",
       " ('submarine', 4),\n",
       " ('tank', 4),\n",
       " ('valium', 4),\n",
       " ('wheel', 4),\n",
       " ('soprano', 4),\n",
       " ('whiskey', 4),\n",
       " ('love', 4),\n",
       " ('parent', 4),\n",
       " ('baseball', 4),\n",
       " ('market', 4),\n",
       " ('person', 4),\n",
       " ('pit', 4),\n",
       " ('queen', 4),\n",
       " ('sex', 4),\n",
       " ('sound', 4),\n",
       " ('star', 4),\n",
       " ('time', 4),\n",
       " ('lemon', 3),\n",
       " ('bag', 3),\n",
       " ('squirrel', 3),\n",
       " ('whale', 3),\n",
       " ('banana', 3),\n",
       " ('axe', 3),\n",
       " ('rake', 3),\n",
       " ('scooter', 3),\n",
       " ('cauliflower', 3),\n",
       " ('tiger', 3),\n",
       " ('wardrobe', 3),\n",
       " ('beetle', 3),\n",
       " ('parsley', 3),\n",
       " ('cabbage', 3),\n",
       " ('screwdriver', 3),\n",
       " ('saw', 3),\n",
       " ('pheasant', 3),\n",
       " ('radish', 3),\n",
       " ('jar', 3),\n",
       " ('salmon', 3),\n",
       " ('lettuce', 3),\n",
       " ('cedar', 3),\n",
       " ('carrot', 3),\n",
       " ('plum', 3),\n",
       " ('sheep', 3),\n",
       " ('lion', 3),\n",
       " ('bookcase', 3),\n",
       " ('bull', 3),\n",
       " ('strawberry', 3),\n",
       " ('bus', 3),\n",
       " ('cat', 3),\n",
       " ('table', 3),\n",
       " ('lizard', 3),\n",
       " ('spoon', 3),\n",
       " ('ant', 3),\n",
       " ('chisel', 3),\n",
       " ('truck', 3),\n",
       " ('lime', 3),\n",
       " ('ambulance', 3),\n",
       " ('pig', 3),\n",
       " ('broccoli', 3),\n",
       " ('skateboard', 3),\n",
       " ('barge', 3),\n",
       " ('ship', 3),\n",
       " ('avocado', 3),\n",
       " ('basin', 3),\n",
       " ('bath', 3),\n",
       " ('beer', 3),\n",
       " ('bridge', 3),\n",
       " ('budgie', 3),\n",
       " ('butter', 3),\n",
       " ('cage', 3),\n",
       " ('cake', 3),\n",
       " ('calf', 3),\n",
       " ('canary', 3),\n",
       " ('centipede', 3),\n",
       " ('certificate', 3),\n",
       " ('chainsaw', 3),\n",
       " ('cheetah', 3),\n",
       " ('cider', 3),\n",
       " ('jam', 3),\n",
       " ('kite', 3),\n",
       " ('ladybird', 3),\n",
       " ('lamb', 3),\n",
       " ('mayonnaise', 3),\n",
       " ('moose', 3),\n",
       " ('nightingale', 3),\n",
       " ('parakeet', 3),\n",
       " ('perfume', 3),\n",
       " ('poison', 3),\n",
       " ('poppy', 3),\n",
       " ('prune', 3),\n",
       " ('pumpkin', 3),\n",
       " ('pyramid', 3),\n",
       " ('raccoon', 3),\n",
       " ('rhubarb', 3),\n",
       " ('sardine', 3),\n",
       " ('scallop', 3),\n",
       " ('scorpion', 3),\n",
       " ('seagull', 3),\n",
       " ('seahorse', 3),\n",
       " ('seaweed', 3),\n",
       " ('snail', 3),\n",
       " ('squid', 3),\n",
       " ('stick', 3),\n",
       " ('thermometer', 3),\n",
       " ('tobacco', 3),\n",
       " ('tomato', 3),\n",
       " ('tulip', 3),\n",
       " ('watch', 3),\n",
       " ('wine', 3),\n",
       " ('monastery', 3),\n",
       " ('bike', 3),\n",
       " ('sherry', 3),\n",
       " ('vicar', 3),\n",
       " ('rum', 3),\n",
       " ('terror', 3),\n",
       " ('skin', 3),\n",
       " ('psychoanalysis', 3),\n",
       " ('terminal', 3),\n",
       " ('waitress', 3),\n",
       " ('song', 3),\n",
       " ('rain', 3),\n",
       " ('liquor', 3),\n",
       " ('liqueur', 3),\n",
       " ('lingerie', 3),\n",
       " ('relief', 3),\n",
       " ('church', 3),\n",
       " ('puppy', 3),\n",
       " ('ball', 3),\n",
       " ('bat', 3),\n",
       " ('boy', 3),\n",
       " ('cabinet', 3),\n",
       " ('case', 3),\n",
       " ('change', 3),\n",
       " ('kitten', 3),\n",
       " ('letter', 3),\n",
       " ('male', 3),\n",
       " ('music', 3),\n",
       " ('object', 3),\n",
       " ('party', 3),\n",
       " ('pitcher', 3),\n",
       " ('ram', 3),\n",
       " ('residence', 3),\n",
       " ('room', 3),\n",
       " ('school', 3),\n",
       " ('score', 3),\n",
       " ('trade', 3),\n",
       " ('university', 3),\n",
       " ('world', 3),\n",
       " ('motorcycle', 2),\n",
       " ('wasp', 2),\n",
       " ('van', 2),\n",
       " ('pineapple', 2),\n",
       " ('pear', 2),\n",
       " ('swan', 2),\n",
       " ('alligator', 2),\n",
       " ('peach', 2),\n",
       " ('apricot', 2),\n",
       " ('restaurant', 2),\n",
       " ('poplar', 2),\n",
       " ('pigeon', 2),\n",
       " ('snake', 2),\n",
       " ('cherry', 2),\n",
       " ('beaver', 2),\n",
       " ('carp', 2),\n",
       " ('trout', 2),\n",
       " ('knife', 2),\n",
       " ('canoe', 2),\n",
       " ('spacecraft', 2),\n",
       " ('asparagus', 2),\n",
       " ('aubergine', 2),\n",
       " ('bacon', 2),\n",
       " ('bell', 2),\n",
       " ('biscuit', 2),\n",
       " ('blender', 2),\n",
       " ('blueberry', 2),\n",
       " ('bouquet', 2),\n",
       " ('bracelet', 2),\n",
       " ('brick', 2),\n",
       " ('buttercup', 2),\n",
       " ('camel', 2),\n",
       " ('camera', 2),\n",
       " ('cap', 2),\n",
       " ('caterpillar', 2),\n",
       " ('champagne', 2),\n",
       " ('clam', 2),\n",
       " ('jellyfish', 2),\n",
       " ('jug', 2),\n",
       " ('kayak', 2),\n",
       " ('ketchup', 2),\n",
       " ('leek', 2),\n",
       " ('lemonade', 2),\n",
       " ('lily', 2),\n",
       " ('llama', 2),\n",
       " ('lobster', 2),\n",
       " ('marble', 2),\n",
       " ('menu', 2),\n",
       " ('monkey', 2),\n",
       " ('moss', 2),\n",
       " ('mushroom', 2),\n",
       " ('mussel', 2),\n",
       " ('necklace', 2),\n",
       " ('nectarine', 2),\n",
       " ('nut', 2),\n",
       " ('octopus', 2),\n",
       " ('olive', 2),\n",
       " ('ostrich', 2),\n",
       " ('otter', 2),\n",
       " ('ox', 2),\n",
       " ('parka', 2),\n",
       " ('partridge', 2),\n",
       " ('peacock', 2),\n",
       " ('peas', 2),\n",
       " ('pen', 2),\n",
       " ('pie', 2),\n",
       " ('platypus', 2),\n",
       " ('pliers', 2),\n",
       " ('porcupine', 2),\n",
       " ('prawn', 2),\n",
       " ('raft', 2),\n",
       " ('raspberry', 2),\n",
       " ('rhino', 2),\n",
       " ('rice', 2),\n",
       " ('rock', 2),\n",
       " ('sandwich', 2),\n",
       " ('shark', 2),\n",
       " ('shotgun', 2),\n",
       " ('shrimp', 2),\n",
       " ('skunk', 2),\n",
       " ('soup', 2),\n",
       " ('spanner', 2),\n",
       " ('spider', 2),\n",
       " ('stool', 2),\n",
       " ('sugar', 2),\n",
       " ('sunflower', 2),\n",
       " ('syringe', 2),\n",
       " ('tangerine', 2),\n",
       " ('taxi', 2),\n",
       " ('termite', 2),\n",
       " ('textbook', 2),\n",
       " ('tricycle', 2),\n",
       " ('typewriter', 2),\n",
       " ('walrus', 2),\n",
       " ('wand', 2),\n",
       " ('wheelbarrow', 2),\n",
       " ('whip', 2),\n",
       " ('whistle', 2),\n",
       " ('wolf', 2),\n",
       " ('jigsaw', 2),\n",
       " ('pc', 2),\n",
       " ('petroleum', 2),\n",
       " ('kindergarten', 2),\n",
       " ('pearl', 2),\n",
       " ('cardinal', 2),\n",
       " ('joker', 2),\n",
       " ('mother', 2),\n",
       " ('typhoon', 2),\n",
       " ('volleyball', 2),\n",
       " ('ink', 2),\n",
       " ('kilt', 2),\n",
       " ('chick', 2),\n",
       " ('ambassador', 2),\n",
       " ('arithmetic', 2),\n",
       " ('walnut', 2),\n",
       " ('panda', 2),\n",
       " ('lactose', 2),\n",
       " ('medicine', 2),\n",
       " ('ale', 2),\n",
       " ('rage', 2),\n",
       " ('anger', 2),\n",
       " ('memo', 2),\n",
       " ('orange', 2),\n",
       " ('logo', 2),\n",
       " ('booze', 2),\n",
       " ('vintage', 2),\n",
       " ('stallion', 2),\n",
       " ('stag', 2),\n",
       " ('physician', 2),\n",
       " ('surprise', 2),\n",
       " ('mule', 2),\n",
       " ('lady', 2),\n",
       " ('math', 2),\n",
       " ('symphony', 2),\n",
       " ('range', 2),\n",
       " ('race', 2),\n",
       " ('title', 2),\n",
       " ('rodent', 2),\n",
       " ('weapon', 2),\n",
       " ('salesman', 2),\n",
       " ('magazine', 2),\n",
       " ('manual', 2),\n",
       " ('baritone', 2),\n",
       " ('algebra', 2),\n",
       " ('bonnet', 2),\n",
       " ('alcohol', 2),\n",
       " ('beverage', 2),\n",
       " ('tongue', 2),\n",
       " ('motorway', 2),\n",
       " ('sadness', 2),\n",
       " ('physiology', 2),\n",
       " ('spaghetti', 2),\n",
       " ('shellfish', 2),\n",
       " ('ape', 2),\n",
       " ('mare', 2),\n",
       " ('size', 2),\n",
       " ('laptop', 2),\n",
       " ('birthday', 2),\n",
       " ('army', 2),\n",
       " ('accident', 2),\n",
       " ('action', 2),\n",
       " ('adult', 2),\n",
       " ('adventure', 2),\n",
       " ('animal', 2),\n",
       " ('apartment', 2),\n",
       " ('approach', 2),\n",
       " ('art', 2),\n",
       " ('balance', 2),\n",
       " ('bank', 2),\n",
       " ('bar', 2),\n",
       " ('beach', 2),\n",
       " ('beak', 2),\n",
       " ('bedroom', 2),\n",
       " ('bird', 2),\n",
       " ('board', 2),\n",
       " ('brain', 2),\n",
       " ('cancer', 2),\n",
       " ('capital', 2),\n",
       " ('center', 2),\n",
       " ('child', 2),\n",
       " ('china', 2),\n",
       " ('chip', 2),\n",
       " ('jack', 2),\n",
       " ('japan', 2),\n",
       " ('kid', 2),\n",
       " ('kingdom', 2),\n",
       " ('labor', 2),\n",
       " ('lace', 2),\n",
       " ('lease', 2),\n",
       " ('light', 2),\n",
       " ('line', 2),\n",
       " ('mammal', 2),\n",
       " ('marriage', 2),\n",
       " ('meat', 2),\n",
       " ('mercury', 2),\n",
       " ('minister', 2),\n",
       " ('movement', 2),\n",
       " ('nation', 2),\n",
       " ('ocean', 2),\n",
       " ('oxygen', 2),\n",
       " ('paper', 2),\n",
       " ('plan', 2),\n",
       " ('plane', 2),\n",
       " ('plant', 2),\n",
       " ('pool', 2),\n",
       " ('pop', 2),\n",
       " ('priest', 2),\n",
       " ('river', 2),\n",
       " ('robot', 2),\n",
       " ('root', 2),\n",
       " ('seat', 2),\n",
       " ('separation', 2),\n",
       " ('shop', 2),\n",
       " ('silver', 2),\n",
       " ('spike', 2),\n",
       " ('statue', 2),\n",
       " ('steak', 2),\n",
       " ('steam', 2),\n",
       " ('storm', 2),\n",
       " ('sun', 2),\n",
       " ('triangle', 2),\n",
       " ('trunk', 2),\n",
       " ('turkey', 2),\n",
       " ('vacation', 2),\n",
       " ('volcano', 2),\n",
       " ('war', 2),\n",
       " ('wool', 2),\n",
       " ('word', 2),\n",
       " ('work', 2),\n",
       " ('sparrow', 1),\n",
       " ('moth', 1),\n",
       " ('woodpecker', 1),\n",
       " ('owl', 1),\n",
       " ('pine', 1),\n",
       " ('penguin', 1),\n",
       " ('robin', 1),\n",
       " ('butterfly', 1),\n",
       " ('potato', 1),\n",
       " ('limber', 1),\n",
       " ('cafeteria', 1),\n",
       " ('stingray', 1),\n",
       " ('sled', 1),\n",
       " ('stable', 1),\n",
       " ('steakhouse', 1),\n",
       " ('shed', 1),\n",
       " ('barracuda', 1),\n",
       " ('sickle', 1),\n",
       " ('chickadee', 1),\n",
       " ('ladybug', 1),\n",
       " ('bulldozer', 1),\n",
       " ('pitchfork', 1),\n",
       " ('toothpick', 1),\n",
       " ('synagogue', 1),\n",
       " ('scraper', 1),\n",
       " ('plow', 1),\n",
       " ('morgue', 1),\n",
       " ('skyscraper', 1),\n",
       " ('airship', 1),\n",
       " ('nunnery', 1),\n",
       " ('stickleback', 1),\n",
       " ('sailboat', 1),\n",
       " ('bumblebee', 1),\n",
       " ('toucan', 1),\n",
       " ('anchor', 1),\n",
       " ('arm', 1),\n",
       " ('armchair', 1),\n",
       " ('aspirin', 1),\n",
       " ('barrel', 1),\n",
       " ('bee', 1),\n",
       " ('belt', 1),\n",
       " ('boat', 1),\n",
       " ('bolts', 1),\n",
       " ('broom', 1),\n",
       " ('bucket', 1),\n",
       " ('buckle', 1),\n",
       " ('buffalo', 1),\n",
       " ('bullet', 1),\n",
       " ('candle', 1),\n",
       " ('cart', 1),\n",
       " ('clamp', 1),\n",
       " ('jeep', 1),\n",
       " ('jelly', 1),\n",
       " ('ladder', 1),\n",
       " ('ladle', 1),\n",
       " ('lantern', 1),\n",
       " ('limousine', 1),\n",
       " ('lipstick', 1),\n",
       " ('lorry', 1),\n",
       " ('mask', 1),\n",
       " ('microscope', 1),\n",
       " ('microwave', 1),\n",
       " ('mittens', 1),\n",
       " ('mop', 1),\n",
       " ('needle', 1),\n",
       " ('nose', 1),\n",
       " ('oyster', 1),\n",
       " ('pamphlet', 1),\n",
       " ('peeler', 1),\n",
       " ('pelican', 1),\n",
       " ('pencil', 1),\n",
       " ('pony', 1),\n",
       " ('rattle', 1),\n",
       " ('raven', 1),\n",
       " ('ruler', 1),\n",
       " ('sandpaper', 1),\n",
       " ('satchel', 1),\n",
       " ('scythe', 1),\n",
       " ('shawl', 1),\n",
       " ('shield', 1),\n",
       " ('sink', 1),\n",
       " ('sledge', 1),\n",
       " ('spatula', 1),\n",
       " ('strainer', 1),\n",
       " ('surfboard', 1),\n",
       " ('swing', 1),\n",
       " ('tambourine', 1),\n",
       " ('telephone', 1),\n",
       " ('tent', 1),\n",
       " ('thumb', 1),\n",
       " ('toe', 1),\n",
       " ('tortoise', 1),\n",
       " ('tractor', 1),\n",
       " ('tweezers', 1),\n",
       " ('unicycle', 1),\n",
       " ('watermelon', 1),\n",
       " ('wheelchair', 1),\n",
       " ('whisk', 1),\n",
       " ('worm', 1),\n",
       " ('zebra', 1),\n",
       " ('tie', 1),\n",
       " ('lecturer', 1),\n",
       " ('secret', 1),\n",
       " ('questionnaire', 1),\n",
       " ('pope', 1),\n",
       " ('chant', 1),\n",
       " ('telegraph', 1),\n",
       " ('binder', 1),\n",
       " ('leak', 1),\n",
       " ('pocket', 1),\n",
       " ('snooker', 1),\n",
       " ('soccer', 1),\n",
       " ('wheat', 1),\n",
       " ('tummy', 1),\n",
       " ('sweetness', 1),\n",
       " ('mailbox', 1),\n",
       " ('pair', 1),\n",
       " ('attraction', 1),\n",
       " ('uprising', 1),\n",
       " ('refreshment', 1),\n",
       " ('chef', 1),\n",
       " ('traitor', 1),\n",
       " ('ten', 1),\n",
       " ('theater', 1),\n",
       " ('mortar', 1),\n",
       " ('red', 1),\n",
       " ('therapy', 1),\n",
       " ('monarch', 1),\n",
       " ('anorexia', 1),\n",
       " ('tumor', 1),\n",
       " ('tyrant', 1),\n",
       " ('swimming', 1),\n",
       " ('association', 1),\n",
       " ('thesaurus', 1),\n",
       " ('vial', 1),\n",
       " ('border', 1),\n",
       " ('alpha', 1),\n",
       " ('thrill', 1),\n",
       " ('intestine', 1),\n",
       " ('python', 1),\n",
       " ('velocity', 1),\n",
       " ('malaria', 1),\n",
       " ('primate', 1),\n",
       " ('assortment', 1),\n",
       " ('breaker', 1),\n",
       " ('bronze', 1),\n",
       " ('suit', 1),\n",
       " ('tip', 1),\n",
       " ('ipod', 1),\n",
       " ('baggage', 1),\n",
       " ('shaving', 1),\n",
       " ('pronoun', 1),\n",
       " ('nanny', 1),\n",
       " ('principle', 1),\n",
       " ('sauna', 1),\n",
       " ('investment', 1),\n",
       " ('pram', 1),\n",
       " ('carnage', 1),\n",
       " ('pudding', 1),\n",
       " ('massage', 1),\n",
       " ('bounty', 1),\n",
       " ('inn', 1),\n",
       " ('apprehension', 1),\n",
       " ('toddler', 1),\n",
       " ('bingo', 1),\n",
       " ('thief', 1),\n",
       " ('migrant', 1),\n",
       " ('suburb', 1),\n",
       " ('studio', 1),\n",
       " ('antibiotic', 1),\n",
       " ('charity', 1),\n",
       " ('veil', 1),\n",
       " ('twenty', 1),\n",
       " ('teacher', 1),\n",
       " ('technician', 1),\n",
       " ('tar', 1),\n",
       " ('melon', 1),\n",
       " ('kidnapping', 1),\n",
       " ('radar', 1),\n",
       " ('telescope', 1),\n",
       " ('chamber', 1),\n",
       " ('surgeon', 1),\n",
       " ('laborer', 1),\n",
       " ('apathy', 1),\n",
       " ('overhead', 1),\n",
       " ('poet', 1),\n",
       " ('tomorrow', 1),\n",
       " ('pirate', 1),\n",
       " ('pilot', 1),\n",
       " ('bowling', 1),\n",
       " ('retina', 1),\n",
       " ('apostle', 1),\n",
       " ('yearning', 1),\n",
       " ('manor', 1),\n",
       " ('nipple', 1),\n",
       " ('bead', 1),\n",
       " ('vicinity', 1),\n",
       " ('louse', 1),\n",
       " ('cataract', 1),\n",
       " ('mime', 1),\n",
       " ('bureau', 1),\n",
       " ('nerve', 1),\n",
       " ('ticket', 1),\n",
       " ('perseverance', 1),\n",
       " ('mob', 1),\n",
       " ('psychiatry', 1),\n",
       " ('stocking', 1),\n",
       " ('piracy', 1),\n",
       " ('maple', 1),\n",
       " ('physiotherapist', 1),\n",
       " ('navy', 1),\n",
       " ('cassette', 1),\n",
       " ('cemetery', 1),\n",
       " ('passion', 1),\n",
       " ('badminton', 1),\n",
       " ('vegan', 1),\n",
       " ('supper', 1),\n",
       " ('maggot', 1),\n",
       " ('wage', 1),\n",
       " ('rue', 1),\n",
       " ('brook', 1),\n",
       " ('ointment', 1),\n",
       " ('calculation', 1),\n",
       " ('pew', 1),\n",
       " ('mistress', 1),\n",
       " ('logic', 1),\n",
       " ('ache', 1),\n",
       " ('throne', 1),\n",
       " ('rainforest', 1),\n",
       " ('monsoon', 1),\n",
       " ('turquoise', 1),\n",
       " ('auto', 1),\n",
       " ('mummy', 1),\n",
       " ('blaze', 1),\n",
       " ('value', 1),\n",
       " ('roadway', 1),\n",
       " ('barrier', 1),\n",
       " ('racing', 1),\n",
       " ('adrenaline', 1),\n",
       " ('spouse', 1),\n",
       " ('casket', 1),\n",
       " ('sir', 1),\n",
       " ('berry', 1),\n",
       " ('quarterback', 1),\n",
       " ('knuckle', 1),\n",
       " ('acid', 1),\n",
       " ('artery', 1),\n",
       " ('accusation', 1),\n",
       " ('catcher', 1),\n",
       " ('scapegoat', 1),\n",
       " ('wrath', 1),\n",
       " ('pilgrimage', 1),\n",
       " ('pouch', 1),\n",
       " ('velvet', 1),\n",
       " ('swimmer', 1),\n",
       " ('license', 1),\n",
       " ('mankind', 1),\n",
       " ('platter', 1),\n",
       " ('muse', 1),\n",
       " ('tuberculosis', 1),\n",
       " ('boar', 1),\n",
       " ('metro', 1),\n",
       " ('beard', 1),\n",
       " ('agony', 1),\n",
       " ('panic', 1),\n",
       " ('artillery', 1),\n",
       " ('military', 1),\n",
       " ('seaman', 1),\n",
       " ('mom', 1),\n",
       " ('bulldog', 1),\n",
       " ('underwear', 1),\n",
       " ('butcher', 1),\n",
       " ('chimpanzee', 1),\n",
       " ('reel', 1),\n",
       " ('robbery', 1),\n",
       " ('karaoke', 1),\n",
       " ('maid', 1),\n",
       " ('chemistry', 1),\n",
       " ('president', 1),\n",
       " ('chapel', 1),\n",
       " ('breeze', 1),\n",
       " ('safari', 1),\n",
       " ('pizza', 1),\n",
       " ('optimism', 1),\n",
       " ('trolley', 1),\n",
       " ('medication', 1),\n",
       " ('motorbike', 1),\n",
       " ('penis', 1),\n",
       " ('pickup', 1),\n",
       " ('resignation', 1),\n",
       " ('reindeer', 1),\n",
       " ('oat', 1),\n",
       " ('teaching', 1),\n",
       " ('vodka', 1),\n",
       " ('bamboo', 1),\n",
       " ('maize', 1),\n",
       " ('rucksack', 1),\n",
       " ('recovery', 1),\n",
       " ('taste', 1),\n",
       " ('spaceship', 1),\n",
       " ('negation', 1),\n",
       " ('parameter', 1),\n",
       " ('adjective', 1),\n",
       " ('wife', 1),\n",
       " ('spiral', 1),\n",
       " ('violinist', 1),\n",
       " ('nickname', 1),\n",
       " ('astronomy', 1),\n",
       " ('publisher', 1),\n",
       " ('carbohydrate', 1),\n",
       " ('infant', 1),\n",
       " ('longing', 1),\n",
       " ('asthma', 1),\n",
       " ('ban', 1),\n",
       " ('jean', 1),\n",
       " ('nostalgia', 1),\n",
       " ('motto', 1),\n",
       " ('murderer', 1),\n",
       " ('linguistics', 1),\n",
       " ('pharmacy', 1),\n",
       " ('carpenter', 1),\n",
       " ('staple', 1),\n",
       " ('margarine', 1),\n",
       " ('sausage', 1),\n",
       " ('cipher', 1),\n",
       " ('serpent', 1),\n",
       " ('mail', 1),\n",
       " ('propaganda', 1),\n",
       " ('anatomy', 1),\n",
       " ('term', 1),\n",
       " ('skull', 1),\n",
       " ('caring', 1),\n",
       " ('cereal', 1),\n",
       " ('attorney', 1),\n",
       " ('nurse', 1),\n",
       " ('brethren', 1),\n",
       " ('warrant', 1),\n",
       " ('radius', 1),\n",
       " ('bend', 1),\n",
       " ('postman', 1),\n",
       " ('preposition', 1),\n",
       " ('bargain', 1),\n",
       " ('rugby', 1),\n",
       " ('brigade', 1),\n",
       " ('automobile', 1),\n",
       " ('theft', 1),\n",
       " ('parachute', 1),\n",
       " ('mango', 1),\n",
       " ('toast', 1),\n",
       " ('protein', 1),\n",
       " ('affection', 1),\n",
       " ('uterus', 1),\n",
       " ('lipid', 1),\n",
       " ('psychology', 1),\n",
       " ('leukemia', 1),\n",
       " ('pathology', 1),\n",
       " ('librarian', 1),\n",
       " ('resentment', 1),\n",
       " ('tsunami', 1),\n",
       " ('almond', 1),\n",
       " ('waiter', 1),\n",
       " ('migraine', 1),\n",
       " ('receiver', 1),\n",
       " ('buggy', 1),\n",
       " ('sack', 1),\n",
       " ('radiation', 1),\n",
       " ('nursing', 1),\n",
       " ('biologist', 1),\n",
       " ('rider', 1),\n",
       " ('thirty', 1),\n",
       " ('ultimatum', 1),\n",
       " ('skating', 1),\n",
       " ('analogy', 1),\n",
       " ('asylum', 1),\n",
       " ('zeal', 1),\n",
       " ('stepmother', 1),\n",
       " ('knee', 1),\n",
       " ('linguist', 1),\n",
       " ('noun', 1),\n",
       " ('roast', 1),\n",
       " ('swap', 1),\n",
       " ('black', 1),\n",
       " ('palace', 1),\n",
       " ('bra', 1),\n",
       " ('winner', 1),\n",
       " ('yesterday', 1),\n",
       " ('postcard', 1),\n",
       " ('influenza', 1),\n",
       " ('slogan', 1),\n",
       " ('neurology', 1),\n",
       " ('ore', 1),\n",
       " ('invitation', 1),\n",
       " ('loo', 1),\n",
       " ('silo', 1),\n",
       " ('paddle', 1),\n",
       " ('subtraction', 1),\n",
       " ('sunshine', 1),\n",
       " ('bookshop', 1),\n",
       " ('amphibian', 1),\n",
       " ('playing', 1),\n",
       " ('aquarium', 1),\n",
       " ('twelve', 1),\n",
       " ('pianist', 1),\n",
       " ('reptile', 1),\n",
       " ('package', 1),\n",
       " ('sociology', 1),\n",
       " ('charcoal', 1),\n",
       " ('seminar', 1),\n",
       " ('tour', 1),\n",
       " ('remorse', 1),\n",
       " ('theology', 1),\n",
       " ('jealousy', 1),\n",
       " ('patience', 1),\n",
       " ('tutor', 1),\n",
       " ('measles', 1),\n",
       " ('laboratory', 1),\n",
       " ('suitcase', 1),\n",
       " ('insomnia', 1),\n",
       " ('receptionist', 1),\n",
       " ('jewelry', 1),\n",
       " ('stipend', 1),\n",
       " ('yellow', 1),\n",
       " ('royalty', 1),\n",
       " ('platform', 1),\n",
       " ('shower', 1),\n",
       " ('petal', 1),\n",
       " ('actor', 1),\n",
       " ('age', 1),\n",
       " ('agreement', 1),\n",
       " ('air', 1),\n",
       " ('aisle', 1),\n",
       " ('alley', 1),\n",
       " ('alto', 1),\n",
       " ('angel', 1),\n",
       " ('arch', 1),\n",
       " ('article', 1),\n",
       " ('artist', 1),\n",
       " ('athlete', 1),\n",
       " ('atmosphere', 1),\n",
       " ('author', 1),\n",
       " ('authority', 1),\n",
       " ('bark', 1),\n",
       " ('basement', 1),\n",
       " ('basketball', 1),\n",
       " ('bathroom', 1),\n",
       " ('bathtub', 1),\n",
       " ('beam', 1),\n",
       " ('beauty', 1),\n",
       " ('beef', 1),\n",
       " ('benefit', 1),\n",
       " ('bias', 1),\n",
       " ('bicycle', 1),\n",
       " ('bill', 1),\n",
       " ('birth', 1),\n",
       " ('boot', 1),\n",
       " ('boss', 1),\n",
       " ('branch', 1),\n",
       " ('bread', 1),\n",
       " ('camp', 1),\n",
       " ('cannabis', 1),\n",
       " ('captain', 1),\n",
       " ('card', 1),\n",
       " ('care', 1),\n",
       " ('cell', 1),\n",
       " ('cellar', 1),\n",
       " ('channel', 1),\n",
       " ('charm', 1),\n",
       " ('chest', 1),\n",
       " ('choice', 1),\n",
       " ('city', 1),\n",
       " ('civilization', 1),\n",
       " ('class', 1),\n",
       " ('independence', 1),\n",
       " ('index', 1),\n",
       " ('individual', 1),\n",
       " ('industry', 1),\n",
       " ('information', 1),\n",
       " ('insect', 1),\n",
       " ('instruction', 1),\n",
       " ('instrument', 1),\n",
       " ('integrity', 1),\n",
       " ('island', 1),\n",
       " ('jail', 1),\n",
       " ('job', 1),\n",
       " ('john', 1),\n",
       " ('joy', 1),\n",
       " ('judge', 1),\n",
       " ('juice', 1),\n",
       " ('kettle', 1),\n",
       " ('keyboard', 1),\n",
       " ('killer', 1),\n",
       " ('kindness', 1),\n",
       " ('kitchen', 1),\n",
       " ('knob', 1),\n",
       " ('knowledge', 1),\n",
       " ('lake', 1),\n",
       " ('land', 1),\n",
       " ('language', 1),\n",
       " ('law', 1),\n",
       " ('lawn', 1),\n",
       " ('leader', 1),\n",
       " ('leaf', 1),\n",
       " ('level', 1),\n",
       " ('liberty', 1),\n",
       " ('life', 1),\n",
       " ('link', 1),\n",
       " ('lobby', 1),\n",
       " ('loneliness', 1),\n",
       " ('lot', 1),\n",
       " ('lover', 1),\n",
       " ('lung', 1),\n",
       " ('machine', 1),\n",
       " ('mall', 1),\n",
       " ('map', 1),\n",
       " ('master', 1),\n",
       " ('match', 1),\n",
       " ('material', 1),\n",
       " ('metal', 1),\n",
       " ('middle', 1),\n",
       " ('mine', 1),\n",
       " ('misery', 1),\n",
       " ('monk', 1),\n",
       " ('moon', 1),\n",
       " ('mountain', 1),\n",
       " ('murder', 1),\n",
       " ('muscle', 1),\n",
       " ('nature', 1),\n",
       " ('network', 1),\n",
       " ('news', 1),\n",
       " ('nick', 1),\n",
       " ('night', 1),\n",
       " ('noise', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # df[['sub_label', 'subj_anchors_wordnet']]\n",
    "# # df.columns\n",
    "\n",
    "Counter(df['sub_label_sg'].to_list()).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4f3569f-6fe5-4632-acb6-7bd79bf266f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>subj_anchors_wordnet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>tigers</td>\n",
       "      <td>['MISSING']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>whales</td>\n",
       "      <td>['MISSING']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>swan</td>\n",
       "      <td>['coscoroba', 'cygnets', 'waterfowl', 'waterbi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>beetle</td>\n",
       "      <td>['ladybeetles', 'ladybug', 'ladybird', 'longic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>rats</td>\n",
       "      <td>['MISSING']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>voices</td>\n",
       "      <td>['MISSING']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>wars</td>\n",
       "      <td>['MISSING']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>wheels</td>\n",
       "      <td>['MISSING']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>windows</td>\n",
       "      <td>['MISSING']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>work</td>\n",
       "      <td>['jobs', 'writing', 'films', 'pic', 'flicks', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub_label                               subj_anchors_wordnet\n",
       "47      tigers                                        ['MISSING']\n",
       "59      whales                                        ['MISSING']\n",
       "66        swan  ['coscoroba', 'cygnets', 'waterfowl', 'waterbi...\n",
       "143     beetle  ['ladybeetles', 'ladybug', 'ladybird', 'longic...\n",
       "165       rats                                        ['MISSING']\n",
       "...        ...                                                ...\n",
       "1984    voices                                        ['MISSING']\n",
       "1989      wars                                        ['MISSING']\n",
       "2000    wheels                                        ['MISSING']\n",
       "2004   windows                                        ['MISSING']\n",
       "2012      work  ['jobs', 'writing', 'films', 'pic', 'flicks', ...\n",
       "\n",
       "[148 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"p10_def_sap == 1 and p10_def_dap== 0\")[['sub_label', 'subj_anchors_wordnet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8945c021-fe30-497f-b9cf-7bb803431f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>relation</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "      <th>sub_position</th>\n",
       "      <th>sub_label_sg</th>\n",
       "      <th>sub_label_pl</th>\n",
       "      <th>...</th>\n",
       "      <th>p5_def_dap</th>\n",
       "      <th>p10_def_dap</th>\n",
       "      <th>p1_lsp_dap</th>\n",
       "      <th>p5_lsp_dap</th>\n",
       "      <th>p10_lsp_dap</th>\n",
       "      <th>mrr_sentence</th>\n",
       "      <th>mrr_def_sap</th>\n",
       "      <th>mrr_lsp_sap</th>\n",
       "      <th>mrr_def_dap</th>\n",
       "      <th>mrr_lsp_dap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, sub_label, obj_label, relation, masked_sentences, sub_sister, uuid, sub_position, sub_label_sg, sub_label_pl, def_sap, def_dap, lsp_sap, lsp_dap, anchor_lsp_sap, sub_label_sgpl, subj_anchors_swow, subj_anchors, obj_in_BERT, obj_mask_sentence, obj_mask_sentence_score, obj_mask_def_sap, obj_mask_def_sap_score, obj_mask_lsp_sap, obj_mask_lsp_sap_score, subj_anchors_wordnet, subj_anchors_wordnet_sg, subj_anchors_wordnet_pl, subj_anchors_wordnet_all, subj_anchors_combined, anchor_num, def_dap_with_subj_anchor, lsp_dap_with_subj_anchor, obj_mask_def_dap, obj_mask_def_dap_score, obj_mask_lsp_dap, obj_mask_lsp_dap_score, obj_label_sg, p1_sentence, p5_sentence, p10_sentence, p1_def_sap, p5_def_sap, p10_def_sap, p1_lsp_sap, p5_lsp_sap, p10_lsp_sap, p1_def_dap, p5_def_dap, p10_def_dap, p1_lsp_dap, p5_lsp_dap, p10_lsp_dap, mrr_sentence, mrr_def_sap, mrr_lsp_sap, mrr_def_dap, mrr_lsp_dap]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 58 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.query(\"subj_anchors_wordnet == ['MISSING']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140d9425-d7d5-47c1-81ae-3d9c9d069d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../../data/hypernymsuite/ALL/SWOWStrength/IsA.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "317e019d-6a27-4577-8878-0fde77794037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "with open(filepath, 'r', encoding='utf-8') as fin:\n",
    "    data = fin.readlines()\n",
    "    data = [eval(x) for x in data]\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df['obj_label'] = df['obj_label'].apply(lambda x: [x] if isinstance(x, str) else x)\n",
    "    df['masked_sentences'] = df['masked_sentences'].apply(lambda x: eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6719afa-e4e2-411f-a41f-6be921153d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>subj_anchors_sg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catfish</td>\n",
       "      <td>['bass', 'carp', 'fish', 'trout', 'shrimp']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lemon</td>\n",
       "      <td>['lime', 'citrus', 'orange', 'grape', 'strawbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turtles</td>\n",
       "      <td>['snake', 'bird', 'fish', 'lizard', 'frog']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bags</td>\n",
       "      <td>['luggage', 'box', 'suitcase', 'backpack', 'tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rabbits</td>\n",
       "      <td>['hare', 'rodent', 'mouse', 'mammal', 'dog']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label                                    subj_anchors_sg\n",
       "0   catfish        ['bass', 'carp', 'fish', 'trout', 'shrimp']\n",
       "1     lemon  ['lime', 'citrus', 'orange', 'grape', 'strawbe...\n",
       "2   turtles        ['snake', 'bird', 'fish', 'lizard', 'frog']\n",
       "3      bags  ['luggage', 'box', 'suitcase', 'backpack', 'tr...\n",
       "4   rabbits       ['hare', 'rodent', 'mouse', 'mammal', 'dog']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>subj_anchors_wordnet_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catfish</td>\n",
       "      <td>['carp', 'basses', 'cisco', 'roe', 'herring']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lemon</td>\n",
       "      <td>['limes', 'citrus', 'orange', 'apples', 'grapes']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turtles</td>\n",
       "      <td>['snakes', 'birds', 'fishes', 'lizards', 'frogs']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bags</td>\n",
       "      <td>['boxes', 'yes', 'shoes', 'cases', 'obviously']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rabbits</td>\n",
       "      <td>['foxes', 'deer', 'squirrels', 'mice', 'rodents']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label                            subj_anchors_wordnet_pl\n",
       "0   catfish      ['carp', 'basses', 'cisco', 'roe', 'herring']\n",
       "1     lemon  ['limes', 'citrus', 'orange', 'apples', 'grapes']\n",
       "2   turtles  ['snakes', 'birds', 'fishes', 'lizards', 'frogs']\n",
       "3      bags    ['boxes', 'yes', 'shoes', 'cases', 'obviously']\n",
       "4   rabbits  ['foxes', 'deer', 'squirrels', 'mice', 'rodents']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>subj_anchors_wordnet_pl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>catfish</td>\n",
       "      <td>['basses', 'carp', 'perches']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lemon</td>\n",
       "      <td>['chocolates', 'orange', 'limes', 'cherries', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>turtles</td>\n",
       "      <td>['snakes', 'birds', 'fishes', 'lizards', 'frogs']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bags</td>\n",
       "      <td>['boxes', 'yes', 'shoes', 'cases', 'obviously']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rabbits</td>\n",
       "      <td>['foxes', 'deer', 'squirrels', 'mice', 'rodents']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label                            subj_anchors_wordnet_pl\n",
       "0   catfish                      ['basses', 'carp', 'perches']\n",
       "1     lemon  ['chocolates', 'orange', 'limes', 'cherries', ...\n",
       "2   turtles  ['snakes', 'birds', 'fishes', 'lizards', 'frogs']\n",
       "3      bags    ['boxes', 'yes', 'shoes', 'cases', 'obviously']\n",
       "4   rabbits  ['foxes', 'deer', 'squirrels', 'mice', 'rodents']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path1 = \"../../log/bert-large-uncased/ALL/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_AddSWOWSimilar.HYPERNYMSUITE.csv\"\n",
    "path2 = \"../../log/bert-large-uncased/ALL/SWOWStrength/df_all_use_global_dap_True_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_anchor_source_WordNet_wns_True_wnf_False_swow_score_source_None.HYPERNYMSUITE.csv\"\n",
    "path3 = \"../../log/bert-large-uncased/ALL/SWOWStrength/df_all_use_global_dap_True_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_anchor_source_WordNet_wns_False_wnf_True_swow_score_source_None.HYPERNYMSUITE.csv\"\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)\n",
    "df3 = pd.read_csv(path3)\n",
    "\n",
    "display(df1[['sub_label', 'subj_anchors_sg']].head())\n",
    "\n",
    "display(df2[['sub_label', 'subj_anchors_wordnet_pl']].head())\n",
    "\n",
    "display(df3[['sub_label', 'subj_anchors_wordnet_pl']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0608d25c-78c3-4ce6-bffc-b47cafce9636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'fp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d93bbdd2e84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mout_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../log/word_to_cohyponyms_score_pl.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"save {out_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: dump() missing 1 required positional argument: 'fp'"
     ]
    }
   ],
   "source": [
    "import json \n",
    "import pandas as pd \n",
    "from collections import defaultdict, Counter \n",
    "\n",
    "path = '../log/word_to_cohyponyms_score.json'\n",
    "data = json.load(open(path, 'r'))\n",
    "\n",
    "from inflection import singularize, pluralize \n",
    "\n",
    "data_new = defaultdict(dict)\n",
    "for i, (k,v) in enumerate(data.items()):\n",
    "    cur_dic = {}\n",
    "    k = pluralize(k)\n",
    "    for k1, v1 in v.items():\n",
    "        k1 = pluralize(k1)\n",
    "        cur_dic[k1] = v1 \n",
    "    data_new[k] = cur_dic\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "        \n",
    "out_path = '../log/word_to_cohyponyms_score_pl.json'\n",
    "json.dump(open(path, 'w'))\n",
    "\n",
    "print(f\"save {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e0ef160-7787-46ce-b201-5a400a0605ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name dataclass_transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-aeb641bfb491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minflection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msingularize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpluralize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gpfs/projects/punim0478/chunhua/cogsci/DAP/pre_post_process/script/inflection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyinflect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# set library-specific custom warning handling before doing anything else\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/spacy/errors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mErrorsWithCodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/spacy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/thinc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcatalogue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfigValidationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVARIABLE_RE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/confection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfigparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParsingError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelMetaclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pydantic/__init__.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36minit pydantic.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pydantic/dataclasses.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36minit pydantic.dataclasses\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name dataclass_transform"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24b3b515-26d1-460b-82dc-548482da234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import os, sys \n",
    "\n",
    "\n",
    "def read_cohyponyms(path = '../log/word_to_cohyponyms.txt'):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"reading cohyponyms: {path}\")\n",
    "        df = pd.read_csv(path)\n",
    "        word_to_cohyponym = dict(zip(df['word'], df['cohyponyms']))\n",
    "        return word_to_cohyponym\n",
    "    print(f\"{path} not found\")\n",
    "\n",
    "\n",
    "\n",
    "def get_path_using_hypernym_dict(hypernym,hypernym_dict,synsets):\n",
    "    '''\n",
    "    Return the path between a sense and a specified hypernym \n",
    "    Core idea: starting from the hypernym, find its child sense (iterate this process, DFS)\n",
    "    \n",
    "    hypernym: a synset, which is a hypernym   \n",
    "    hypernym_dict: a {hypernym: sense} dict \n",
    "    sensets: a synsets \n",
    "    '''\n",
    "    \n",
    "    path = [hypernym]\n",
    "    current_synset = hypernym_dict[hypernym]\n",
    "    #     print(hypernym, current_synset)\n",
    "    \n",
    "    while current_synset not in synsets: #stop criteria: when find a sense belonging to the synsets\n",
    "    #         print(current_synset)\n",
    "        path.append(current_synset)\n",
    "        current_synset =  hypernym_dict[current_synset]\n",
    "    path.append(current_synset)\n",
    "    return path\n",
    "    \n",
    "# hypernym_dict = get_hypernym_path_dict(wn.synsets(\"book\",\"n\"))\n",
    "# print(get_path_using_hypernym_dict(wn.synset('physical_entity.n.01'),hypernym_dict,wn.synsets(\"book\",\"n\")))\n",
    "        \n",
    "\n",
    "def get_hypernym_path_dict(synsets):\n",
    "    '''\n",
    "    get the hypernyms for all synsets of a given word \n",
    "    return hypernym_dict: key is the hypernym and value is the synset\n",
    "    '''\n",
    "    hypernym_dict = {}\n",
    "    synsets_to_expand = synsets\n",
    "    while synsets_to_expand:\n",
    "        new_synsets_to_expand = set()\n",
    "        for synset in synsets_to_expand:\n",
    "            for hypernym in synset.hypernyms():\n",
    "                if hypernym not in hypernym_dict:  # this ensures we get the shortest path\n",
    "                    hypernym_dict[hypernym] = synset\n",
    "                    new_synsets_to_expand.add(hypernym)\n",
    "        synsets_to_expand = new_synsets_to_expand\n",
    "    return hypernym_dict\n",
    "        \n",
    "def get_wordnet_shortest_path_between(word1,word2):\n",
    "    '''\n",
    "    get the shorttest path betwen two words\n",
    "    question: what to return if a word is not in the wordnet\n",
    "    '''\n",
    "\n",
    "    synsets1 = wn.synsets(word1, \"n\") #\"\"n\"\" is added in 230107\n",
    "    synsets2 = wn.synsets(word2, \"n\")\n",
    "    if len(synsets1)==0 or len(synsets2) ==0: return [] #retrun [] means no path exsit \n",
    "    # added these two lines to catch situation where word1 and word2 share a synset, the distance is 1, 1/path=1\n",
    "    match = set(synsets1).intersection(set(synsets2))\n",
    "    if match: return [list(match)[0]]\n",
    "\n",
    "    hypernym_dict1 = get_hypernym_path_dict(synsets1)\n",
    "    hypernym_dict2 = get_hypernym_path_dict(synsets2)\n",
    "    best_path = []\n",
    "    for hypernym in hypernym_dict1:\n",
    "        if hypernym in hypernym_dict2 and hypernym_dict1[hypernym] != hypernym_dict2[hypernym]: #find the LCS\n",
    "            path1 = get_path_using_hypernym_dict(hypernym,hypernym_dict1,synsets1)\n",
    "            path2 = get_path_using_hypernym_dict(hypernym,hypernym_dict2,synsets2)\n",
    "            \n",
    "            if not best_path or len(path1) + len(path2) - 1 < len(best_path):\n",
    "                path1.reverse()\n",
    "                best_path = path1 + path2[1:]\n",
    "    return best_path\n",
    "\n",
    "    \n",
    "def get_wordnet_shortest_path_length_between(word1,word2, oov_path_len=100):\n",
    "    '''\n",
    "    oov_path: the path for out-of-vocabulary words\n",
    "    '''\n",
    "    best_path = get_wordnet_shortest_path_between(word1, word2)    \n",
    "    return len(best_path) if len(best_path)>0 else oov_path_len \n",
    "\n",
    "def get_wordnet_shortest_path_score_between(word1,word2):\n",
    "    '''\n",
    "    path_score = 1/short_path_length(word2, word2)\n",
    "    path_score=0 if word1/word2 is not in wordnet \n",
    "    '''\n",
    "    best_path = get_wordnet_shortest_path_between(word1, word2)    \n",
    "    return 1/len(best_path) if len(best_path)>0 else 0\n",
    "\n",
    "\n",
    "\n",
    "def get_wordnet_avg_path_score_between_sub_and_anchors(sub_labels, subj_anchors):\n",
    "    '''\n",
    "    evalaute the quality of anchors by measuring their average shortest paths score in WordNet\n",
    "    path_score: [0, 1] ; 1 means those anchors are all very close to the sub_labels , 0 indicates that those anchors are far away or not exist in WordNet\n",
    "\n",
    "    args:\n",
    "        sub_labels: a list of sub_labels \n",
    "        subj_anchors: a list of dict (anchor: score), each sub_label have N anchors \n",
    "    '''\n",
    "    path_scores = []\n",
    "    for i, (sub_label, subj_anchors) in enumerate(zip(sub_labels, subj_anchors)): \n",
    "        path_score  = sum([get_wordnet_shortest_path_score_between(sub_label, subj_anchor) for subj_anchor in subj_anchors])/len(subj_anchors)\n",
    "        path_lens.append(path_score)\n",
    "    return path_scores \n",
    "\n",
    "\n",
    "def get_sister_terms(word, distance_to_hypernym=1):\n",
    "    '''\n",
    "    \"Coordinate (sister) terms: share the same hypernym\"\n",
    "    \"The sister relation is the usual one encountered when working with tree structures: sisters are word forms (either simple words or collocations) that are both immediate hyponyms of the same node\"\n",
    "    \n",
    "    Args:\n",
    "        word: the input word\n",
    "        hop: the hops to hypernyms, default is 1, which means take the top 1 hypernym of x\n",
    "    '''\n",
    "    sister_terms = set()\n",
    "    for synset in wn.synsets(word ,\"n\"):\n",
    "        for hypernym in synset.hypernyms()[:distance_to_hypernym]:\n",
    "#             print(hypernym)\n",
    "            sister_synsets = hypernym.hyponyms()\n",
    "            for sister_synset in sister_synsets:\n",
    "                sister_names = [x.name() for x in sister_synset.lemmas()]\n",
    "                sister_names_selected = [name.lower() for name in sister_names if len(name.split(\"_\"))==1 and  len(name.split(\"-\"))==1  and name!=word]\n",
    "                sister_terms = sister_terms.union(set(sister_names_selected))\n",
    "    return list(sister_terms)\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     path_score = get_wordnet_shortest_path_score_between(\"dog\", \"animal\")\n",
    "#     print(path_score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a8def1-1cbd-4093-a00d-970013648926",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_score = get_wordnet_shortest_path_score_between(\"dog\", \"animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e66ed72-cffd-4f40-9125-29f60d89d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wn\n",
      "  Using cached wn-0.9.3-py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/easybuild-2019/easybuild/software/mpi/gcc/8.3.0/openmpi/3.1.4/jupyter/1.0.0-python-3.7.4/lib/python3.7/site-packages (from wn) (3.10.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from wn) (2.22.0)\n",
      "Collecting tomli\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests->wn) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests->wn) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests->wn) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests->wn) (2.8)\n",
      "Installing collected packages: tomli, wn\n",
      "Successfully installed tomli-2.0.1 wn-0.9.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42bd0803-e2ba-4c6f-9e8d-5bd16f64974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import wn, wn.taxonomy\n",
    "ewn = wn.Wordnet('ewn:2020')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c5c008-c707-4583-8ce6-64a97616d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9285714285714286\n",
      "0.8571428571428571\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import wn\n",
    "from wn.similarity import wup\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "spatula = ewn.synsets('dog')[0]\n",
    "print(wup(spatula, ewn.synsets('wolf', pos='n')[0]))\n",
    "print(wup(spatula, ewn.synsets('cat', pos='n')[0]))\n",
    "print(wup(spatula, spatula))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "392301d2-a846-4b24-8959-787b901eb009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n",
      "0.2\n",
      "1.0\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# spatula = ewn.synsets('dog')[0]\n",
    "# print(path(spatula, ewn.synsets('wolf')[0]))\n",
    "# print(path(spatula, ewn.synsets('cat')[0]))\n",
    "# print(path(spatula, spatula))\n",
    "\n",
    "\n",
    "\n",
    "score = get_shortest_path_score('dog', 'wolf')\n",
    "print(score) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835d4e1-33ad-451f-8e45-4ac22047dcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading cohyponyms: ../log/word_to_cohyponyms.txt\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "import json \n",
    "import wn\n",
    "from wn.similarity import path\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "\n",
    "\n",
    "def read_cohyponyms(path = '../log/word_to_cohyponyms.txt'):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"reading cohyponyms: {path}\")\n",
    "        df = pd.read_csv(path)\n",
    "        word_to_cohyponym = dict(zip(df['word'], df['cohyponyms']))\n",
    "        return word_to_cohyponym\n",
    "    print(f\"{path} not found\")\n",
    "\n",
    "    \n",
    "def get_shortest_path_score(word1, word2):\n",
    "    synsets1 = ewn.synsets(word1, pos='n')    \n",
    "    synsets2 = ewn.synsets(word2, pos='n')\n",
    "    if len(synsets1)==0 or len(synsets2)==0: return 0 \n",
    "    score = path(synsets1[0] , synsets2[0]  )\n",
    "    return score \n",
    "\n",
    "def write_cohyponym_scores(word_to_cohyponyms_score, output_path):\n",
    "    with open(output_path, 'w') as fout:\n",
    "        json.dump(word_to_cohyponyms_score, fout, indent=4)\n",
    "    print(output_path)\n",
    "\n",
    "def get_path_score_for_cohyponyms(word_to_cohyponyms, debug=False):\n",
    "    word_to_cohyponyms_score = defaultdict()\n",
    "    if debug:    \n",
    "        query_words = ['dog', 'wolf', 'corn', 'car']\n",
    "    else: \n",
    "        query_words = word_to_cohyponyms.keys()\n",
    "        \n",
    "    for k in query_words: \n",
    "        cur_cohyponyms_to_score = defaultdict()\n",
    "        if len(word_to_cohyponyms[k])==0: continue \n",
    "        for v in eval(word_to_cohyponyms[k]):\n",
    "            score = get_shortest_path_score(k, v)\n",
    "            ## print(k, v, score) \n",
    "            cur_cohyponyms_to_score[v] = round(score, 4)\n",
    "        cur_cohyponyms_to_score = dict(sorted(cur_cohyponyms_to_score.items(), key=lambda x: x[1], reverse=True))\n",
    "        word_to_cohyponyms_score[k] = cur_cohyponyms_to_score\n",
    "    return word_to_cohyponyms_score\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    debug=False \n",
    "#     debug=True \n",
    "    word_to_cohyponyms = read_cohyponyms()\n",
    "    word_to_cohyponyms_score = get_path_score_for_cohyponyms(word_to_cohyponyms, debug=debug)\n",
    "    output_path = '../log/word_to_cohyponyms_score.json'\n",
    "    write_cohyponym_scores(word_to_cohyponyms_score, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5fee75b-8905-4ff7-af24-8e9018e778c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import os, sys \n",
    "import wn\n",
    "from wn.similarity import path\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "\n",
    "\n",
    "def read_cohyponyms(path = '../log/word_to_cohyponyms.txt'):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"reading cohyponyms: {path}\")\n",
    "        df = pd.read_csv(path)\n",
    "        df['cohyponyms'] = df['cohyponyms'].apply(lambda x: eval(x))\n",
    "        word_to_cohyponym = dict(zip(df['word'].to_list(), df['cohyponyms'].to_list()))\n",
    "        return word_to_cohyponym\n",
    "    print(f\"{path} not found\")\n",
    "\n",
    "def read_cohyponyms_with_score(path = '../log/word_to_cohyponyms_score.json'):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"reading cohyponyms: {path}\")\n",
    "        word_to_cohyponym_score = json.load(open(path, 'r'))\n",
    "        word_to_cohyponym = {k: list(v.keys()) for k,v in word_to_cohyponym_score.items()}\n",
    "        return word_to_cohyponym\n",
    "    print(f\"{path} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24ee8681-44c9-4def-bcec-3da42d118790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading cohyponyms: ../log/word_to_cohyponyms_score.json\n"
     ]
    }
   ],
   "source": [
    "word_to_wn_cohyponyms = read_cohyponyms_with_score(path = '../log/word_to_cohyponyms_score.json') #word is singular or plural? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47379e4-cf89-41c2-bfb1-9e6398c751e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(word_to_wn_cohyponyms.keys())) #[:3]\n",
    "word_to_wn_cohyponyms['bag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ae2930b-cb1f-47bf-8e30-01e5dd5d9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1babb00d-655a-42bc-8ffb-126692b2491f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sub_label', 'obj_label', 'relation', 'obj_in_BERT',\n",
       "       'sub_label_pl', 'subj_anchors_label', 'subj_anchors_pred',\n",
       "       'p1_subj_anchors_pred', 'p5_subj_anchors_pred', 'p10_subj_anchors_pred',\n",
       "       'mrr_subj_anchors_pred', 'masked_sentences', 'uuid', 'sub_position',\n",
       "       'sub_label_sg', 'def_sap', 'def_dap', 'lsp_sap', 'lsp_dap',\n",
       "       'anchor_lsp_sap', 'sub_label_sgpl', 'obj_mask_sentence',\n",
       "       'obj_mask_sentence_score', 'obj_mask_def_sap', 'obj_mask_def_sap_score',\n",
       "       'obj_mask_lsp_sap', 'obj_mask_lsp_sap_score', 'subj_anchors',\n",
       "       'subj_anchors_score', 'subj_anchors_sg', 'subj_anchors_pl',\n",
       "       'subj_anchors_all', 'subj_anchors_combined', 'def_dap_with_subj_anchor',\n",
       "       'lsp_dap_with_subj_anchor', 'obj_mask_def_dap',\n",
       "       'obj_mask_def_dap_score', 'obj_mask_lsp_dap', 'obj_mask_lsp_dap_score',\n",
       "       'sub_sister', 'obj_label_sg', 'p1_sentence', 'p5_sentence',\n",
       "       'p10_sentence', 'p1_def_sap', 'p5_def_sap', 'p10_def_sap', 'p1_lsp_sap',\n",
       "       'p5_lsp_sap', 'p10_lsp_sap', 'p1_def_dap', 'p5_def_dap', 'p10_def_dap',\n",
       "       'p1_lsp_dap', 'p5_lsp_dap', 'p10_lsp_dap', 'mrr_sentence',\n",
       "       'mrr_def_sap', 'mrr_lsp_sap', 'mrr_def_dap', 'mrr_lsp_dap',\n",
       "       'anchor_wordnet_path_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../../log/bert-large-uncased/ALL/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWStrength.HYPERNYMSUITE.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b08a22-5911-488e-8632-a8b0bee20dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e711e18-3512-4602-9bd2-79b9c3dfbfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading cohyponyms: ../log/word_to_cohyponyms.txt\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "def read_cohyponyms(path = '../log/word_to_cohyponyms.txt'):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"reading cohyponyms: {path}\")\n",
    "        df = pd.read_csv(path)\n",
    "        df['cohyponyms'] = df['cohyponyms'].apply(lambda x: eval(x))\n",
    "        word_to_cohyponym = dict(zip(df['word'].to_list(), df['cohyponyms'].to_list()))\n",
    "        return word_to_cohyponym\n",
    "    print(f\"{path} not found\")\n",
    "word_to_cohyponym = read_cohyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c9052b-6125-4020-9937-726066470389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# path = '../log/word_to_cohyponyms_score.json'\n",
    "\n",
    "def read_cohyponyms_with_score(path = '../log/word_to_cohyponyms_score.json'):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"reading cohyponyms: {path}\")\n",
    "        word_to_cohyponym_score = json.load(open(path, 'r'))\n",
    "        word_to_cohyponym = {k: list(v.keys()) for k,v in data.items()}\n",
    "        return word_to_cohyponym\n",
    "print(f\"{path} not found\")\n",
    "\n",
    "word_to_cohyponym = read_cohyponyms_with_score()\n",
    "\n",
    "print( word_to_cohyponym ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc46df-fb10-4d93-bca5-b1025e521b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e6c6acb-4659-4c3f-9fb3-5f279adbb068",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name dataclass_transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-7052a9af5e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimple_separated_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minflection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msingularize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpluralize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdf_to_latex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFrame2Latex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/gpfs/projects/punim0478/chunhua/cogsci/DAP/pre_post_process/script/inflection.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyinflect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# set library-specific custom warning handling before doing anything else\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/spacy/errors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mErrorsWithCodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/spacy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/thinc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcatalogue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfigValidationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVARIABLE_RE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/confection/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfigparser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParsingError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelMetaclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelField\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pydantic/__init__.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36minit pydantic.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pydantic/dataclasses.cpython-37m-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36minit pydantic.dataclasses\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name dataclass_transform"
     ]
    }
   ],
   "source": [
    "import os, sys \n",
    "import pandas as pd\n",
    "pd.options.display.max_columns=500\n",
    "pd.options.display.max_colwidth=1000\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "tqdm.pandas()\n",
    "import re \n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "# import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from tabulate import tabulate, simple_separated_format\n",
    "from inflection import singularize, pluralize\n",
    "from df_to_latex import DataFrame2Latex\n",
    "from collections import Counter, defaultdict\n",
    "from inflection import singularize, pluralize\n",
    "\n",
    "from utils_path import dataset_to_respath\n",
    "# # Using WN, WN.taxonomy to retrieve path distance \n",
    "# - Pointers: \n",
    "#     - https://wn.readthedocs.io/en/latest/setup.html\n",
    "#     - https://wn.readthedocs.io/en/latest/api/wn.html\n",
    "# \n",
    "# - Installation: \n",
    "# ```\n",
    "# !pip install wn\n",
    "# !pip install wn[web]\n",
    "# wn.download('ewn:2020')\n",
    "# ```\n",
    "\n",
    "# get the co-hyponyms from WordNet (Shick and Schutze, 2020)\n",
    "# - get the hypernyms, maxinum d(x,y) is 2\n",
    "# - get the top 2 most frequent senses of each hypernym \n",
    "# - get hyponyms of each hypernyms, maxinum distance d(y,z) is 4 \n",
    "# - constrain the depeth of hypernyms to be 6\n",
    "\n",
    "# In[201]:\n",
    "\n",
    "\n",
    "import re \n",
    "import wn, wn.taxonomy\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "\n",
    "def test_min_depth():\n",
    "    for word in ['concept', 'thought', 'living thing', 'whole', 'psychological feature', 'unit', 'artifact', 'abstraction', 'object','physical entity', 'entity']:\n",
    "        synset = wn.synsets(word, pos='n')[0]\n",
    "        min_depth = wn.taxonomy.min_depth(synset, simulate_root=False)\n",
    "        print(word, min_depth)\n",
    "\n",
    "\n",
    "def get_inherited_hypernyms(word, k_synset, max_path_hyper, min_taxo_depth=6, print_flag=False):\n",
    "    '''\n",
    "    k_synset: the most frequent k_synset of word\n",
    "    max_path_hyper: up to k level of hypernyms, e.g., 2 level higher than word \n",
    "    min_taxo_depth=6: concept, exluded hypernyms: unit, object, artifact, entity\n",
    "    '''\n",
    "    \n",
    "    hyper_synsets = []\n",
    "    for i, synset in enumerate(wn.synsets(word, pos='n')[:k_synset]): #top K senses of word \n",
    "        #print(f\"{word} synset {i+1}\")\n",
    "        for j, path in enumerate(wn.taxonomy.hypernym_paths(synset)): #retrieve the hyper path for each synset \n",
    "            #print(f\"path {j}\")\n",
    "            for i, ss in enumerate(path[:max_path_hyper]): # get the hypernyms within max_path_hyper\n",
    "                ss_min_txo_depth = wn.taxonomy.min_depth(ss, simulate_root=False)\n",
    "                \n",
    "                if ss_min_txo_depth< min_taxo_depth: continue  #remove general concepts like \"entity\", 'physical entity'\n",
    "                hyper_synsets.append(ss)\n",
    "                if print_flag: \n",
    "                    print(' ' * i, ss, ss.lemmas()[0], ss_min_txo_depth)\n",
    "                    \n",
    "    return hyper_synsets\n",
    "\n",
    "def get_direct_hyonyms(synsets):\n",
    "    '''\n",
    "    Return the direct hyponyms of a given list of synsets\n",
    "    ''' \n",
    "    sister_synsets = []\n",
    "    for synset in synsets: \n",
    "        sister_synsets.extend(synset.hyponyms() )\n",
    "    return sister_synsets\n",
    "\n",
    "\n",
    "def get_inherited_hyponyms(initial_synsets, max_path_hypo):\n",
    "    synsets = initial_synsets\n",
    "    synsets_hyponyms = []\n",
    "    \n",
    "    while max_path_hypo>0:\n",
    "        synsets = get_direct_hyonyms(synsets)\n",
    "        synsets_hyponyms.extend(synsets)\n",
    "        max_path_hypo -=1\n",
    "        #print(dist)\n",
    "        #print(synsets)\n",
    "        #print(\"-\"*80)\n",
    "    #print(Counter(synsets_all).most_common())\n",
    "    return synsets_hyponyms\n",
    "\n",
    "\n",
    "def filter_cohyponyms(word, synsets_cohyponyms, top_k=50):\n",
    "    cohyponyms = []\n",
    "    for synset in synsets_cohyponyms:\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma == word: continue \n",
    "            if len(lemma.split(\" \")) >1 or len(lemma.split(\"-\")) >1: continue \n",
    "            cohyponyms.append(lemma.lower())\n",
    "    cohyponyms = Counter(cohyponyms)\n",
    "     #if top_k !=None:        \n",
    "    return cohyponyms.most_common(top_k)\n",
    "    #else:\n",
    "    #    return dict(cohyponyms.most_common())\n",
    "\n",
    "    \n",
    "def get_cohyponyms(word, top_k_cohyonyms=50, top_k_word_synset=2, max_path_hyper=2, max_path_hypo =4, print_flag=False):\n",
    "    \n",
    "    hyper_synsets = get_inherited_hypernyms(word, k_synset=top_k_word_synset, max_path_hyper = max_path_hyper)\n",
    "    if print_flag:\n",
    "        for synset in hyper_synsets:\n",
    "            print(synset, synset.lemmas())\n",
    "\n",
    "    synsets_cohyponyms = get_inherited_hyponyms(hyper_synsets, max_path_hypo= max_path_hypo)\n",
    "\n",
    "    concept_cohyponyms = filter_cohyponyms(word, synsets_cohyponyms, top_k=top_k_cohyonyms)\n",
    "    return list(dict(concept_cohyponyms).keys())\n",
    "   \n",
    "\n",
    "def test_get_cohyponyms(word, test_cohyponyms):\n",
    "    '''\n",
    "    word = 'corn'\n",
    "    test_cohyponyms = ['bean', 'potato', 'barley', 'wheat', 'pea'] \n",
    "    word = 'train'\n",
    "    test_cohyponyms = ['bus', 'plane', 'car', 'tram', 'truck']\n",
    "    test_get_cohyponyms(word,test_cohyponyms )\n",
    "    '''\n",
    "    top_k_cohyonyms = None #200 \n",
    "    top_k_word_synset = 2\n",
    "    max_path_hyper = 2\n",
    "    max_path_hypo = 4\n",
    "\n",
    "    concept_cohyponyms  = get_cohyponyms(word, top_k_cohyonyms=top_k_cohyonyms, \n",
    "                                         top_k_word_synset=top_k_word_synset, \n",
    "                                         max_path_hyper=max_path_hyper, max_path_hypo = max_path_hypo)\n",
    "    \n",
    "    for query in test_cohyponyms:\n",
    "        if query in concept_cohyponyms:\n",
    "            print(query, 'yes')\n",
    "        else:\n",
    "            print(query, 'no')\n",
    "    print(len(concept_cohyponyms), concept_cohyponyms)\n",
    "\n",
    "\n",
    "\n",
    "# # Evaluation \n",
    "\n",
    "# In[225]:\n",
    "\n",
    "\n",
    "def merge_predictions_in_concept_level(words, uniform_funcion=None, top_k=None ):\n",
    "    '''\n",
    "    uniform_function: either signualarize or pluralize \n",
    "    '''\n",
    "    words_uniformed = [uniform_funcion(word) for word in words] if uniform_funcion !=None else words\n",
    "    concepts = list(OrderedDict.fromkeys(words_uniformed))\n",
    "    return concepts[:top_k] if top_k is not None else concepts\n",
    "\n",
    "def concept_evaluation(label, pred):\n",
    "    '''\n",
    "    \n",
    "    label: a list with the singualr and plural labels (e.g., ['tool', 'tools'])\n",
    "    pred: the top K prediction list \n",
    "\n",
    "    return:\n",
    "        1 if label share with pred else 0  \n",
    "    '''\n",
    "    if not isinstance(label, list):\n",
    "        label = eval(label)\n",
    "        \n",
    "    if not isinstance(pred, list):\n",
    "        pred = eval(pred)\n",
    "\n",
    "    shared = set(label).intersection(set(pred))\n",
    "    return 1 if len(shared)>0 else 0 \n",
    "    # return len(shared)/len(pred)\n",
    "    \n",
    "\n",
    "def get_precision_at_k_concept(df, relation, pred_cols, label_col, k_list, pred_col_suffix='obj_mask_'):\n",
    "    '''\n",
    "    evalaute model predictions in concept level, ignoring the morphology affects (singular, plural)\n",
    "    '''\n",
    "\n",
    "    p_at_x = [] #defaultdict() \n",
    "    for pred_col in pred_cols: \n",
    "        suffix = pred_col.replace(pred_col_suffix, \"\")\n",
    "        prec_cur = defaultdict()\n",
    "        prec_cur['mask_type'] = suffix\n",
    "        for k in k_list: \n",
    "            df[f'p{k}_{suffix}'] = df[[label_col, pred_col]].apply(lambda x: concept_evaluation(x[0], eval(x[1])[:k] if isinstance(x[1], str) else x[1][:k]), axis=1 )\n",
    "            prec_cur[f'p@{k}'] = round(df[f'p{k}_{suffix}'].mean() , 3)*100\n",
    "\n",
    "        p_at_x.append(prec_cur)  \n",
    "        \n",
    "\n",
    "    # aggregate the average precision across k \n",
    "    df_res = pd.DataFrame(p_at_x) #, columns=['mask_type', 'mAP'])\n",
    "    df_res['relation'] = [relation]*len(df_res)\n",
    "    return df_res\n",
    "\n",
    "def get_highest_mrr_among_labels(label, pred):\n",
    "    '''\n",
    "    return the highest rank among the multiple labels. This is applicable to single labels as well, if we the single label is put in a list\n",
    "\n",
    "    pred: a list of words (candidates)\n",
    "    label: the true labels, which is a list (different forms of a word, e.g., singular or plurs, like animal and animals)\n",
    "    '''\n",
    "    mrr = 0 \n",
    "    if pred is None: return mrr \n",
    "\n",
    "    rank_list = [ pred.index(item) + 1 for item in label if item in pred] \n",
    "    if len(rank_list)>0:\n",
    "        mrr = 1/min(rank_list)\n",
    "\n",
    "    return mrr \n",
    "\n",
    "\n",
    "def get_mrr(df, relation, pred_cols, label_col, pred_col_suffix):\n",
    "    '''\n",
    "    mrr is calculated based on the top_k rank, all elements in obj_col are used\n",
    "    '''\n",
    "\n",
    "    mrr = [] \n",
    "    for i, pred_col in enumerate(pred_cols):\n",
    "        cur_mrr = defaultdict()\n",
    "        suffix = pred_col.replace(pred_col_suffix, \"\")\n",
    "\n",
    "        df[f'mrr_{suffix}'] = df[[label_col, pred_col]].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1 ) \n",
    "        \n",
    "        cur_mrr['mask_type'] = suffix\n",
    "        cur_mrr[f\"mrr\"] = round(df[f'mrr_{suffix}'].mean(), 3)*100\n",
    "        mrr.append(cur_mrr)\n",
    "\n",
    "    mrr_df =  pd.DataFrame(data = mrr) #, columns=['mask_type', 'mrr'])\n",
    "    # mrr_df['mask_type']= mrr_df['mask_type'].apply(lambda x: x.replace(\"\"))\n",
    "    mrr_df['relation'] = relation\n",
    "    return mrr_df \n",
    "\n",
    "\n",
    "# In[202]:\n",
    "\n",
    "\n",
    "def get_dataset_to_respath(dataset_to_respath, print_flag=False):\n",
    "    # remote path \n",
    "#     dataset_to_respath = {'hypernymsuite-BLESS': 'log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'lm_diagnostic_extended-singular': 'log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv', 'clsb-singular': 'log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv', 'hypernymsuite-LEDS': 'log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-EVAL': 'log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-SHWARTZ': 'log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv'}\n",
    "\n",
    "    source_dir = 'spartan:~/cogsci/DAP/'\n",
    "    target_dir = '../../'\n",
    "    dataset_to_localpath = defaultdict()\n",
    "    dataset_rename = {\n",
    "        'hypernymsuite-BLESS': 'BLESS', 'lm_diagnostic_extended-singular': 'DIAG', 'clsb-singular':'CLSB', 'hypernymsuite-LEDS': 'LEDS', 'hypernymsuite-EVAL': 'EVAL', 'hypernymsuite-SHWARTZ': \n",
    "        \"SHWARTZ\"\n",
    "    }\n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        path = path.replace(\".tsv\", \".csv\")\n",
    "        source_path = source_dir + path \n",
    "        dataset_l1 = dataset.split(\"-\")[0]\n",
    "        dataset_l2 = dataset.split(\"-\")[1] \n",
    "        target_path = target_dir + path\n",
    "        scp_string = f\"!scp {source_path} {target_path}\"\n",
    "        if print_flag:\n",
    "            print(scp_string)\n",
    "            print()\n",
    "#         print(target_path)\n",
    "        dataset_to_localpath[dataset_rename[dataset]] = target_path \n",
    "#     print(dataset_to_localpath)\n",
    "    return dataset_to_localpath\n",
    "dataset_to_localpath = get_dataset_to_respath(dataset_to_respath)\n",
    "\n",
    "\n",
    "from nltk.corpus import wordnet \n",
    "wn_lemmas = set(wordnet.all_lemma_names())\n",
    "def check_word_in_wordnet(word, wn_lemmas):\n",
    "    '''\n",
    "    1 if word in wordnet else 0\n",
    "    '''\n",
    "    return 1 if word in wn_lemmas else 0 \n",
    "\n",
    "\n",
    "def get_all_vocab(dataset_to_localpath):\n",
    "    dataset_to_df = defaultdict()\n",
    "    vocab_sub = set()\n",
    "    for dataset, path in dataset_to_localpath.items(): \n",
    "        if debug:\n",
    "           if dataset!='DIAG': continue \n",
    "        print(\"dataset\", dataset)\n",
    "        df = pd.read_csv(path)\n",
    "        vocab_sub.update(df['sub_label_sg'].to_list())\n",
    "        print(len(vocab_sub))\n",
    "    return list(vocab_sub)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Config for getting co-hyponyms from WordNet\n",
    "top_k_cohyonyms = None #200 \n",
    "top_k_word_synset = 2\n",
    "max_path_hyper = 2\n",
    "max_path_hypo = 4\n",
    "\n",
    "#config for evaluation \n",
    "pred_col_suffix=''\n",
    "label_col = 'sub_sister_new'\n",
    "pred_cols = ['subj_anchors_all_sg']\n",
    "relation='co-hyponyms'\n",
    "debug= True #True #eval(sys.argv[1])\n",
    "print(\"debug\", debug)\n",
    "\n",
    "word= 'mug'\n",
    "cohyponyms = get_cohyponyms(word, top_k_cohyonyms=top_k_cohyonyms, \n",
    "                                 top_k_word_synset=top_k_word_synset, \n",
    "                                 max_path_hyper=max_path_hyper, \n",
    "                                 max_path_hypo = max_path_hypo)\n",
    "word_to_cohyponyms[word] = cohyponyms\n",
    "if debug:\n",
    "    print(word, cohyponyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79c7a0a1-9922-4d9e-bfed-77e45950eea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.5.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001b[K     || 6.5 MB 40.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions<4.5.0,>=3.7.4.1 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc/8.3.0/openmpi/3.1.4/jupyter/1.0.0-python-3.7.4/lib/python3.7/site-packages (from spacy) (3.10.0.0)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
      "\u001b[K     || 126 kB 112.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
      "\u001b[K     || 490 kB 103.9 MB/s eta 0:00:01           | 225 kB 103.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (912 kB)\n",
      "\u001b[K     || 912 kB 110.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/easybuild-2019/easybuild/software/mpi/gcc/8.3.0/openmpi/3.1.4/scipy-bundle/2019.10-python-3.7.4/lib/python3.7/site-packages (from spacy) (1.17.3)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     || 56 kB 5.1 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/setuptools/57.4.0-python-3.7.4/lib/python3.7/site-packages (from spacy) (57.4.0)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     || 42 kB 375 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/chunhua/.local/lib/python3.7/site-packages (from spacy) (4.64.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[K     || 181 kB 116.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from spacy) (2.10.1)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "\u001b[K     || 48 kB 1.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     || 3.1 MB 117.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (0.6.0)\n",
      "Collecting typing-extensions<4.5.0,>=3.7.4.1\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[K     || 10.2 MB 109.7 MB/s eta 0:00:01                    | 2.0 MB 109.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting click<9.0.0,>=7.1.1\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     || 96 kB 9.7 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.8.0,>=0.3.0->spacy) (0.22)\n",
      "Requirement already satisfied: more-itertools in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from zipp>=0.5->catalogue<2.1.0,>=2.0.6->spacy) (7.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/lib/python3.7/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Installing collected packages: typing-extensions, catalogue, srsly, pydantic, murmurhash, cymem, click, wasabi, typer, smart-open, preshed, packaging, confection, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 click-8.1.3 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 packaging-23.0 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.5 smart-open-6.3.0 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.8 typer-0.7.0 typing-extensions-4.4.0 wasabi-1.1.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/usr/local/easybuild-2019/easybuild/software/compiler/gcccore/8.3.0/python/3.7.4/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1106ab91-2503-4dc9-a60a-1ec5f208d962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label_sg</th>\n",
       "      <th>obj_mask_def_sap</th>\n",
       "      <th>mrr_def_sap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4376</th>\n",
       "      <td>boulevard</td>\n",
       "      <td>['film']</td>\n",
       "      <td>['road', 'street', 'highway', 'avenue', 'roadway', 'route', 'path', 'expressway', 'drive', 'city']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>supper</td>\n",
       "      <td>['meal']</td>\n",
       "      <td>['meal', 'dinner', 'feast', 'banquet', 'breakfast', 'entertainment', 'party', 'lunch', 'food', 'celebration']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>reels</td>\n",
       "      <td>['equipment']</td>\n",
       "      <td>['film', 'tape', 'rope', 'string', 'puppet', 'rod', 'frame', 'camera', 'instrument', 'vessel']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4419</th>\n",
       "      <td>players</td>\n",
       "      <td>['film']</td>\n",
       "      <td>['player', 'team', 'person', 'machine', 'computer', 'car', 'game', 'ship', 'vehicle', 'vessel']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>washers</td>\n",
       "      <td>['good']</td>\n",
       "      <td>['machine', 'toilet', 'laundry', 'sink', 'robot', 'person', 'refrigerator', 'broom', 'vacuum', 'oven']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4142</th>\n",
       "      <td>retaliations</td>\n",
       "      <td>['film']</td>\n",
       "      <td>['punishment', 'revenge', 'reaction', 'response', 'retribution', 'defense', 'crime', 'penalty', 'vengeance', 'threat']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>['song']</td>\n",
       "      <td>['science', 'observatory', 'art', 'discipline', 'telescope', 'architecture', 'painting', 'hobby', 'music', 'physics']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>migraine</td>\n",
       "      <td>['ache']</td>\n",
       "      <td>['headache', 'pain', 'condition', 'disorder', 'disease', 'mania', 'fever', 'seizure', 'nightmare', 'vertigo']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>noises</td>\n",
       "      <td>['sound']</td>\n",
       "      <td>['sound', 'thing', 'vibration', 'language', 'music', 'word', 'voice', 'action', 'signal', 'response']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>warning</td>\n",
       "      <td>['advice']</td>\n",
       "      <td>['threat', 'promise', 'message', 'order', 'signal', 'sign', 'alarm', 'advice', 'command', 'statement']</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>skunks</td>\n",
       "      <td>['mammal']</td>\n",
       "      <td>['dog', 'animal', 'mammal', 'bird', 'rat', 'creature', 'fox', 'cat', 'weasel', 'fish']</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>miracles</td>\n",
       "      <td>['book']</td>\n",
       "      <td>['magic', 'event', 'faith', 'religion', 'healing', 'belief', 'curse', 'prayer', 'ritual', 'phenomenon']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>tables</td>\n",
       "      <td>['artifact']</td>\n",
       "      <td>['structure', 'object', 'database', 'chair', 'graph', 'building', 'furniture', 'chart', 'desk', 'room']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>prayers</td>\n",
       "      <td>['work']</td>\n",
       "      <td>['ritual', 'meditation', 'chant', 'mantra', 'worship', 'devotion', 'gesture', 'liturgy', 'statement', 'sermon']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>mankind</td>\n",
       "      <td>['mammal']</td>\n",
       "      <td>['humanity', 'human', 'man', 'god', 'person', 'people', 'civilization', 'nation', 'animal', 'society']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>california</td>\n",
       "      <td>['single']</td>\n",
       "      <td>['state', 'car', 'desert', 'person', 'mountain', 'tree', 'boat', 'house', 'horse', 'country']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>jellyfish</td>\n",
       "      <td>['film']</td>\n",
       "      <td>['fish', 'jelly', 'mollusk', 'octopus', 'sponge', 'shrimp', 'animal', 'lobster', 'coral', 'squid']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>breakdowns</td>\n",
       "      <td>['album']</td>\n",
       "      <td>['failure', 'disorder', 'accident', 'break', 'problem', 'panic', 'divorce', 'depression', 'loss', 'reaction']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>pools</td>\n",
       "      <td>['group']</td>\n",
       "      <td>['reservoir', 'lake', 'pond', 'building', 'river', 'tank', 'water', 'fountain', 'structure', 'aquarium']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>springs</td>\n",
       "      <td>['organization']</td>\n",
       "      <td>['spring', 'river', 'stream', 'noun', 'pool', 'car', 'boat', 'word', 'place', 'reservoir']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>surprises</td>\n",
       "      <td>['feeling']</td>\n",
       "      <td>['holiday', 'event', 'shock', 'celebration', 'entertainment', 'vacation', 'reaction', 'relief', 'greeting', 'game']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>males</td>\n",
       "      <td>['beast']</td>\n",
       "      <td>['animal', 'female', 'mammal', 'god', 'bird', 'queen', 'insect', 'man', 'human', 'woman']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>lands</td>\n",
       "      <td>['place']</td>\n",
       "      <td>['place', 'thing', 'property', 'space', 'country', 'territory', 'terrain', 'area', 'lot', 'soil']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>studios</td>\n",
       "      <td>['workplace']</td>\n",
       "      <td>['building', 'house', 'laboratory', 'place', 'office', 'gallery', 'theatre', 'factory', 'space', 'home']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>pubs</td>\n",
       "      <td>['construction']</td>\n",
       "      <td>['tavern', 'building', 'house', 'hotel', 'restaurant', 'establishment', 'bar', 'place', 'inn', 'club']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>takeovers</td>\n",
       "      <td>['song']</td>\n",
       "      <td>['merger', 'coup', 'election', 'conflict', 'negotiation', 'revolution', 'change', 'compromise', 'divorce', 'action']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>wheels</td>\n",
       "      <td>['invention']</td>\n",
       "      <td>['vehicle', 'bicycle', 'machine', 'car', 'device', 'lever', 'automobile', 'object', 'tool', 'mechanism']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>leopard</td>\n",
       "      <td>['animal']</td>\n",
       "      <td>['animal', 'cat', 'bird', 'tiger', 'lion', 'mammal', 'dog', 'wolf', 'beast', 'panther']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>wings</td>\n",
       "      <td>['food']</td>\n",
       "      <td>['aircraft', 'structure', 'building', 'bird', 'tail', 'body', 'roof', 'butterfly', 'plane', 'feather']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>park</td>\n",
       "      <td>['place']</td>\n",
       "      <td>['place', 'garden', 'city', 'playground', 'cemetery', 'landscape', 'forest', 'neighborhood', 'space', 'building']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>cakes</td>\n",
       "      <td>['band']</td>\n",
       "      <td>['dessert', 'food', 'bread', 'decoration', 'pastry', 'dish', 'pudding', 'fruit', 'meal', 'pie']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>super</td>\n",
       "      <td>['artist']</td>\n",
       "      <td>['superhero', 'star', 'person', 'car', 'machine', 'locomotive', 'robot', 'monster', 'giant', 'ship']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>rose</td>\n",
       "      <td>['symbol']</td>\n",
       "      <td>['flower', 'fruit', 'plant', 'shrub', 'orchid', 'perfume', 'vase', 'tree', 'flowers', 'symbol']</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>lipids</td>\n",
       "      <td>['molecule']</td>\n",
       "      <td>['protein', 'molecule', 'substance', 'liquid', 'cell', 'sugar', 'gas', 'fluid', 'polymer', 'solid']</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>wool</td>\n",
       "      <td>['material']</td>\n",
       "      <td>['cloth', 'fabric', 'material', 'textile', 'yarn', 'fiber', 'fibre', 'cotton', 'thread', 'clothing']</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>brothers</td>\n",
       "      <td>['episode']</td>\n",
       "      <td>['sister', 'family', 'brother', 'sisters', 'pair', 'car', 'locomotive', 'house', 'boat', 'father']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>lava</td>\n",
       "      <td>['color']</td>\n",
       "      <td>['rock', 'volcano', 'liquid', 'magma', 'gas', 'substance', 'river', 'stone', 'fluid', 'water']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>mileage</td>\n",
       "      <td>['distance']</td>\n",
       "      <td>['unit', 'distance', 'number', 'measurement', 'metric', 'quantity', 'measure', 'percentage', 'value', 'constant']</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>kidnaps</td>\n",
       "      <td>['film']</td>\n",
       "      <td>['kidnapping', 'abduction', 'crime', 'ransom', 'threat', 'search', 'robbery', 'terrorism', 'punishment', 'emergency']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>rave</td>\n",
       "      <td>['film']</td>\n",
       "      <td>['party', 'music', 'entertainment', 'carnival', 'dance', 'concert', 'gathering', 'celebration', 'event', 'club']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>phantoms</td>\n",
       "      <td>['film']</td>\n",
       "      <td>['ghost', 'robot', 'phantom', 'car', 'cat', 'aircraft', 'shadow', 'machine', 'demon', 'vehicle']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>rome</td>\n",
       "      <td>['leaders']</td>\n",
       "      <td>['city', 'roman', 'building', 'ship', 'place', 'temple', 'boat', 'house', 'country', 'town']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>change</td>\n",
       "      <td>['song']</td>\n",
       "      <td>['transformation', 'action', 'event', 'transition', 'shift', 'process', 'movement', 'mistake', 'reaction', 'development']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>tunnels</td>\n",
       "      <td>['nightclub']</td>\n",
       "      <td>['road', 'building', 'passage', 'bridge', 'structure', 'construction', 'railroad', 'cave', 'roadway', 'passageway']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>clarinets</td>\n",
       "      <td>['object']</td>\n",
       "      <td>['instrument', 'flute', 'trumpet', 'saxophone', 'trombone', 'guitar', 'oboe', 'horn', 'organ', 'violin']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>best</td>\n",
       "      <td>['album']</td>\n",
       "      <td>['worst', 'failure', 'house', 'book', 'car', 'perfection', 'minimum', 'lot', 'place', 'building']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>onions</td>\n",
       "      <td>['ingredient']</td>\n",
       "      <td>['vegetable', 'potato', 'plant', 'carrot', 'mushroom', 'sausage', 'herb', 'cabbage', 'garlic', 'fruit']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>canary</td>\n",
       "      <td>['animal']</td>\n",
       "      <td>['bird', 'cat', 'parrot', 'animal', 'pigeon', 'crow', 'bee', 'fish', 'butterfly', 'mammal']</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>noses</td>\n",
       "      <td>['feature']</td>\n",
       "      <td>['mouth', 'horn', 'bone', 'tongue', 'object', 'structure', 'instrument', 'organ', 'thumb', 'shape']</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>raccoons</td>\n",
       "      <td>['mammal']</td>\n",
       "      <td>['mammal', 'dog', 'animal', 'cat', 'fox', 'predator', 'canine', 'primate', 'pig', 'monkey']</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sub_label      obj_label_sg  \\\n",
       "4376     boulevard          ['film']   \n",
       "1116        supper          ['meal']   \n",
       "1201         reels     ['equipment']   \n",
       "4419       players          ['film']   \n",
       "379        washers          ['good']   \n",
       "4142  retaliations          ['film']   \n",
       "3254     astronomy          ['song']   \n",
       "1354      migraine          ['ache']   \n",
       "1740        noises         ['sound']   \n",
       "2941       warning        ['advice']   \n",
       "837         skunks        ['mammal']   \n",
       "2825      miracles          ['book']   \n",
       "203         tables      ['artifact']   \n",
       "2158       prayers          ['work']   \n",
       "1176       mankind        ['mammal']   \n",
       "3867    california        ['single']   \n",
       "3241     jellyfish          ['film']   \n",
       "3145    breakdowns         ['album']   \n",
       "1797         pools         ['group']   \n",
       "2975       springs  ['organization']   \n",
       "1118     surprises       ['feeling']   \n",
       "4383         males         ['beast']   \n",
       "1657         lands         ['place']   \n",
       "1042       studios     ['workplace']   \n",
       "179           pubs  ['construction']   \n",
       "3502     takeovers          ['song']   \n",
       "933         wheels     ['invention']   \n",
       "633        leopard        ['animal']   \n",
       "2033         wings          ['food']   \n",
       "1760          park         ['place']   \n",
       "3532         cakes          ['band']   \n",
       "4143         super        ['artist']   \n",
       "800           rose        ['symbol']   \n",
       "1338        lipids      ['molecule']   \n",
       "2037          wool      ['material']   \n",
       "3715      brothers       ['episode']   \n",
       "3218          lava         ['color']   \n",
       "3742       mileage      ['distance']   \n",
       "4665       kidnaps          ['film']   \n",
       "3100          rave          ['film']   \n",
       "2213      phantoms          ['film']   \n",
       "4225          rome       ['leaders']   \n",
       "3547        change          ['song']   \n",
       "3516       tunnels     ['nightclub']   \n",
       "108      clarinets        ['object']   \n",
       "2184          best         ['album']   \n",
       "697         onions    ['ingredient']   \n",
       "557         canary        ['animal']   \n",
       "689          noses       ['feature']   \n",
       "770       raccoons        ['mammal']   \n",
       "\n",
       "                                                                                                               obj_mask_def_sap  \\\n",
       "4376                         ['road', 'street', 'highway', 'avenue', 'roadway', 'route', 'path', 'expressway', 'drive', 'city']   \n",
       "1116              ['meal', 'dinner', 'feast', 'banquet', 'breakfast', 'entertainment', 'party', 'lunch', 'food', 'celebration']   \n",
       "1201                             ['film', 'tape', 'rope', 'string', 'puppet', 'rod', 'frame', 'camera', 'instrument', 'vessel']   \n",
       "4419                            ['player', 'team', 'person', 'machine', 'computer', 'car', 'game', 'ship', 'vehicle', 'vessel']   \n",
       "379                      ['machine', 'toilet', 'laundry', 'sink', 'robot', 'person', 'refrigerator', 'broom', 'vacuum', 'oven']   \n",
       "4142     ['punishment', 'revenge', 'reaction', 'response', 'retribution', 'defense', 'crime', 'penalty', 'vengeance', 'threat']   \n",
       "3254      ['science', 'observatory', 'art', 'discipline', 'telescope', 'architecture', 'painting', 'hobby', 'music', 'physics']   \n",
       "1354              ['headache', 'pain', 'condition', 'disorder', 'disease', 'mania', 'fever', 'seizure', 'nightmare', 'vertigo']   \n",
       "1740                      ['sound', 'thing', 'vibration', 'language', 'music', 'word', 'voice', 'action', 'signal', 'response']   \n",
       "2941                     ['threat', 'promise', 'message', 'order', 'signal', 'sign', 'alarm', 'advice', 'command', 'statement']   \n",
       "837                                      ['dog', 'animal', 'mammal', 'bird', 'rat', 'creature', 'fox', 'cat', 'weasel', 'fish']   \n",
       "2825                    ['magic', 'event', 'faith', 'religion', 'healing', 'belief', 'curse', 'prayer', 'ritual', 'phenomenon']   \n",
       "203                     ['structure', 'object', 'database', 'chair', 'graph', 'building', 'furniture', 'chart', 'desk', 'room']   \n",
       "2158            ['ritual', 'meditation', 'chant', 'mantra', 'worship', 'devotion', 'gesture', 'liturgy', 'statement', 'sermon']   \n",
       "1176                     ['humanity', 'human', 'man', 'god', 'person', 'people', 'civilization', 'nation', 'animal', 'society']   \n",
       "3867                              ['state', 'car', 'desert', 'person', 'mountain', 'tree', 'boat', 'house', 'horse', 'country']   \n",
       "3241                         ['fish', 'jelly', 'mollusk', 'octopus', 'sponge', 'shrimp', 'animal', 'lobster', 'coral', 'squid']   \n",
       "3145              ['failure', 'disorder', 'accident', 'break', 'problem', 'panic', 'divorce', 'depression', 'loss', 'reaction']   \n",
       "1797                   ['reservoir', 'lake', 'pond', 'building', 'river', 'tank', 'water', 'fountain', 'structure', 'aquarium']   \n",
       "2975                                 ['spring', 'river', 'stream', 'noun', 'pool', 'car', 'boat', 'word', 'place', 'reservoir']   \n",
       "1118        ['holiday', 'event', 'shock', 'celebration', 'entertainment', 'vacation', 'reaction', 'relief', 'greeting', 'game']   \n",
       "4383                                  ['animal', 'female', 'mammal', 'god', 'bird', 'queen', 'insect', 'man', 'human', 'woman']   \n",
       "1657                          ['place', 'thing', 'property', 'space', 'country', 'territory', 'terrain', 'area', 'lot', 'soil']   \n",
       "1042                   ['building', 'house', 'laboratory', 'place', 'office', 'gallery', 'theatre', 'factory', 'space', 'home']   \n",
       "179                      ['tavern', 'building', 'house', 'hotel', 'restaurant', 'establishment', 'bar', 'place', 'inn', 'club']   \n",
       "3502       ['merger', 'coup', 'election', 'conflict', 'negotiation', 'revolution', 'change', 'compromise', 'divorce', 'action']   \n",
       "933                    ['vehicle', 'bicycle', 'machine', 'car', 'device', 'lever', 'automobile', 'object', 'tool', 'mechanism']   \n",
       "633                                     ['animal', 'cat', 'bird', 'tiger', 'lion', 'mammal', 'dog', 'wolf', 'beast', 'panther']   \n",
       "2033                     ['aircraft', 'structure', 'building', 'bird', 'tail', 'body', 'roof', 'butterfly', 'plane', 'feather']   \n",
       "1760          ['place', 'garden', 'city', 'playground', 'cemetery', 'landscape', 'forest', 'neighborhood', 'space', 'building']   \n",
       "3532                            ['dessert', 'food', 'bread', 'decoration', 'pastry', 'dish', 'pudding', 'fruit', 'meal', 'pie']   \n",
       "4143                       ['superhero', 'star', 'person', 'car', 'machine', 'locomotive', 'robot', 'monster', 'giant', 'ship']   \n",
       "800                             ['flower', 'fruit', 'plant', 'shrub', 'orchid', 'perfume', 'vase', 'tree', 'flowers', 'symbol']   \n",
       "1338                        ['protein', 'molecule', 'substance', 'liquid', 'cell', 'sugar', 'gas', 'fluid', 'polymer', 'solid']   \n",
       "2037                       ['cloth', 'fabric', 'material', 'textile', 'yarn', 'fiber', 'fibre', 'cotton', 'thread', 'clothing']   \n",
       "3715                         ['sister', 'family', 'brother', 'sisters', 'pair', 'car', 'locomotive', 'house', 'boat', 'father']   \n",
       "3218                             ['rock', 'volcano', 'liquid', 'magma', 'gas', 'substance', 'river', 'stone', 'fluid', 'water']   \n",
       "3742          ['unit', 'distance', 'number', 'measurement', 'metric', 'quantity', 'measure', 'percentage', 'value', 'constant']   \n",
       "4665      ['kidnapping', 'abduction', 'crime', 'ransom', 'threat', 'search', 'robbery', 'terrorism', 'punishment', 'emergency']   \n",
       "3100           ['party', 'music', 'entertainment', 'carnival', 'dance', 'concert', 'gathering', 'celebration', 'event', 'club']   \n",
       "2213                           ['ghost', 'robot', 'phantom', 'car', 'cat', 'aircraft', 'shadow', 'machine', 'demon', 'vehicle']   \n",
       "4225                               ['city', 'roman', 'building', 'ship', 'place', 'temple', 'boat', 'house', 'country', 'town']   \n",
       "3547  ['transformation', 'action', 'event', 'transition', 'shift', 'process', 'movement', 'mistake', 'reaction', 'development']   \n",
       "3516        ['road', 'building', 'passage', 'bridge', 'structure', 'construction', 'railroad', 'cave', 'roadway', 'passageway']   \n",
       "108                    ['instrument', 'flute', 'trumpet', 'saxophone', 'trombone', 'guitar', 'oboe', 'horn', 'organ', 'violin']   \n",
       "2184                          ['worst', 'failure', 'house', 'book', 'car', 'perfection', 'minimum', 'lot', 'place', 'building']   \n",
       "697                     ['vegetable', 'potato', 'plant', 'carrot', 'mushroom', 'sausage', 'herb', 'cabbage', 'garlic', 'fruit']   \n",
       "557                                 ['bird', 'cat', 'parrot', 'animal', 'pigeon', 'crow', 'bee', 'fish', 'butterfly', 'mammal']   \n",
       "689                         ['mouth', 'horn', 'bone', 'tongue', 'object', 'structure', 'instrument', 'organ', 'thumb', 'shape']   \n",
       "770                                 ['mammal', 'dog', 'animal', 'cat', 'fox', 'predator', 'canine', 'primate', 'pig', 'monkey']   \n",
       "\n",
       "      mrr_def_sap  \n",
       "4376     0.000000  \n",
       "1116     1.000000  \n",
       "1201     0.000000  \n",
       "4419     0.000000  \n",
       "379      0.000000  \n",
       "4142     0.000000  \n",
       "3254     0.000000  \n",
       "1354     0.000000  \n",
       "1740     1.000000  \n",
       "2941     0.125000  \n",
       "837      0.333333  \n",
       "2825     0.000000  \n",
       "203      0.000000  \n",
       "2158     0.000000  \n",
       "1176     0.000000  \n",
       "3867     0.000000  \n",
       "3241     0.000000  \n",
       "3145     0.000000  \n",
       "1797     0.000000  \n",
       "2975     0.000000  \n",
       "1118     0.000000  \n",
       "4383     0.000000  \n",
       "1657     1.000000  \n",
       "1042     0.000000  \n",
       "179      0.000000  \n",
       "3502     0.000000  \n",
       "933      0.000000  \n",
       "633      1.000000  \n",
       "2033     0.000000  \n",
       "1760     1.000000  \n",
       "3532     0.000000  \n",
       "4143     0.000000  \n",
       "800      0.100000  \n",
       "1338     0.500000  \n",
       "2037     0.333333  \n",
       "3715     0.000000  \n",
       "3218     0.000000  \n",
       "3742     0.500000  \n",
       "4665     0.000000  \n",
       "3100     0.000000  \n",
       "2213     0.000000  \n",
       "4225     0.000000  \n",
       "3547     0.000000  \n",
       "3516     0.000000  \n",
       "108      0.000000  \n",
       "2184     0.000000  \n",
       "697      0.000000  \n",
       "557      0.250000  \n",
       "689      0.000000  \n",
       "770      1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['sub_label', 'obj_label_sg', 'obj_mask_def_sap', 'mrr_def_sap']].sample(50)#.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a3368-1391-49f2-99f0-1c3f08b60dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef3b00da-2ebc-41b3-9406-305fd8fd1a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ['bass', 'carp', 'shrimp', 'perch', 'alligator...\n",
       "1      ['lime', 'orange', 'apple', 'yes', 'cherry', '...\n",
       "2      ['snake', 'bird', 'fish', 'lizard', 'frog', 'd...\n",
       "3      ['box', 'yes', 'shoe', 'case', 'obviously', 'y...\n",
       "4      ['fox', 'deer', 'squirrels', 'mouse', 'rodent'...\n",
       "                             ...                        \n",
       "874    ['nail', 'maybe', 'chain', 'bolt', 'nuts', 'ye...\n",
       "875    ['rabbit', 'deer', 'fox', 'squirrels', 'bear',...\n",
       "876    ['violin', 'guitar', 'piano', 'viola', 'string...\n",
       "877    ['mask', 'yes', 'glove', 'belt', 'maybe', 'rin...\n",
       "878    ['speaker', 'amplifier', 'radio', 'computer', ...\n",
       "Name: subj_anchors_all, Length: 879, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subj_anchors_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4fa8e873-0c78-44bf-971b-5d2396a53c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subj_anchors_shared</th>\n",
       "      <th>subj_anchors_swow</th>\n",
       "      <th>subj_anchors_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[whiskers, catsups]</td>\n",
       "      <td>['bass', 'carp', 'shrimp', 'perch', 'alligator', 'trout', 'rabbit', 'channel', 'cod', 'turtle']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[orange, yellow]</td>\n",
       "      <td>[limes, sour, citruses, yellow, rinds, lemonades, tarts, bitter, juices, squeeze, orange, peel, puckers, tequila, acids, sprites, teas, melons, waters, limo, squash]</td>\n",
       "      <td>['lime', 'orange', 'apple', 'yes', 'cherry', 'water', 'pepper', 'sugar', 'yellow', 'chocolate']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>[shells, slow, tortoises, seas, necks, reptile, ninja, amphibian, rabbits, shields, awkward, back, ponds, scales, speedy]</td>\n",
       "      <td>['snake', 'bird', 'fish', 'lizard', 'frog', 'dragon', 'shark', 'monkey', 'bear', 'deer']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[satchel, sack, purses, shopping, plastics, pouches, luggages, papers, pack, backpacks, carry, brown, saddles, trashes, carrying, beg, shoulders, parcels, lunches, bookbag, bundle, stuffs, capture, travels, cases, bags, rag, tote, lag, pockets, airports, suitcase, wallets, moneys, snag, puss, nag, canvas, carriers, baskets, shoes, sweets, rubbishes, supermarkets]</td>\n",
       "      <td>['box', 'yes', 'shoe', 'case', 'obviously', 'yeah', 'clothes', 'thing', 'maybe', 'package']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rodent]</td>\n",
       "      <td>[bunny, roger, carrots, white, rodent, breeding, jack, rabbi, magics, tails, multiply, pet, rascal, reproduce, lettuce, rabbits, speedy, bounces, turtles, cats, procreate, paws, breeds, tortoises, shoot, small]</td>\n",
       "      <td>['fox', 'deer', 'squirrels', 'mouse', 'rodent', 'rat', 'dog', 'wolf', 'snake']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>[]</td>\n",
       "      <td>[tools, monkeys, screwdriver, spanners, pipes, plumbing, sockets, bolts, tighten, pliers, benches, levers, mechanic, plumbers, ratchets, torques]</td>\n",
       "      <td>['nail', 'maybe', 'chain', 'bolt', 'nuts', 'yes', 'actually', 'obviously', 'rope', 'apparently']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>[]</td>\n",
       "      <td>[acorn, nuts, chipmunk, trees, rodent, bushy, brown, sandy, stash, chases, squirrel]</td>\n",
       "      <td>['rabbit', 'deer', 'fox', 'squirrels', 'bear', 'turkey', 'bird', 'yes', 'badger', 'beaver']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>[viola]</td>\n",
       "      <td>[violins, musics, instruments, orchestra, strings, basses, viola, bands, musicians, base]</td>\n",
       "      <td>['violin', 'guitar', 'piano', 'viola', 'string', 'flute', 'organ', 'keyboard']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['mask', 'yes', 'glove', 'belt', 'maybe', 'ring', 'coat', 'hand', 'hat', 'shoe']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>[]</td>\n",
       "      <td>[speakers, radios, audios, records, surround, analogs, basements, cassettes, receivers]</td>\n",
       "      <td>['speaker', 'amplifier', 'radio', 'computer', 'guitar', 'camera', 'monitor', 'keyboard', 'electronics', 'light']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>879 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subj_anchors_shared  \\\n",
       "0                    []   \n",
       "1      [orange, yellow]   \n",
       "2                    []   \n",
       "3                    []   \n",
       "4              [rodent]   \n",
       "..                  ...   \n",
       "874                  []   \n",
       "875                  []   \n",
       "876             [viola]   \n",
       "877                  []   \n",
       "878                  []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                 subj_anchors_swow  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                              [whiskers, catsups]   \n",
       "1                                                                                                                                                                                                            [limes, sour, citruses, yellow, rinds, lemonades, tarts, bitter, juices, squeeze, orange, peel, puckers, tequila, acids, sprites, teas, melons, waters, limo, squash]   \n",
       "2                                                                                                                                                                                                                                                        [shells, slow, tortoises, seas, necks, reptile, ninja, amphibian, rabbits, shields, awkward, back, ponds, scales, speedy]   \n",
       "3    [satchel, sack, purses, shopping, plastics, pouches, luggages, papers, pack, backpacks, carry, brown, saddles, trashes, carrying, beg, shoulders, parcels, lunches, bookbag, bundle, stuffs, capture, travels, cases, bags, rag, tote, lag, pockets, airports, suitcase, wallets, moneys, snag, puss, nag, canvas, carriers, baskets, shoes, sweets, rubbishes, supermarkets]   \n",
       "4                                                                                                                                                               [bunny, roger, carrots, white, rodent, breeding, jack, rabbi, magics, tails, multiply, pet, rascal, reproduce, lettuce, rabbits, speedy, bounces, turtles, cats, procreate, paws, breeds, tortoises, shoot, small]   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                             ...   \n",
       "874                                                                                                                                                                                                                              [tools, monkeys, screwdriver, spanners, pipes, plumbing, sockets, bolts, tighten, pliers, benches, levers, mechanic, plumbers, ratchets, torques]   \n",
       "875                                                                                                                                                                                                                                                                                           [acorn, nuts, chipmunk, trees, rodent, bushy, brown, sandy, stash, chases, squirrel]   \n",
       "876                                                                                                                                                                                                                                                                                      [violins, musics, instruments, orchestra, strings, basses, viola, bands, musicians, base]   \n",
       "877                                                                                                                                                                                                                                                                                                                                                                             []   \n",
       "878                                                                                                                                                                                                                                                                                        [speakers, radios, audios, records, surround, analogs, basements, cassettes, receivers]   \n",
       "\n",
       "                                                                                                     subj_anchors_all  \n",
       "0                     ['bass', 'carp', 'shrimp', 'perch', 'alligator', 'trout', 'rabbit', 'channel', 'cod', 'turtle']  \n",
       "1                     ['lime', 'orange', 'apple', 'yes', 'cherry', 'water', 'pepper', 'sugar', 'yellow', 'chocolate']  \n",
       "2                            ['snake', 'bird', 'fish', 'lizard', 'frog', 'dragon', 'shark', 'monkey', 'bear', 'deer']  \n",
       "3                         ['box', 'yes', 'shoe', 'case', 'obviously', 'yeah', 'clothes', 'thing', 'maybe', 'package']  \n",
       "4                                      ['fox', 'deer', 'squirrels', 'mouse', 'rodent', 'rat', 'dog', 'wolf', 'snake']  \n",
       "..                                                                                                                ...  \n",
       "874                  ['nail', 'maybe', 'chain', 'bolt', 'nuts', 'yes', 'actually', 'obviously', 'rope', 'apparently']  \n",
       "875                       ['rabbit', 'deer', 'fox', 'squirrels', 'bear', 'turkey', 'bird', 'yes', 'badger', 'beaver']  \n",
       "876                                    ['violin', 'guitar', 'piano', 'viola', 'string', 'flute', 'organ', 'keyboard']  \n",
       "877                                  ['mask', 'yes', 'glove', 'belt', 'maybe', 'ring', 'coat', 'hand', 'hat', 'shoe']  \n",
       "878  ['speaker', 'amplifier', 'radio', 'computer', 'guitar', 'camera', 'monitor', 'keyboard', 'electronics', 'light']  \n",
       "\n",
       "[879 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e7e862a6-9de8-4b7c-9fa7-c4a7f1820e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_sg</th>\n",
       "      <th>subj_anchors_shared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>moth</td>\n",
       "      <td>[insect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>rifle</td>\n",
       "      <td>[pistol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>sparrow</td>\n",
       "      <td>[robin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>beetle</td>\n",
       "      <td>[insect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>sheep</td>\n",
       "      <td>[cattle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>bus</td>\n",
       "      <td>[tram]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>bus</td>\n",
       "      <td>[tram]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>shirt</td>\n",
       "      <td>[tie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>cherry</td>\n",
       "      <td>[berry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>lemon</td>\n",
       "      <td>[orange, yellow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>pistol</td>\n",
       "      <td>[revolver, shotgun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>tiger</td>\n",
       "      <td>[lion, bear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>cedar</td>\n",
       "      <td>[oak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>pear</td>\n",
       "      <td>[peach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>rifle</td>\n",
       "      <td>[pistol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>rifle</td>\n",
       "      <td>[pistol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>toaster</td>\n",
       "      <td>[oven]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>screwdriver</td>\n",
       "      <td>[screw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>robe</td>\n",
       "      <td>[white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>shirt</td>\n",
       "      <td>[tie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>robe</td>\n",
       "      <td>[white]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>bowl</td>\n",
       "      <td>[bowling]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>apple</td>\n",
       "      <td>[pear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>piano</td>\n",
       "      <td>[organ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>plum</td>\n",
       "      <td>[pear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>screwdriver</td>\n",
       "      <td>[screw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>pear</td>\n",
       "      <td>[peach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>apricot</td>\n",
       "      <td>[peach]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>missile</td>\n",
       "      <td>[torpedo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>jar</td>\n",
       "      <td>[can, bottle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>castle</td>\n",
       "      <td>[moat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>pistol</td>\n",
       "      <td>[revolver, shotgun]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>library</td>\n",
       "      <td>[archive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>butterfly</td>\n",
       "      <td>[moth, insect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>castle</td>\n",
       "      <td>[moat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>bear</td>\n",
       "      <td>[lion, wolf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>rabbit</td>\n",
       "      <td>[rodent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>revolver</td>\n",
       "      <td>[pistol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>bed</td>\n",
       "      <td>[blanket, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>jet</td>\n",
       "      <td>[aircraft]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>blouse</td>\n",
       "      <td>[skirt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>violin</td>\n",
       "      <td>[viola]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>blouse</td>\n",
       "      <td>[skirt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>pineapple</td>\n",
       "      <td>[mango]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>lemon</td>\n",
       "      <td>[orange, yellow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>blouse</td>\n",
       "      <td>[skirt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>blouse</td>\n",
       "      <td>[skirt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>bed</td>\n",
       "      <td>[blanket, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>trout</td>\n",
       "      <td>[carp, salmon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>jar</td>\n",
       "      <td>[can, bottle]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_label_sg  subj_anchors_shared\n",
       "54          moth             [insect]\n",
       "540        rifle             [pistol]\n",
       "661      sparrow              [robin]\n",
       "189       beetle             [insect]\n",
       "488        sheep             [cattle]\n",
       "248          bus               [tram]\n",
       "393          bus               [tram]\n",
       "636        shirt                [tie]\n",
       "793       cherry              [berry]\n",
       "250        lemon     [orange, yellow]\n",
       "860       pistol  [revolver, shotgun]\n",
       "842        tiger         [lion, bear]\n",
       "482        cedar                [oak]\n",
       "825         pear              [peach]\n",
       "812        rifle             [pistol]\n",
       "260        rifle             [pistol]\n",
       "414      toaster               [oven]\n",
       "705  screwdriver              [screw]\n",
       "663         robe              [white]\n",
       "516        shirt                [tie]\n",
       "358         robe              [white]\n",
       "431         bowl            [bowling]\n",
       "216        apple               [pear]\n",
       "20         piano              [organ]\n",
       "240         plum               [pear]\n",
       "763  screwdriver              [screw]\n",
       "748         pear              [peach]\n",
       "531      apricot              [peach]\n",
       "405      missile            [torpedo]\n",
       "772          jar        [can, bottle]\n",
       "219       castle               [moat]\n",
       "384       pistol  [revolver, shotgun]\n",
       "172      library            [archive]\n",
       "391    butterfly       [moth, insect]\n",
       "344       castle               [moat]\n",
       "435         bear         [lion, wolf]\n",
       "720       rabbit             [rodent]\n",
       "601     revolver             [pistol]\n",
       "203          bed    [blanket, pillow]\n",
       "563          jet           [aircraft]\n",
       "730       blouse              [skirt]\n",
       "186       violin              [viola]\n",
       "652       blouse              [skirt]\n",
       "161    pineapple              [mango]\n",
       "114        lemon     [orange, yellow]\n",
       "818       blouse              [skirt]\n",
       "434       blouse              [skirt]\n",
       "66           bed    [blanket, pillow]\n",
       "496        trout       [carp, salmon]\n",
       "714          jar        [can, bottle]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8549b56a-817b-4bb1-b16d-2b5e368545c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['lambskin', 'lapin', 'astrakhan', 'bearskin', 'beaver', 'chinchilla', 'ermine', 'fox', 'leopard', 'mink', 'muskrat', 'otter', 'raccoon', 'sable', 'sealskin', 'seal', 'squirrel', 'sheepskin', 'broadtail', 'cowhide', 'cony', 'coney', 'hare', 'parchment', 'fell', 'hide', 'leather', 'fur', 'pelt', 'bunny', 'cottontail', 'leporide', 'angora', 'leveret', 'jackrabbit', 'vellum', 'goatskin', 'rawhide', 'grain', 'alligator', 'buckskin', 'buff', 'calf', 'calfskin', 'chamois', 'chammy', 'shammy', 'cordovan', 'cowskin', 'crush', 'deerskin', 'doeskin', 'horsehide', 'kid', 'kidskin', 'mocha', 'morocco', 'pigskin', 'fleece', 'suede', 'roan', 'canecutter', 'counter', 'quarter', 'saddle', 'upper', 'vamp', 'levant', 'duplicidentata', 'leporid', 'pika']\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "def read_cohyponyms(path = '../log/word_to_cohyponyms.txt'):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        word_to_cohyponym = dict(zip(df['word'], df['cohyponyms']))\n",
    "        return word_to_cohyponym\n",
    "    print(f\"{path} not found\")\n",
    "\n",
    "word_to_cohyponym = read_cohyponyms(path = '../log/word_to_cohyponyms.txt')\n",
    "word_to_cohyponym['rabbit']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92a8773a-98fd-4b86-90bb-2b024d0d7110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>relation</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_type</th>\n",
       "      <th>obj_label_single</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aeroplane</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>[An aeroplane is a [MASK].]</td>\n",
       "      <td>IsA</td>\n",
       "      <td>2</td>\n",
       "      <td>taxonomic</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>[drone, airplane, whirlybird, ornithopter, war...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alligator</td>\n",
       "      <td>reptile</td>\n",
       "      <td>[An alligator is a [MASK].]</td>\n",
       "      <td>IsA</td>\n",
       "      <td>16</td>\n",
       "      <td>taxonomic</td>\n",
       "      <td>reptile</td>\n",
       "      <td>[deerskin, calfskin, buff, fleece, crocodile, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alligator</td>\n",
       "      <td>animal</td>\n",
       "      <td>[An alligator is an [MASK].]</td>\n",
       "      <td>IsA</td>\n",
       "      <td>11</td>\n",
       "      <td>taxonomic</td>\n",
       "      <td>animal</td>\n",
       "      <td>[deerskin, calfskin, buff, fleece, crocodile, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alligator</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>[An alligator is a [MASK].]</td>\n",
       "      <td>IsA</td>\n",
       "      <td>8</td>\n",
       "      <td>functional</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>[deerskin, calfskin, buff, fleece, crocodile, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alligator</td>\n",
       "      <td>predator</td>\n",
       "      <td>[An alligator is a [MASK].]</td>\n",
       "      <td>IsA</td>\n",
       "      <td>6</td>\n",
       "      <td>taxonomic</td>\n",
       "      <td>predator</td>\n",
       "      <td>[deerskin, calfskin, buff, fleece, crocodile, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sub_label  obj_label              masked_sentences relation  weight  \\\n",
       "0  aeroplane    vehicle   [An aeroplane is a [MASK].]      IsA       2   \n",
       "1  alligator    reptile   [An alligator is a [MASK].]      IsA      16   \n",
       "2  alligator     animal  [An alligator is an [MASK].]      IsA      11   \n",
       "3  alligator  carnivore   [An alligator is a [MASK].]      IsA       8   \n",
       "4  alligator   predator   [An alligator is a [MASK].]      IsA       6   \n",
       "\n",
       "  feature_type obj_label_single  \\\n",
       "0    taxonomic          vehicle   \n",
       "1    taxonomic          reptile   \n",
       "2    taxonomic           animal   \n",
       "3   functional        carnivore   \n",
       "4    taxonomic         predator   \n",
       "\n",
       "                                          sub_sister  uuid  \n",
       "0  [drone, airplane, whirlybird, ornithopter, war...     0  \n",
       "1  [deerskin, calfskin, buff, fleece, crocodile, ...     1  \n",
       "2  [deerskin, calfskin, buff, fleece, crocodile, ...     2  \n",
       "3  [deerskin, calfskin, buff, fleece, crocodile, ...     3  \n",
       "4  [deerskin, calfskin, buff, fleece, crocodile, ...     4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>relation</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>goose</td>\n",
       "      <td>waterbird</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A goose is a [MASK]., A goose is an [MASK].]</td>\n",
       "      <td>[dove, fathead, meshuggener, duck, goofball, m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robin</td>\n",
       "      <td>passerine</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A robin is a [MASK]., A robin is an [MASK].]</td>\n",
       "      <td>[snowbird, veery, redtail, redstart, redbreast...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catfish</td>\n",
       "      <td>fish</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A catfish is a [MASK]., A catfish is an [MASK].]</td>\n",
       "      <td>[sandfish, wolffish, eel, greeneye, ghostfish,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>musket</td>\n",
       "      <td>firearm</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A musket is a [MASK]., A musket is an [MASK].]</td>\n",
       "      <td>[flintlock, hackbut, harquebus, firelock, arqu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lemon</td>\n",
       "      <td>produce</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A lemon is a [MASK]., A lemon is an [MASK].]</td>\n",
       "      <td>[lemanderin, grapefruit, good, insert, button,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label  obj_label relation  \\\n",
       "0     goose  waterbird      IsA   \n",
       "1     robin  passerine      IsA   \n",
       "2   catfish       fish      IsA   \n",
       "3    musket    firearm      IsA   \n",
       "4     lemon    produce      IsA   \n",
       "\n",
       "                                    masked_sentences  \\\n",
       "0      [A goose is a [MASK]., A goose is an [MASK].]   \n",
       "1      [A robin is a [MASK]., A robin is an [MASK].]   \n",
       "2  [A catfish is a [MASK]., A catfish is an [MASK].]   \n",
       "3    [A musket is a [MASK]., A musket is an [MASK].]   \n",
       "4      [A lemon is a [MASK]., A lemon is an [MASK].]   \n",
       "\n",
       "                                          sub_sister  uuid  \n",
       "0  [dove, fathead, meshuggener, duck, goofball, m...     0  \n",
       "1  [snowbird, veery, redtail, redstart, redbreast...     1  \n",
       "2  [sandfish, wolffish, eel, greeneye, ghostfish,...     2  \n",
       "3  [flintlock, hackbut, harquebus, firelock, arqu...     3  \n",
       "4  [lemanderin, grapefruit, good, insert, button,...     4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>relation</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accident</td>\n",
       "      <td>error</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An accident is a [MASK]., An accident is an [...</td>\n",
       "      <td>[gravy, convergence, reverse, flash, interrupt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accident</td>\n",
       "      <td>mistake</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An accident is a [MASK]., An accident is an [...</td>\n",
       "      <td>[gravy, convergence, reverse, flash, interrupt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>action</td>\n",
       "      <td>event</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An action is a [MASK]., An action is an [MASK].]</td>\n",
       "      <td>[job, ironing, omnipotence, degeneration, inte...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>action</td>\n",
       "      <td>work</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An action is a [MASK]., An action is an [MASK].]</td>\n",
       "      <td>[job, ironing, omnipotence, degeneration, inte...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actor</td>\n",
       "      <td>person</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An actor is a [MASK]., An actor is an [MASK].]</td>\n",
       "      <td>[quester, white, signer, knocker, granter, nam...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label obj_label relation  \\\n",
       "0  accident     error      IsA   \n",
       "1  accident   mistake      IsA   \n",
       "2    action     event      IsA   \n",
       "3    action      work      IsA   \n",
       "4     actor    person      IsA   \n",
       "\n",
       "                                    masked_sentences  \\\n",
       "0  [An accident is a [MASK]., An accident is an [...   \n",
       "1  [An accident is a [MASK]., An accident is an [...   \n",
       "2  [An action is a [MASK]., An action is an [MASK].]   \n",
       "3  [An action is a [MASK]., An action is an [MASK].]   \n",
       "4    [An actor is a [MASK]., An actor is an [MASK].]   \n",
       "\n",
       "                                          sub_sister  uuid  \n",
       "0  [gravy, convergence, reverse, flash, interrupt...     0  \n",
       "1  [gravy, convergence, reverse, flash, interrupt...     1  \n",
       "2  [job, ironing, omnipotence, degeneration, inte...     2  \n",
       "3  [job, ironing, omnipotence, degeneration, inte...     3  \n",
       "4  [quester, white, signer, knocker, granter, nam...     4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>relation</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>etching</td>\n",
       "      <td>art</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An etching is a [MASK]., An etching is an [MA...</td>\n",
       "      <td>[halftone, serigraphy, woodcut, lithography, p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>panda</td>\n",
       "      <td>vertebrate</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A panda is a [MASK]., A panda is an [MASK].]</td>\n",
       "      <td>[potto, coati, raccoon, kinkajou, racoon, bass...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decrease</td>\n",
       "      <td>change</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A decrease is a [MASK]., A decrease is an [MA...</td>\n",
       "      <td>[birth, nascency, defining, dealignment, degen...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dinghy</td>\n",
       "      <td>boat</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A dinghy is a [MASK]., A dinghy is an [MASK].]</td>\n",
       "      <td>[canoe, cockleshell, gig, rowboat, dory, yawl,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>islander</td>\n",
       "      <td>inhabitant</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An islander is a [MASK]., An islander is an [...</td>\n",
       "      <td>[resident, earthling, philistine, plainsman, e...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label   obj_label relation  \\\n",
       "0   etching         art      IsA   \n",
       "1     panda  vertebrate      IsA   \n",
       "2  decrease      change      IsA   \n",
       "3    dinghy        boat      IsA   \n",
       "4  islander  inhabitant      IsA   \n",
       "\n",
       "                                    masked_sentences  \\\n",
       "0  [An etching is a [MASK]., An etching is an [MA...   \n",
       "1      [A panda is a [MASK]., A panda is an [MASK].]   \n",
       "2  [A decrease is a [MASK]., A decrease is an [MA...   \n",
       "3    [A dinghy is a [MASK]., A dinghy is an [MASK].]   \n",
       "4  [An islander is a [MASK]., An islander is an [...   \n",
       "\n",
       "                                          sub_sister  uuid  \n",
       "0  [halftone, serigraphy, woodcut, lithography, p...     0  \n",
       "1  [potto, coati, raccoon, kinkajou, racoon, bass...     1  \n",
       "2  [birth, nascency, defining, dealignment, degen...     2  \n",
       "3  [canoe, cockleshell, gig, rowboat, dory, yawl,...     3  \n",
       "4  [resident, earthling, philistine, plainsman, e...     4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>relation</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>golo</td>\n",
       "      <td>river</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A golo is a [MASK]., A golo is an [MASK].]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kerrobert</td>\n",
       "      <td>town</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A kerrobert is a [MASK]., A kerrobert is an [...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geometria</td>\n",
       "      <td>film</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A geometria is a [MASK]., A geometria is an [...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>evaporation</td>\n",
       "      <td>place</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[An evaporation is a [MASK]., An evaporation i...</td>\n",
       "      <td>[melting, vapour, thawing, thaw, vaporisation,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bonehead</td>\n",
       "      <td>band</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[A bonehead is a [MASK]., A bonehead is an [MA...</td>\n",
       "      <td>[knucklehead, hammerhead, loggerhead, dumbass,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub_label obj_label relation  \\\n",
       "0         golo     river      IsA   \n",
       "1    kerrobert      town      IsA   \n",
       "2    geometria      film      IsA   \n",
       "3  evaporation     place      IsA   \n",
       "4     bonehead      band      IsA   \n",
       "\n",
       "                                    masked_sentences  \\\n",
       "0        [A golo is a [MASK]., A golo is an [MASK].]   \n",
       "1  [A kerrobert is a [MASK]., A kerrobert is an [...   \n",
       "2  [A geometria is a [MASK]., A geometria is an [...   \n",
       "3  [An evaporation is a [MASK]., An evaporation i...   \n",
       "4  [A bonehead is a [MASK]., A bonehead is an [MA...   \n",
       "\n",
       "                                          sub_sister  uuid  \n",
       "0                                                 []     0  \n",
       "1                                                 []     1  \n",
       "2                                                 []     2  \n",
       "3  [melting, vapour, thawing, thaw, vaporisation,...     3  \n",
       "4  [knucklehead, hammerhead, loggerhead, dumbass,...     4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_label_pl</th>\n",
       "      <th>relation</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[A graver is a [MASK].]</td>\n",
       "      <td>tool</td>\n",
       "      <td>graver</td>\n",
       "      <td>gravers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[bevel, dibber, spreader, hammer, crank, float...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[A smallmouth is a [MASK].]</td>\n",
       "      <td>fish</td>\n",
       "      <td>smallmouth</td>\n",
       "      <td>smallmouths</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[largemouth]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[A pelican is a [MASK].]</td>\n",
       "      <td>bird</td>\n",
       "      <td>pelican</td>\n",
       "      <td>pelicans</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[cormorant, snakebird, tropicbird, darter, anh...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A sapsucker is a [MASK].]</td>\n",
       "      <td>bird</td>\n",
       "      <td>sapsucker</td>\n",
       "      <td>sapsuckers</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[wryneck, redhead, piculet, ivorybill, flicker]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[A mako is a [MASK].]</td>\n",
       "      <td>fish</td>\n",
       "      <td>mako</td>\n",
       "      <td>makos</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[porbeagle]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              masked_sentences obj_label   sub_label sub_label_pl relation  \\\n",
       "0      [A graver is a [MASK].]      tool      graver      gravers      IsA   \n",
       "1  [A smallmouth is a [MASK].]      fish  smallmouth  smallmouths      IsA   \n",
       "2     [A pelican is a [MASK].]      bird     pelican     pelicans      IsA   \n",
       "3   [A sapsucker is a [MASK].]      bird   sapsucker   sapsuckers      IsA   \n",
       "4        [A mako is a [MASK].]      fish        mako        makos      IsA   \n",
       "\n",
       "                                          sub_sister  uuid  \n",
       "0  [bevel, dibber, spreader, hammer, crank, float...     1  \n",
       "1                                       [largemouth]     2  \n",
       "2  [cormorant, snakebird, tropicbird, darter, anh...     3  \n",
       "3    [wryneck, redhead, piculet, ivorybill, flicker]     4  \n",
       "4                                        [porbeagle]     5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36eb204c-6299-41ef-9cd8-4c3be1192f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17337\n",
      "11251\n",
      "5246\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_all['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5a31caf-54f0-4e08-909e-928ade09082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from scipy import stats \n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "796b426e-6e52-48df-86ae-81eda9cbd86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLESS significantly different True -3.7806617339994197 0.00016699050740069635\n",
      "\n",
      "\n",
      "BLESS significantly different False -1.784478718222449 0.07469112072607259\n",
      "\n",
      "\n",
      "CLSB significantly different True -3.0986967754062382 0.002001587317957245\n",
      "\n",
      "\n",
      "CLSB significantly different True -5.22689378264068 2.1246887427239493e-07\n",
      "\n",
      "\n",
      "EVAL significantly different False 0.2725929514850968 0.7852260629887482\n",
      "\n",
      "\n",
      "EVAL significantly different False 1.218858308361267 0.2232040877422561\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from significance_test import significance_test_single_dataset\n",
    "min_pvalue = 0.05 \n",
    "\n",
    "dataset_to_paths = {\n",
    "    'BLESS': [\n",
    "         \"../../log/bert-large-uncased/BLESS/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_None.HYPERNYMSUITE.csv\",\n",
    "         \"../../log/bert-large-uncased/BLESS/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWSimilar.HYPERNYMSUITE.csv\",\n",
    "         \"../../log/bert-large-uncased/BLESS/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWStrength.HYPERNYMSUITE.csv\",\n",
    "        \"../../log/bert-large-uncased/BLESS/swow_rw/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_SWOW_swow_score_source_None.HYPERNYMSUITE.csv\",\n",
    "\n",
    "        ],\n",
    "     'CLSB': [\"../../log/bert-large-uncased/clsb/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_None.CLSB.csv\",\n",
    "            \"../../log/bert-large-uncased/clsb/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWSimilar.CLSB.csv\",\n",
    "             \"../../log/bert-large-uncased/clsb/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWStrength.CLSB.csv\",\n",
    "            \"../../log/bert-large-uncased/clsb/swow_rw/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_SWOW_swow_score_source_None.CLSB.csv\",\n",
    "            ],\n",
    "    'EVAL': [\n",
    "         \"../../log/bert-large-uncased/EVAL/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_None.HYPERNYMSUITE.csv\",\n",
    "         \"../../log/bert-large-uncased/EVAL/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWSimilar.HYPERNYMSUITE.csv\",\n",
    "        \"../../log/bert-large-uncased/EVAL/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWStrength.HYPERNYMSUITE.csv\",\n",
    "        \"../../log/bert-large-uncased/EVAL/swow_rw/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_SWOW_swow_score_source_None.HYPERNYMSUITE.csv\",\n",
    "        ]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "metrics =[ \n",
    "#            ['mrr_def_sap', 'mrr_def_dap'], \n",
    "           ['p10_def_sap', 'p10_def_dap'],\n",
    "#            ['mrr_lsp_sap', 'mrr_lsp_dap'],\n",
    "           ['p10_lsp_sap', 'p10_lsp_dap'],\n",
    "         ]\n",
    "# res = significance_test_single_dataset(df, dataset, metrics, min_pvalue =0.05, display_res=False):\n",
    "# print(res)\n",
    "for dataset, paths in dataset_to_paths.items():\n",
    "    df1 = pd.read_csv(paths[0])\n",
    "    df2 = pd.read_csv(paths[1])\n",
    "    df3 = pd.read_csv(paths[2])\n",
    "    df4 = pd.read_csv(paths[3])\n",
    "\n",
    "    for metric in metrics:\n",
    "    #     print(metric)\n",
    "#         statistic, pvalue = stats.ttest_rel(df1[metric[0]], df1[metric[1]])\n",
    "#         reject_np = True if pvalue < min_pvalue else False \n",
    "#         print(dataset, \"significantly different\", reject_np, statistic, pvalue)\n",
    "\n",
    "#         statistic, pvalue = stats.ttest_rel(df2[metric[0]], df2[metric[1]])\n",
    "#         reject_np = True if pvalue < min_pvalue else False \n",
    "#         print(dataset, \"significantly different\", reject_np, statistic, pvalue)\n",
    "\n",
    "#         statistic, pvalue = stats.ttest_rel(df3[metric[0]], df3[metric[1]])\n",
    "#         reject_np = True if pvalue < min_pvalue else False \n",
    "#         print(dataset, \"significantly different\", reject_np, statistic, pvalue)\n",
    "        \n",
    "        statistic, pvalue = stats.ttest_rel(df4[metric[0]], df4[metric[1]])\n",
    "        reject_np = True if pvalue < min_pvalue else False \n",
    "        print(dataset, \"significantly different\", reject_np, statistic, pvalue)\n",
    "\n",
    "#         statistic, pvalue = stats.ttest_rel(df1[metric[1]], df2[metric[1]])\n",
    "#         reject_np = True if pvalue < min_pvalue else False \n",
    "#         print(dataset, \"significantly different\", reject_np, statistic, pvalue)\n",
    "        \n",
    "#         statistic, pvalue = stats.ttest_rel(df1[metric[1]], df3[metric[1]])\n",
    "#         reject_np = True if pvalue < min_pvalue else False \n",
    "#         print(dataset, \"significantly different\", reject_np, statistic, pvalue)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d088d9c-d773-478e-bca4-a59fc0549059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.to_latex of     sub_label_sg                               subj_anchors\n",
       "201         corn         [bean, potato, barley, wheat, pea]\n",
       "216        apple       [pear, fruit, banana, grape, tomato]\n",
       "227          car  [truck, vehicle, train, motorcycle, tire]\n",
       "294         corn         [bean, potato, barley, wheat, pea]\n",
       "370        apple       [pear, fruit, banana, grape, tomato]\n",
       "448          car  [truck, vehicle, train, motorcycle, tire]\n",
       "460          car  [truck, vehicle, train, motorcycle, tire]\n",
       "521         corn         [bean, potato, barley, wheat, pea]\n",
       "608         corn         [bean, potato, barley, wheat, pea]\n",
       "683        train          [car, vehicle, truck, bus, plane]\n",
       "685        train          [car, vehicle, truck, bus, plane]\n",
       "780        train          [car, vehicle, truck, bus, plane]\n",
       "795         corn         [bean, potato, barley, wheat, pea]\n",
       "802        apple       [pear, fruit, banana, grape, tomato]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.to_latex of     sub_label_sg                               subj_anchors\n",
       "8          apple       [pear, fruit, banana, grape, tomato]\n",
       "9          apple       [pear, fruit, banana, grape, tomato]\n",
       "139          car  [truck, vehicle, train, motorcycle, tire]\n",
       "216         corn         [bean, potato, barley, wheat, pea]\n",
       "217         corn         [bean, potato, barley, wheat, pea]\n",
       "218         corn         [bean, potato, barley, wheat, pea]\n",
       "219         corn         [bean, potato, barley, wheat, pea]\n",
       "220         corn         [bean, potato, barley, wheat, pea]\n",
       "254        daisy        [rose, lily, violet, cherry, peach]\n",
       "255        daisy        [rose, lily, violet, cherry, peach]\n",
       "256        daisy        [rose, lily, violet, cherry, peach]\n",
       "876        train          [car, vehicle, truck, bus, plane]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.to_latex of     sub_label_sg                               subj_anchors\n",
       "22         apple       [pear, fruit, banana, grape, tomato]\n",
       "23         apple       [pear, fruit, banana, grape, tomato]\n",
       "141          car  [truck, vehicle, train, motorcycle, tire]\n",
       "142          car  [truck, vehicle, train, motorcycle, tire]\n",
       "143          car  [truck, vehicle, train, motorcycle, tire]\n",
       "219         corn         [bean, potato, barley, wheat, pea]\n",
       "864        train          [car, vehicle, truck, bus, plane]\n",
       "865        train          [car, vehicle, truck, bus, plane]>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from inflection import singularize, pluralize \n",
    "\n",
    "query = ['car', 'apple', 'train', 'corn', 'daisy']\n",
    "# query = ['daisy', 'motel', 'murre', 'trireme']\n",
    "\n",
    "for dataset, paths in dataset_to_paths.items():\n",
    "    df1 = pd.read_csv(paths[0])\n",
    "    df2 = pd.read_csv(paths[1])\n",
    "    df3 = pd.read_csv(paths[2])\n",
    "    df4 = pd.read_csv(paths[3])\n",
    "    \n",
    "    df2['subj_anchors'] = df2['subj_anchors'].apply(lambda x: [singularize(item) for item in eval(x)[:5] ])\n",
    "    df2['subj_anchors_swow'] = df2['subj_anchors_swow'].apply(lambda x: eval(x)[:5])\n",
    "    display(df2.query(f\"sub_label_sg in {query}\")[['sub_label_sg', 'subj_anchors']].to_latex) #.sample(10))\n",
    "    \n",
    "#     df4['subj_anchors'] = df4['subj_anchors'].apply(lambda x: [singularize(item) for item in eval(x)[:5] ])\n",
    "#     df4['subj_anchors_swow'] = df4['subj_anchors_swow'].apply(lambda x: eval(x)[:5])\n",
    "#     display(df4.query(f\"sub_label_sg in {query}\")[['sub_label_sg', 'subj_anchors', 'subj_anchors_swow']].to_latex) #.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "170f9794-1cfc-45e2-887c-9a280de35e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.to_latex of Empty DataFrame\n",
       "Columns: [sub_label_sg, subj_anchors, subj_anchors_swow]\n",
       "Index: []>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = ['daisy', 'motel', 'murre', 'trireme']\n",
    "display(df4.query(f\"sub_label_sg in {query}\")[['sub_label_sg', 'subj_anchors', 'subj_anchors_swow']].to_latex) #.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11765f47-c9a5-4acb-8eb5-f290fbe90a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sub_label', 'obj_label', 'relation', 'masked_sentences',\n",
       "       'sub_sister', 'uuid', 'sub_position', 'sub_label_sg', 'sub_label_pl',\n",
       "       'def_sap', 'def_dap', 'lsp_sap', 'lsp_dap', 'anchor_lsp_sap',\n",
       "       'sub_label_sgpl', 'subj_anchors_swow', 'subj_anchors', 'obj_in_BERT',\n",
       "       'obj_mask_sentence', 'obj_mask_sentence_score', 'obj_mask_def_sap',\n",
       "       'obj_mask_def_sap_score', 'obj_mask_lsp_sap', 'obj_mask_lsp_sap_score',\n",
       "       'subj_anchors_score', 'subj_anchors_sg', 'subj_anchors_pl',\n",
       "       'subj_anchors_all', 'subj_anchors_combined',\n",
       "       'masked_sentences_with_subj_anchor', 'def_dap_with_subj_anchor',\n",
       "       'lsp_dap_with_subj_anchor', 'obj_mask_def_dap',\n",
       "       'obj_mask_def_dap_score', 'obj_mask_lsp_dap', 'obj_mask_lsp_dap_score',\n",
       "       'p1_subj_anchors_sg', 'p5_subj_anchors_sg', 'p10_subj_anchors_sg',\n",
       "       'p1_subj_anchors_all', 'p5_subj_anchors_all', 'p10_subj_anchors_all',\n",
       "       'mrr_subj_anchors_sg', 'mrr_subj_anchors_all',\n",
       "       'anchor_wordnet_path_len', 'obj_label_sg', 'p1_sentence', 'p5_sentence',\n",
       "       'p10_sentence', 'p1_def_sap', 'p5_def_sap', 'p10_def_sap', 'p1_lsp_sap',\n",
       "       'p5_lsp_sap', 'p10_lsp_sap', 'p1_def_dap', 'p5_def_dap', 'p10_def_dap',\n",
       "       'p1_lsp_dap', 'p5_lsp_dap', 'p10_lsp_dap', 'mrr_sentence',\n",
       "       'mrr_def_sap', 'mrr_lsp_sap', 'mrr_def_dap', 'mrr_lsp_dap'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../../log/bert-large-uncased/clsb/swow_rw/exp_data_results_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_None.CLSB.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df[].columns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da7fe2-ef12-4d48-bf3d-0ebaff74aff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1655bf3f-db91-430a-8df3-ab1447e89b60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4bfdf26fa034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sim_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_rw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../../data/swow/S_RW.R123.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msim_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word1' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from inflection import singularize, pluralize \n",
    "\n",
    "def get_sim_matrix(path_rw='../../data/swow/S_RW.R123.csv'):\n",
    "    df = pd.read_csv(path_rw)\n",
    "    sim_matrix = df.to_numpy()\n",
    "    vocab = df.columns[1:]\n",
    "    vocab_pl = [pluralize(word) for word in vocab]\n",
    "    word2id = {word:i for i, word in enumerate(vocab)}\n",
    "    return word2id, sim_matrix\n",
    "\n",
    "word2id, sim_matrix = get_sim_matrix(path_rw='../../data/swow/S_RW.R123.csv')\n",
    "sim_score = query_sim(word1, word2, word2id, sim_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dad4aca-93fa-4deb-b52e-0cfc67fe7786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0368332743848336\n"
     ]
    }
   ],
   "source": [
    "def query_sim(word1, word2, swow_score_tuple ):\n",
    "    '''\n",
    "    query the similary between two words in a similarity matrix \n",
    "    '''\n",
    "    word2id, sim_matrix  = swow_score_tuple\n",
    "    \n",
    "    sim_score =0 \n",
    "    if word1 in word2id and word2 in word2id:\n",
    "        id1 = word2id.get(word1)\n",
    "        id2 = word2id.get(word2)\n",
    "\n",
    "        sim_score = sim_matrix[id1][id2+1] #the first col is the word \n",
    "    return sim_score \n",
    "\n",
    "\n",
    "# word1 = 'dogs'\n",
    "# word2 = 'wolf'\n",
    "word1 = 'abacus'\n",
    "word2= 'a'\n",
    "\n",
    "sim_score = query_sim(word1, word2, word2id, sim_matrix)\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12fdf2b6-5202-4bdb-9ffc-75c673edf86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_RW.R123.csv\t\t       swow.en.similar_words.sg.json\n",
      "strength.SWOW-EN.R123.csv      swow.en.similar_words.sgpl.json\n",
      "swow.en.fbs.json\t       swow.en.strength.R123.json\n",
      "swow.en.similar_words.json     swow.en.strength.R123.pl.json\n",
      "swow.en.similar_words.pl.json  vocab_to_plural.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data/swow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2b7371e-aa2a-4ffa-8de4-8011494f62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_matrix[word2id.get('dog')]\n",
    "\n",
    "path = \"../../data/swow/swow.en.fbs.json\"\n",
    "\n",
    "word_to_fbs = json.load(open(path, 'r'))\n",
    "\n",
    "path = \"../../data/swow/swow.en.similar_words.sg.json\"\n",
    "word_to_similar = json.load(open(path, 'r'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe1ae198-7bf3-44db-a568-9bca3569902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "dict_keys(['meow', 'purrs', 'kitties', 'pussies', 'whiskers', 'puss', 'kitten', 'pet', 'leopard', 'mouse', 'paws', 'animals', 'tails', 'tigers', 'lion', 'litter', 'scratches', 'mats', 'mice', 'soft', 'naps', 'black', 'nip', 'scan', 'adorable', 'carnivore', 'sneaky', 'catwalks', 'allergies', 'liter', 'wild', 'boxes', 'rabbits', 'lovable', 'independent', 'lazy', 'trees', 'birds', 'predator'])\n",
      "dict_keys(['kittens', 'cat', 'kitten', 'kitty', 'paw', 'feline', 'meow', 'dog', 'pet'])\n",
      "\n",
      "\n",
      "train\n",
      "dict_keys(['locomotive', 'caboose', 'stations', 'railroads', 'rails', 'tracks', 'transportations', 'passengers', 'timetables', 'steams', 'transport', 'wagons', 'tickets', 'whistle', 'travels', 'buses', 'wrecks', 'cars', 'teach', 'vehicles', 'ride', 'practice', 'trips', 'toys', 'luggages', 'robbers', 'riding', 'planes', 'bridals', 'speeds', 'automobiles', 'vain', 'signals', 'sleep', 'wheels'])\n",
      "dict_keys(['railway', 'railroad', 'train', 'locomotive', 'transportation', 'car', 'tram', 'truck', 'transport', 'freight'])\n",
      "\n",
      "\n",
      "joy\n",
      "dict_keys(['bliss', 'pleasures', 'love', 'smile', 'christmas', 'laughters', 'almonds', 'lives', 'peaces', 'smiles', 'tears', 'laugh', 'kill', 'merry', 'joyful', 'laughing', 'luck', 'play', 'carefree', 'jump', 'sadnesses', 'wonder', 'kids', 'alive', 'children', 'loving', 'pains', 'bells', 'birthdays', 'mountains', 'song', 'summers', 'weddings'])\n",
      "dict_keys(['joyful', 'happy', 'merry', 'happiness', 'glee', 'joyous', 'delight', 'smiles', 'elated', 'glad'])\n",
      "\n",
      "\n",
      "bowl\n",
      "dict_keys(['cereals', 'soups', 'spoon', 'toilets', 'plates', 'ceramic', 'super', 'salads', 'potteries', 'bowling', 'mix', 'rices', 'bowel', 'cherries', 'oatmeal', 'pots', 'saucers', 'mixers', 'ramen', 'chopsticks', 'pudding', 'china', 'noodles', 'pins', 'breakfasts', 'strike'])\n",
      "dict_keys(['bowl', 'crockery', 'plate', 'dish', 'chopstick', 'cup', 'spoon', 'ceramic'])\n",
      "\n",
      "\n",
      "stove\n",
      "dict_keys(['oven', 'burners', 'range', 'appliances', 'kitchens', 'tops', 'pan', 'pipes', 'pots', 'burn', 'kettles', 'irons', 'bake', 'bricks'])\n",
      "dict_keys(['cooker', 'oven', 'burner', 'cook', 'skillet', 'saucepan', 'kitchen', 'cooking', 'broil', 'kettle'])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = ['dog', 'cat', 'corn', 'train', 'joy', 'bowl', 'stove']\n",
    "# word = 'rabbit'\n",
    "for word in query:\n",
    "    if word in word_to_fbs and word in word_to_similar:\n",
    "        print(word)\n",
    "        print( word_to_fbs[word].keys())\n",
    "        print( word_to_similar[word].keys())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb979363-c74d-4fc2-8f39-c6f4ecde05e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3117b8f-0117-4b6c-b794-53212682040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function: \n",
    "\n",
    "1. word1 (cue/hyponym), word2(response/related_words/co-hyponym)\n",
    "2. identify the similarity score or association strength \n",
    "\n",
    "issue: the raw S_RW.R123 are not normalized, some words are singular, some words are plural \n",
    "\n",
    "the solution: \n",
    "    * given all the word1 will be pluralized and the anchors will be singularied or pluralized after aggregation \n",
    "    * we can normalize all cues into plural? so the similar words will also be plural? which fits into the original anchors\n",
    "    * what would happen if both singular and plural are in the original SWOW? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "572b06ae-ef61-42c6-89f9-c6bd4c9b4341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3ac53b-2cb8-4b55-892d-b11a63c04738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from collections import defaultdict, Counter \n",
    "# def \n",
    "input_path = '../../data/swow/swow.en.strength.R123.json'\n",
    "swow_score_dict = json.load( open ())\n",
    "\n",
    "vocab_cues = set(swow_score_dict.keys())\n",
    "vocab_res = set()\n",
    "for k,v in swow_score_dict.items():\n",
    "    vocab_res.update(v.keys() )\n",
    "    \n",
    "vocab = vocab_cues.union(vocab_res)\n",
    "vocab = set({str(k) for k in vocab})\n",
    "vocab_to_plural = {k: pluralize(k) for k in vocab }\n",
    "\n",
    "swow_score_dict_pl = defaultdict()\n",
    "for k,v in swow_score_dict.items():\n",
    "    v_pl = {vocab_to_plural.get(k1):v1 for k1, v1 in v.items() }\n",
    "    swow_score_dict_pl[vocab_to_plural.get(k)] = v_pl\n",
    "output_path = input_path.replace('.json', '.pl.json')\n",
    "json.dump(swow_score_dict_pl, open(output_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9f8e8a3-25b5-4661-a9b8-c5c8b5438997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swow_score_dict_pl.dump()\n",
    "input_path = '../../data/swow/swow.en.strength.R123.json' \n",
    "print(f'save {output_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd12ad68-deae-412c-9153-45c3c3898481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save ../../data/swow/swow.en.strength.R123.pl.json\n"
     ]
    }
   ],
   "source": [
    "# swow_score_dict_pl['rabbits']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bbc89-65f4-4123-8911-6f6b34c71dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114bf177-afca-455c-855f-e1b400f2aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function: \n",
    "    input: word1:cue, word2:co-hyponyms/response? \n",
    "    output: the association strength score \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c594d9a-add0-4e7c-91c0-90e2a21eb00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0368332743848336\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aaf9c445-91bc-4315-8b15-c5de4f3f4505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>a</th>\n",
       "      <th>a few</th>\n",
       "      <th>a little</th>\n",
       "      <th>a lot</th>\n",
       "      <th>aardvark</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abdicate</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abduction</th>\n",
       "      <th>Abel</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abode</th>\n",
       "      <th>Aboriginal</th>\n",
       "      <th>aborigine</th>\n",
       "      <th>abortion</th>\n",
       "      <th>about</th>\n",
       "      <th>...</th>\n",
       "      <th>yuk</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yuppie</th>\n",
       "      <th>zap</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealot</th>\n",
       "      <th>zebra</th>\n",
       "      <th>Zen</th>\n",
       "      <th>zenith</th>\n",
       "      <th>Zeppelin</th>\n",
       "      <th>zero</th>\n",
       "      <th>zest</th>\n",
       "      <th>zesty</th>\n",
       "      <th>Zeus</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zit</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071836</td>\n",
       "      <td>0.087998</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>0.148540</td>\n",
       "      <td>0.036833</td>\n",
       "      <td>0.020847</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.065202</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>0.017431</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.021331</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>0.040737</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.021668</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>0.029184</td>\n",
       "      <td>0.146775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.028118</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>0.022656</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.015949</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.041973</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.118230</td>\n",
       "      <td>0.017602</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.022376</td>\n",
       "      <td>0.014898</td>\n",
       "      <td>0.009429</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003725</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.024179</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>0.032391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a few</td>\n",
       "      <td>0.071836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411114</td>\n",
       "      <td>0.419096</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.085048</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.030484</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.016623</td>\n",
       "      <td>0.027511</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.047517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.018736</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.019599</td>\n",
       "      <td>0.038351</td>\n",
       "      <td>0.021007</td>\n",
       "      <td>0.025708</td>\n",
       "      <td>0.042905</td>\n",
       "      <td>0.020627</td>\n",
       "      <td>0.110562</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>0.005999</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>0.025522</td>\n",
       "      <td>0.020187</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>0.018682</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>0.026820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a little</td>\n",
       "      <td>0.087998</td>\n",
       "      <td>0.411114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459404</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>0.051574</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>0.015226</td>\n",
       "      <td>0.015796</td>\n",
       "      <td>0.025255</td>\n",
       "      <td>0.027053</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.015108</td>\n",
       "      <td>0.011474</td>\n",
       "      <td>0.034190</td>\n",
       "      <td>0.033204</td>\n",
       "      <td>0.015928</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.021640</td>\n",
       "      <td>0.084149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.025737</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.019772</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>0.016344</td>\n",
       "      <td>0.015466</td>\n",
       "      <td>0.023857</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.077176</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.012551</td>\n",
       "      <td>0.014415</td>\n",
       "      <td>0.012107</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.014685</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>0.023710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a lot</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>0.419096</td>\n",
       "      <td>0.459404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>0.055456</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.007374</td>\n",
       "      <td>0.012018</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.008195</td>\n",
       "      <td>0.022562</td>\n",
       "      <td>0.047236</td>\n",
       "      <td>0.020122</td>\n",
       "      <td>0.016165</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>0.007628</td>\n",
       "      <td>0.054251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>0.021112</td>\n",
       "      <td>0.025927</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.018597</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.036104</td>\n",
       "      <td>0.017992</td>\n",
       "      <td>0.058006</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.014198</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.010044</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.020812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>0.148540</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.026005</td>\n",
       "      <td>0.009544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.014878</td>\n",
       "      <td>0.057654</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.047898</td>\n",
       "      <td>0.010117</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>0.024718</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>0.012851</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.098066</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>0.122235</td>\n",
       "      <td>0.098934</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.014657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056044</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.034625</td>\n",
       "      <td>0.025239</td>\n",
       "      <td>0.013148</td>\n",
       "      <td>0.168480</td>\n",
       "      <td>0.023059</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.037003</td>\n",
       "      <td>0.029435</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.018283</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.014140</td>\n",
       "      <td>0.030028</td>\n",
       "      <td>0.033717</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.048980</td>\n",
       "      <td>0.027129</td>\n",
       "      <td>0.203164</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.039573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abacus</td>\n",
       "      <td>0.036833</td>\n",
       "      <td>0.085048</td>\n",
       "      <td>0.051574</td>\n",
       "      <td>0.055456</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.031553</td>\n",
       "      <td>0.031001</td>\n",
       "      <td>0.013787</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>0.020574</td>\n",
       "      <td>0.023187</td>\n",
       "      <td>0.030575</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.027282</td>\n",
       "      <td>0.017997</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.036557</td>\n",
       "      <td>0.039470</td>\n",
       "      <td>0.009293</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022492</td>\n",
       "      <td>0.043684</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.022580</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>0.077753</td>\n",
       "      <td>0.040293</td>\n",
       "      <td>0.021946</td>\n",
       "      <td>0.109843</td>\n",
       "      <td>0.013236</td>\n",
       "      <td>0.013374</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>0.033095</td>\n",
       "      <td>0.023133</td>\n",
       "      <td>0.011663</td>\n",
       "      <td>0.050854</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.020323</td>\n",
       "      <td>0.017078</td>\n",
       "      <td>0.031217</td>\n",
       "      <td>0.007492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.020847</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>0.021844</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045143</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.324532</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.068491</td>\n",
       "      <td>0.081846</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.081104</td>\n",
       "      <td>0.033638</td>\n",
       "      <td>0.006755</td>\n",
       "      <td>0.018042</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.046898</td>\n",
       "      <td>0.023860</td>\n",
       "      <td>0.036968</td>\n",
       "      <td>0.184730</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024416</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.023217</td>\n",
       "      <td>0.009739</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.025241</td>\n",
       "      <td>0.017527</td>\n",
       "      <td>0.007212</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>0.062095</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.007343</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.012138</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.013320</td>\n",
       "      <td>0.044889</td>\n",
       "      <td>0.043947</td>\n",
       "      <td>0.017999</td>\n",
       "      <td>0.005960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abbey</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.014878</td>\n",
       "      <td>0.031553</td>\n",
       "      <td>0.045143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.103389</td>\n",
       "      <td>0.019542</td>\n",
       "      <td>0.038354</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.050870</td>\n",
       "      <td>0.105247</td>\n",
       "      <td>0.031299</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010818</td>\n",
       "      <td>0.019792</td>\n",
       "      <td>0.012938</td>\n",
       "      <td>0.030233</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.140937</td>\n",
       "      <td>0.024560</td>\n",
       "      <td>0.120824</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.006663</td>\n",
       "      <td>0.009739</td>\n",
       "      <td>0.014041</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>0.018780</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>0.005989</td>\n",
       "      <td>0.023996</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.029967</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.024320</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.013238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>0.065202</td>\n",
       "      <td>0.031448</td>\n",
       "      <td>0.073871</td>\n",
       "      <td>0.009343</td>\n",
       "      <td>0.057654</td>\n",
       "      <td>0.031001</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.017357</td>\n",
       "      <td>0.009949</td>\n",
       "      <td>0.009268</td>\n",
       "      <td>0.025145</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>0.019368</td>\n",
       "      <td>0.018366</td>\n",
       "      <td>0.022135</td>\n",
       "      <td>0.012428</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>0.044486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062322</td>\n",
       "      <td>0.065006</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.007660</td>\n",
       "      <td>0.012331</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.027618</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.010019</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.071082</td>\n",
       "      <td>0.033217</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.013104</td>\n",
       "      <td>0.005471</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.019396</td>\n",
       "      <td>0.005497</td>\n",
       "      <td>0.054538</td>\n",
       "      <td>0.025320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abdicate</td>\n",
       "      <td>0.007319</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.015226</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.013787</td>\n",
       "      <td>0.324532</td>\n",
       "      <td>0.040382</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>0.098641</td>\n",
       "      <td>0.023981</td>\n",
       "      <td>0.086037</td>\n",
       "      <td>0.065407</td>\n",
       "      <td>0.019318</td>\n",
       "      <td>0.040311</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.025489</td>\n",
       "      <td>0.008630</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.154615</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.003298</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>0.014882</td>\n",
       "      <td>0.046876</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.019434</td>\n",
       "      <td>0.012892</td>\n",
       "      <td>0.079162</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.045387</td>\n",
       "      <td>0.029345</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.011523</td>\n",
       "      <td>0.016593</td>\n",
       "      <td>0.004340</td>\n",
       "      <td>0.010863</td>\n",
       "      <td>0.025024</td>\n",
       "      <td>0.016092</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.003480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  12217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0         a     a few  a little     a lot  aardvark    abacus   abandon     abbey  abbreviation  abdicate   abdomen    abduct  abduction      Abel     abhor     abide   ability      able  abnormal     abode  Aboriginal  aborigine  abortion     about  ...       yuk       yum     yummy    yuppie       zap      zeal    zealot     zebra       Zen    zenith  Zeppelin      zero      zest     zesty      Zeus       zip    zipper       zit    zodiac    zombie   zombies      zone       zoo      zoom  zucchini\n",
       "0             a  1.000000  0.071836  0.087998  0.072588  0.148540  0.036833  0.020847  0.004574      0.065202  0.007319  0.017431  0.005284   0.006451  0.021331  0.011638  0.040737  0.029599  0.103400  0.021668  0.006534    0.025898   0.020696  0.029184  0.146775  ...  0.008914  0.028118  0.014399  0.022656  0.010734  0.004158  0.005379  0.015949  0.005380  0.041973  0.009474  0.118230  0.017602  0.019333  0.016032  0.022376  0.014898  0.009429  0.006864  0.003725  0.012584  0.024179  0.016509  0.008217  0.032391\n",
       "1         a few  0.071836  1.000000  0.411114  0.419096  0.018210  0.085048  0.009714  0.008136      0.031448  0.007681  0.009009  0.008425   0.010955  0.030484  0.002816  0.014415  0.005027  0.016623  0.027511  0.008260    0.010352   0.008976  0.004343  0.047517  ...  0.004172  0.018736  0.015837  0.020607  0.008517  0.019599  0.038351  0.021007  0.025708  0.042905  0.020627  0.110562  0.007512  0.017657  0.013911  0.004812  0.005999  0.009506  0.025522  0.020187  0.058412  0.018682  0.012746  0.010856  0.026820\n",
       "2      a little  0.087998  0.411114  1.000000  0.459404  0.026005  0.051574  0.024102  0.007379      0.073871  0.015226  0.015796  0.025255   0.027053  0.018755  0.021356  0.015108  0.011474  0.034190  0.033204  0.015928    0.007783   0.010087  0.021640  0.084149  ...  0.011529  0.025737  0.022270  0.019772  0.020900  0.007698  0.012761  0.016344  0.015466  0.023857  0.013831  0.077176  0.009714  0.012551  0.014415  0.012107  0.009469  0.014685  0.007847  0.009323  0.009721  0.018014  0.011244  0.024952  0.023710\n",
       "3         a lot  0.072588  0.419096  0.459404  1.000000  0.009544  0.055456  0.021844  0.007106      0.009343  0.018892  0.007374  0.012018   0.013460  0.007537  0.005096  0.008195  0.022562  0.047236  0.020122  0.016165    0.009879   0.008895  0.007628  0.054251  ...  0.004454  0.030194  0.021112  0.025927  0.003020  0.017997  0.018597  0.013183  0.008417  0.036104  0.017992  0.058006  0.012249  0.009985  0.025468  0.003839  0.004190  0.006489  0.014198  0.002059  0.010044  0.025147  0.015232  0.008517  0.020812\n",
       "4      aardvark  0.148540  0.018210  0.026005  0.009544  1.000000  0.013470  0.011461  0.014878      0.057654  0.005181  0.047898  0.010117   0.009778  0.024718  0.010129  0.003369  0.012851  0.005758  0.098066  0.028034    0.122235   0.098934  0.019050  0.014657  ...  0.056044  0.019499  0.012829  0.010570  0.034625  0.025239  0.013148  0.168480  0.023059  0.008917  0.037003  0.029435  0.015490  0.010547  0.018283  0.008664  0.014140  0.030028  0.033717  0.022641  0.048980  0.027129  0.203164  0.012115  0.039573\n",
       "5        abacus  0.036833  0.085048  0.051574  0.055456  0.013470  1.000000  0.011867  0.031553      0.031001  0.013787  0.010596  0.020574   0.023187  0.030575  0.016621  0.008589  0.027282  0.017997  0.009060  0.016389    0.036557   0.039470  0.009293  0.022197  ...  0.022492  0.043684  0.011831  0.016450  0.009868  0.004679  0.022580  0.031924  0.077753  0.040293  0.021946  0.109843  0.013236  0.013374  0.068058  0.033095  0.023133  0.011663  0.050854  0.006158  0.005591  0.020323  0.017078  0.031217  0.007492\n",
       "6       abandon  0.020847  0.009714  0.024102  0.021844  0.011461  0.011867  1.000000  0.045143      0.028108  0.324532  0.005255  0.068491   0.081846  0.007031  0.081104  0.033638  0.006755  0.018042  0.010517  0.046898    0.023860   0.036968  0.184730  0.014378  ...  0.024416  0.003823  0.004392  0.023217  0.009739  0.006674  0.012531  0.025241  0.017527  0.007212  0.020765  0.062095  0.005081  0.005584  0.007343  0.016599  0.004489  0.012138  0.007188  0.011574  0.013320  0.044889  0.043947  0.017999  0.005960\n",
       "7         abbey  0.004574  0.008136  0.007379  0.007106  0.014878  0.031553  0.045143  1.000000      0.010711  0.040382  0.004762  0.011825   0.008882  0.103389  0.019542  0.038354  0.004085  0.003945  0.050870  0.105247    0.031299   0.035804  0.017037  0.014493  ...  0.010818  0.019792  0.012938  0.030233  0.004828  0.078406  0.140937  0.024560  0.120824  0.025265  0.030900  0.006663  0.009739  0.014041  0.060835  0.018780  0.024073  0.005989  0.023996  0.020130  0.029967  0.030562  0.024320  0.011819  0.013238\n",
       "8  abbreviation  0.065202  0.031448  0.073871  0.009343  0.057654  0.031001  0.028108  0.010711      1.000000  0.019220  0.017357  0.009949   0.009268  0.025145  0.006904  0.019368  0.018366  0.022135  0.012428  0.005737    0.010776   0.010283  0.020539  0.044486  ...  0.062322  0.065006  0.004157  0.009849  0.022513  0.005352  0.007660  0.012331  0.004021  0.021346  0.012603  0.027618  0.010852  0.010019  0.006435  0.071082  0.033217  0.016053  0.013104  0.005471  0.009023  0.019396  0.005497  0.054538  0.025320\n",
       "9      abdicate  0.007319  0.007681  0.015226  0.018892  0.005181  0.013787  0.324532  0.040382      0.019220  1.000000  0.002293  0.155680   0.098641  0.023981  0.086037  0.065407  0.019318  0.040311  0.003518  0.025489    0.008630   0.009089  0.154615  0.010311  ...  0.016057  0.003298  0.002079  0.012900  0.008762  0.014882  0.046876  0.012424  0.015031  0.019434  0.012892  0.079162  0.005246  0.002024  0.045387  0.029345  0.008830  0.011523  0.016593  0.004340  0.010863  0.025024  0.016092  0.012527  0.003480\n",
       "\n",
       "[10 rows x 12217 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c73faf-867e-44eb-b4eb-62386e1c4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]})\n",
    "display (df)\n",
    "array = df.to_numpy() \n",
    "display(array)\n",
    "# array([[1, 3],\n",
    "#        [2, 4]])\n",
    "\n",
    "word2id = {'A': 0, 'B':1}\n",
    "\n",
    "id1 = word2id['A']\n",
    "id2 = word2id['B']\n",
    "\n",
    "array[id1][id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed550b8-c6c9-4866-815d-1e9585780c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22df087f-a9a8-4157-bf01-78b422a1359a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>subj_anchors</th>\n",
       "      <th>subj_anchors_swow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alligators</td>\n",
       "      <td>['reptiles', 'lizards', 'snakes', 'turtles', 'frogs', 'sharks', 'tigers', 'fish', 'birds', 'yes']</td>\n",
       "      <td>['crocodile', 'reptile', 'reptile', 'cayman', 'amphibian', 'iguana', 'lizard', 'scaly', 'gecko', 'hippo']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alligators</td>\n",
       "      <td>['reptiles', 'lizards', 'snakes', 'turtles', 'frogs', 'sharks', 'tigers', 'fish', 'birds', 'yes']</td>\n",
       "      <td>['crocodile', 'reptile', 'reptile', 'cayman', 'amphibian', 'iguana', 'lizard', 'scaly', 'gecko', 'hippo']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ambulances</td>\n",
       "      <td>['hospitals', 'police', 'buses', 'helicopters', 'cars', 'ems', 'planes', 'trucks', 'firefighters', 'cops']</td>\n",
       "      <td>['emergency', 'medic', 'hospital', 'firetruck', 'siren', 'injured', 'injury', 'accident', 'trauma', 'medical']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ambulances</td>\n",
       "      <td>['hospitals', 'police', 'buses', 'helicopters', 'cars', 'ems', 'planes', 'trucks', 'firefighters', 'cops']</td>\n",
       "      <td>['emergency', 'medic', 'hospital', 'firetruck', 'siren', 'injured', 'injury', 'accident', 'trauma', 'medical']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anchors</td>\n",
       "      <td>['boats', 'ships', 'sailors', 'reporters', 'ropes', 'pilots', 'programming', 'photographers', 'cables', 'conductors']</td>\n",
       "      <td>['nautical', 'sailboat', 'sail', 'boat', 'ship', 'seaman', 'ahoy', 'sailor', 'sailor', 'sailing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ants</td>\n",
       "      <td>['insects', 'bugs', 'bees', 'beetles', 'wasps', 'yes', 'flies', 'hornets', 'spiders', 'snakes']</td>\n",
       "      <td>['anthill', 'ant', 'termite', 'insect', 'termite', 'bug', 'infestation', 'insect', 'swarm', 'pest']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ants</td>\n",
       "      <td>['insects', 'bugs', 'bees', 'beetles', 'wasps', 'yes', 'flies', 'hornets', 'spiders', 'snakes']</td>\n",
       "      <td>['anthill', 'ant', 'termite', 'insect', 'termite', 'bug', 'infestation', 'insect', 'swarm', 'pest']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ants</td>\n",
       "      <td>['insects', 'bugs', 'bees', 'beetles', 'wasps', 'yes', 'flies', 'hornets', 'spiders', 'snakes']</td>\n",
       "      <td>['anthill', 'ant', 'termite', 'insect', 'termite', 'bug', 'infestation', 'insect', 'swarm', 'pest']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>apples</td>\n",
       "      <td>['pear', 'bananas', 'fruits', 'grapes', 'nuts', 'vegetables', 'dates', 'berries', 'nut', 'potatoes']</td>\n",
       "      <td>['apple', 'orange', 'orchard', 'fruit', 'fruit', 'juice', 'juicy', 'pear', 'nectarine', 'banana']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>apples</td>\n",
       "      <td>['pear', 'bananas', 'fruits', 'grapes', 'nuts', 'vegetables', 'dates', 'berries', 'nut', 'potatoes']</td>\n",
       "      <td>['apple', 'orange', 'orchard', 'fruit', 'fruit', 'juice', 'juicy', 'pear', 'nectarine', 'banana']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_label                                                                                                           subj_anchors                                                                                               subj_anchors_swow\n",
       "0  alligators                      ['reptiles', 'lizards', 'snakes', 'turtles', 'frogs', 'sharks', 'tigers', 'fish', 'birds', 'yes']       ['crocodile', 'reptile', 'reptile', 'cayman', 'amphibian', 'iguana', 'lizard', 'scaly', 'gecko', 'hippo']\n",
       "1  alligators                      ['reptiles', 'lizards', 'snakes', 'turtles', 'frogs', 'sharks', 'tigers', 'fish', 'birds', 'yes']       ['crocodile', 'reptile', 'reptile', 'cayman', 'amphibian', 'iguana', 'lizard', 'scaly', 'gecko', 'hippo']\n",
       "2  ambulances             ['hospitals', 'police', 'buses', 'helicopters', 'cars', 'ems', 'planes', 'trucks', 'firefighters', 'cops']  ['emergency', 'medic', 'hospital', 'firetruck', 'siren', 'injured', 'injury', 'accident', 'trauma', 'medical']\n",
       "3  ambulances             ['hospitals', 'police', 'buses', 'helicopters', 'cars', 'ems', 'planes', 'trucks', 'firefighters', 'cops']  ['emergency', 'medic', 'hospital', 'firetruck', 'siren', 'injured', 'injury', 'accident', 'trauma', 'medical']\n",
       "4     anchors  ['boats', 'ships', 'sailors', 'reporters', 'ropes', 'pilots', 'programming', 'photographers', 'cables', 'conductors']               ['nautical', 'sailboat', 'sail', 'boat', 'ship', 'seaman', 'ahoy', 'sailor', 'sailor', 'sailing']\n",
       "5        ants                        ['insects', 'bugs', 'bees', 'beetles', 'wasps', 'yes', 'flies', 'hornets', 'spiders', 'snakes']             ['anthill', 'ant', 'termite', 'insect', 'termite', 'bug', 'infestation', 'insect', 'swarm', 'pest']\n",
       "6        ants                        ['insects', 'bugs', 'bees', 'beetles', 'wasps', 'yes', 'flies', 'hornets', 'spiders', 'snakes']             ['anthill', 'ant', 'termite', 'insect', 'termite', 'bug', 'infestation', 'insect', 'swarm', 'pest']\n",
       "7        ants                        ['insects', 'bugs', 'bees', 'beetles', 'wasps', 'yes', 'flies', 'hornets', 'spiders', 'snakes']             ['anthill', 'ant', 'termite', 'insect', 'termite', 'bug', 'infestation', 'insect', 'swarm', 'pest']\n",
       "8      apples                   ['pear', 'bananas', 'fruits', 'grapes', 'nuts', 'vegetables', 'dates', 'berries', 'nut', 'potatoes']               ['apple', 'orange', 'orchard', 'fruit', 'fruit', 'juice', 'juicy', 'pear', 'nectarine', 'banana']\n",
       "9      apples                   ['pear', 'bananas', 'fruits', 'grapes', 'nuts', 'vegetables', 'dates', 'berries', 'nut', 'potatoes']               ['apple', 'orange', 'orchard', 'fruit', 'fruit', 'juice', 'juicy', 'pear', 'nectarine', 'banana']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.options.display.max_columns = 50\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "path = '../../log/bert-large-uncased/clsb/swow_rw/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False_anchor_source_LM_swow_score_source_SWOWSimilar.CLSB.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df[['sub_label', 'subj_anchors', 'subj_anchors_swow']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d21cc453-cf1c-4108-b4d3-1f8a0b3f7095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sub_label', 'obj_label', 'masked_sentences', 'relation', 'weight', 'feature_type', 'obj_label_single', 'sub_sister', 'uuid', 'sub_position', 'sub_label_sg', 'sub_label_pl', 'def_sap', 'def_dap', 'lsp_sap', 'lsp_dap', 'anchor_lsp_sap', 'sub_label_sgpl', 'obj_in_BERT', 'obj_mask_sentence', 'obj_mask_sentence_score', 'obj_mask_def_sap', 'obj_mask_def_sap_score', 'obj_mask_lsp_sap', 'obj_mask_lsp_sap_score', 'subj_anchors', 'subj_anchors_score', 'subj_anchors_sg', 'subj_anchors_pl', 'anchor_col_all', 'subj_anchors_combined', 'masked_sentences_with_subj_anchor', 'def_dap_with_subj_anchor', 'lsp_dap_with_subj_anchor', 'obj_mask_def_dap', 'obj_mask_def_dap_score', 'obj_mask_lsp_dap', 'obj_mask_lsp_dap_score', 'p1_subj_anchors_sg', 'p5_subj_anchors_sg', 'p10_subj_anchors_sg', 'p1_anchor_col_all', 'p5_anchor_col_all', 'p10_anchor_col_all', 'mrr_subj_anchors_sg', 'mrr_anchor_col_all', 'anchor_wordnet_path_len', 'obj_label_sg', 'p1_sentence', 'p5_sentence', 'p10_sentence',\n",
       "       'p1_def_sap', 'p5_def_sap', 'p10_def_sap', 'p1_lsp_sap', 'p5_lsp_sap', 'p10_lsp_sap', 'p1_def_dap', 'p5_def_dap', 'p10_def_dap', 'p1_lsp_dap', 'p5_lsp_dap', 'p10_lsp_dap', 'mrr_sentence', 'mrr_def_sap', 'mrr_lsp_sap', 'mrr_def_dap', 'mrr_lsp_dap'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "path = '../../log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_5_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.CLSB.csv'\n",
    "df = pd.read_csv(path)\n",
    "df[['sub_label', 'subj_anchors']].head(10)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa4c97bd-693c-478c-97b7-9ba266d3f87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cartoons': 0.533857657624221, 'animation': 0.507118662573658, 'anime': 0.479162751836246, 'comics': 0.47882159763871, 'Simpsons': 0.446463219623188, 'comic': 0.441965376015914, 'illustration': 0.381379910887028, 'animate': 0.367117010072667, 'Disney': 0.355660662581727, 'humor': 0.35354637618975}\n",
      "c c\n",
      "c c\n",
      "a a\n",
      "a a\n",
      "a a\n",
      "a a\n",
      "c c\n",
      "c c\n",
      "S S\n",
      "S SES\n",
      "c c\n",
      "c c\n",
      "i i\n",
      "i i\n",
      "a a\n",
      "a a\n",
      "D D\n",
      "D DS\n",
      "h h\n",
      "h h\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e403fe8c-280a-4dc8-901a-471d56162649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12215\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>#sub_label</th>\n",
       "      <th>#SWOW_shared_sub_label</th>\n",
       "      <th>#shared_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hypernymsuite-EVAL</td>\n",
       "      <td>621</td>\n",
       "      <td>609</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hypernymsuite-BLESS</td>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clsb-singular</td>\n",
       "      <td>508</td>\n",
       "      <td>453</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hypernymsuite-LEDS</td>\n",
       "      <td>1073</td>\n",
       "      <td>730</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hypernymsuite-SHWARTZ</td>\n",
       "      <td>11061</td>\n",
       "      <td>2478</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lm_diagnostic_extended-singular</td>\n",
       "      <td>576</td>\n",
       "      <td>85</td>\n",
       "      <td>0.148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           dataset  #sub_label  #SWOW_shared_sub_label  \\\n",
       "4               hypernymsuite-EVAL         621                     609   \n",
       "0              hypernymsuite-BLESS         200                     190   \n",
       "2                    clsb-singular         508                     453   \n",
       "3               hypernymsuite-LEDS        1073                     730   \n",
       "5            hypernymsuite-SHWARTZ       11061                    2478   \n",
       "1  lm_diagnostic_extended-singular         576                      85   \n",
       "\n",
       "   #shared_rate  \n",
       "4         0.981  \n",
       "0         0.950  \n",
       "2         0.892  \n",
       "3         0.680  \n",
       "5         0.224  \n",
       "1         0.148  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e21a893f-0ada-47e1-99b0-f67b4a9ff210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>shutters</td>\n",
       "      <td>['film']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>damages</td>\n",
       "      <td>['book']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>neighborhoods</td>\n",
       "      <td>['section']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>ergos</td>\n",
       "      <td>['newspaper']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>flowers</td>\n",
       "      <td>['magazine']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>somebodies</td>\n",
       "      <td>['single']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>trailers</td>\n",
       "      <td>['album']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>outrages</td>\n",
       "      <td>['album']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>tornadoes</td>\n",
       "      <td>['book']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>cores</td>\n",
       "      <td>['album']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>cyclones</td>\n",
       "      <td>['organization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>significances</td>\n",
       "      <td>['magazine']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>breathes</td>\n",
       "      <td>['film']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>controls</td>\n",
       "      <td>['standard']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>poles</td>\n",
       "      <td>['person']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2542</th>\n",
       "      <td>batteries</td>\n",
       "      <td>['organisation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>plugs</td>\n",
       "      <td>['work']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>athletes</td>\n",
       "      <td>['band']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>singles</td>\n",
       "      <td>['composition']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>bandages</td>\n",
       "      <td>['film']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>minutes</td>\n",
       "      <td>['artist']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>camps</td>\n",
       "      <td>['gene']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>traffic</td>\n",
       "      <td>['organization']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>boulders</td>\n",
       "      <td>['album']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3407</th>\n",
       "      <td>luckies</td>\n",
       "      <td>['person']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>breaks</td>\n",
       "      <td>['album']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>welcomes</td>\n",
       "      <td>['film']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>terms</td>\n",
       "      <td>['point']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>gorges</td>\n",
       "      <td>['ravine']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>bills</td>\n",
       "      <td>['person']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>approvals</td>\n",
       "      <td>['acceptance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>cakes</td>\n",
       "      <td>['band']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>instincts</td>\n",
       "      <td>['album']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>impressions</td>\n",
       "      <td>['imprint']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>fates</td>\n",
       "      <td>['city']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>rooms</td>\n",
       "      <td>['organisation']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>jungles</td>\n",
       "      <td>['song']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>bishops</td>\n",
       "      <td>['minister']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>appearances</td>\n",
       "      <td>['occurrence']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>circuses</td>\n",
       "      <td>['arena']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>countries</td>\n",
       "      <td>['place']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>attentions</td>\n",
       "      <td>['stance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>immortals</td>\n",
       "      <td>['book']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>descents</td>\n",
       "      <td>['episode']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>electrics</td>\n",
       "      <td>['animal']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>semis</td>\n",
       "      <td>['match']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>copies</td>\n",
       "      <td>['human']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>pastures</td>\n",
       "      <td>['grassland']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>trips</td>\n",
       "      <td>['step']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>strings</td>\n",
       "      <td>['album']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sub_label         obj_label\n",
       "2208       shutters          ['film']\n",
       "135         damages          ['book']\n",
       "1816  neighborhoods       ['section']\n",
       "2156          ergos     ['newspaper']\n",
       "12          flowers      ['magazine']\n",
       "2316     somebodies        ['single']\n",
       "920        trailers         ['album']\n",
       "1522       outrages         ['album']\n",
       "1427      tornadoes          ['book']\n",
       "1033          cores         ['album']\n",
       "1733       cyclones  ['organization']\n",
       "1592  significances      ['magazine']\n",
       "363        breathes          ['film']\n",
       "684        controls      ['standard']\n",
       "1215          poles        ['person']\n",
       "2542      batteries  ['organisation']\n",
       "357           plugs          ['work']\n",
       "617        athletes          ['band']\n",
       "1430        singles   ['composition']\n",
       "2153       bandages          ['film']\n",
       "182         minutes        ['artist']\n",
       "232           camps          ['gene']\n",
       "785         traffic  ['organization']\n",
       "2004       boulders         ['album']\n",
       "3407        luckies        ['person']\n",
       "2800         breaks         ['album']\n",
       "2783       welcomes          ['film']\n",
       "2634          terms         ['point']\n",
       "3084         gorges        ['ravine']\n",
       "2340          bills        ['person']\n",
       "531       approvals    ['acceptance']\n",
       "1824          cakes          ['band']\n",
       "102       instincts         ['album']\n",
       "1757    impressions       ['imprint']\n",
       "283           fates          ['city']\n",
       "1866          rooms  ['organisation']\n",
       "2431        jungles          ['song']\n",
       "1404        bishops      ['minister']\n",
       "2823    appearances    ['occurrence']\n",
       "1714       circuses         ['arena']\n",
       "962       countries         ['place']\n",
       "1312     attentions        ['stance']\n",
       "183       immortals          ['book']\n",
       "1018       descents       ['episode']\n",
       "1361      electrics        ['animal']\n",
       "1960          semis         ['match']\n",
       "2644         copies         ['human']\n",
       "2434       pastures     ['grassland']\n",
       "2770          trips          ['step']\n",
       "1144        strings         ['album']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.query(\"dataset == 'hypernymsuite-SHWARTZ'\")[['sub_label', 'obj_label']].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3290fdab-4b70-4914-bd68-b363431650f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E090] Extension 'lemma' already exists on Token. To overwrite the existing extension, set `force=True` on `Token.set_extension`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3236ff44df9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# import pyinflect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlemminflect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_core_web_sm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/lemminflect/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0msv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lemma'\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspacyGetLemma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inflect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInflections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspacyGetInfl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/tokens/token.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.set_extension\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E090] Extension 'lemma' already exists on Token. To overwrite the existing extension, set `force=True` on `Token.set_extension`."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37feba75-a06a-469f-93ae-94f133690c71",
   "metadata": {},
   "source": [
    "## TEST the hyponyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c774ed3e-25d4-483a-b058-bf2cbfc8585e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['flower']\n",
      "1 ['angiosperm', 'flowering plant']\n",
      "2 ['spermatophyte', 'phanerogam', 'seed plant']\n",
      "3 ['vascular plant', 'tracheophyte']\n",
      "4 ['woody plant', 'ligneous plant']\n",
      "5 ['bush', 'shrub']\n",
      "6 ['rose', 'rosebush']\n",
      "1\n",
      "['vascular plant', 'tracheophyte']\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import wn, wn.taxonomy\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "\n",
    "dog = ewn.synsets('daisy', pos='n')[0]\n",
    "squirrel = ewn.synsets('rose', pos='n')[0]\n",
    "for i, ss in enumerate(wn.taxonomy.shortest_path(dog, squirrel)):\n",
    "    print(i, ss.lemmas())\n",
    "    \n",
    "\n",
    "dog = ewn.synsets('daisy', pos='n')[0]\n",
    "squirrel = ewn.synsets('rose', pos='n')[0]\n",
    "print ( len(wn.taxonomy.lowest_common_hypernyms(dog, squirrel)) )\n",
    "print( wn.taxonomy.lowest_common_hypernyms(dog, squirrel)[0].lemmas() )\n",
    "\n",
    "print(wn.taxonomy.min_depth(wn.taxonomy.lowest_common_hypernyms(dog, squirrel)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6cf30a4-aad4-438a-bb6e-626e6eebe9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'gunstock', 'weenie', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'hanger', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "2 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "3 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "4 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "5 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "6 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "7 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "8 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n",
      "9 ['tartar', 'scallywag', 'cow', 'bounder', 'rogue', 'undercarriage', 'knave', 'chipolata', 'stand', 'varlet', 'bracket', 'pier', 'brace', 'blackguard', 'handrest', 'knackwurst', 'harness', 'stirrup', 'rib', 'bookend', 'foot', 'andiron', 'heel', 'base', 'liverwurst', 'tee', 'frankfurter', 'stray', 'weenie', 'gunstock', 'stair', 'bridge', 'step', 'hotdog', 'firedog', 'wolf', 'hound', 'hyena', 'backrest', 'footing', 'hyaena', 'villainess', 'back', 'foothold', 'bearing', 'souse', 'bar', 'bologna', 'headstock', 'leg', 'radius', 'shelf', 'backboard', 'bitch', 'tripper', 'rest', 'headcheese', 'wienerwurst', 'doorstop', 'stock', 'rascal', 'tailstock', 'rapscallion', 'rack', 'frank', 'bag', 'harpy', 'hellcat', 'fox', 'shrew', 'pepperoni', 'detent', 'chorizo', 'dragon', 'knockwurst', 'salami', 'feeder', 'hanger', 'stocker', 'head', 'cad', 'doorstopper', 'rocker', 'harp', 'wiener', 'trip', 'bedpost', 'termagant', 'pawl', 'jackal', 'scalawag', 'vixen', 'seat', 'perch', 'yoke', 'spoke', 'frump', 'click', 'baluster', 'pedestal']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "# from inflection import singularize, pluralize \n",
    "\n",
    "\n",
    "def get_sister_terms(word, distance_to_hypernym=1):\n",
    "    '''\n",
    "    \"Coordinate (sister) terms: share the same hypernym\"\n",
    "    \"The sister relation is the usual one encountered when working with tree structures: sisters are word forms (either simple words or collocations) that are both immediate hyponyms of the same node\"\n",
    "    \n",
    "    Args:\n",
    "        word: the input word\n",
    "        hop: the hops to hypernyms, default is 1, which means take the top 1 hypernym of x\n",
    "    '''\n",
    "    sister_terms = set()\n",
    "    for synset in wn.synsets(word ,\"n\"):\n",
    "        for hypernym in synset.hypernyms()[:distance_to_hypernym]:\n",
    "#             print(hypernym)\n",
    "            sister_synsets = hypernym.hyponyms()\n",
    "            for sister_synset in sister_synsets:\n",
    "                sister_names = [x.name() for x in sister_synset.lemmas()]\n",
    "                sister_names_selected = [name.lower() for name in sister_names if len(name.split(\"_\"))==1 and  len(name.split(\"-\"))==1  and name!=word]\n",
    "                sister_terms = sister_terms.union(set(sister_names_selected))\n",
    "    return list(sister_terms)\n",
    "\n",
    "# for each noun synset of x: retrieve the hyponyms of each hypernym within N hops \n",
    "\n",
    "def test_sister_terms():\n",
    "    for k in range(6):# ,10):\n",
    "        print(k, get_sister_terms('dog', k))\n",
    "        print()\n",
    "test_sister_terms()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b2ed655-0d82-4b01-bc54-b2b7b4fc0844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('ewn-01889397-n')\n",
      "8\n",
      "12\n",
      "['eutherian mammal', 'placental', 'placental mammal', 'eutherian'] 3\n",
      "3\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# from nltk.corpus import wordnet as wn\n",
    " \n",
    "# syn1 = wordnet.synsets('hello')[0]\n",
    "# syn2 = wordnet.synsets('selling')[0]\n",
    " \n",
    "# print (\"hello name :  \", syn1.name())\n",
    "# print (\"selling name :  \", syn2.name())\n",
    "# sorted(syn1.common_hypernyms(syn2))\n",
    "\n",
    "# wn.taxonomy.lowest_common_hypernyms()\n",
    "    \n",
    "import wn, wn.taxonomy\n",
    "ewn = wn.Wordnet('ewn:2020')\n",
    "# wn.taxonomy.taxonomy_depth(ewn, 'n')\n",
    "\n",
    "dog = ewn.synsets('dog', pos='n')[0]\n",
    "squirrel = ewn.synsets('squirrel', pos='n')[0]\n",
    "lcs_synsets = wn.taxonomy.lowest_common_hypernyms(dog, squirrel)\n",
    "print(lcs)\n",
    "\n",
    "# print(len()) #Return the common hypernyms furthest from the root.\n",
    "# print ( wn.taxonomy.lowest_common_hypernyms(dog, squirrel)[0].lemmas())\n",
    "\n",
    "# print(\"---\")\n",
    "print ( wn.taxonomy.min_depth(dog) ) \n",
    "print ( wn.taxonomy.min_depth(squirrel) ) \n",
    "\n",
    "for lcs in lcs_synsets:\n",
    "    sp = wn.taxonomy.shortest_path(dog, lcs)\n",
    "    print(lcs.lemmas(), len(sp))\n",
    "    \n",
    "def get_shortest_path_len_to_lcs(word1, word2):\n",
    "    '''\n",
    "    get distance to lcs of_two_words_in_taxonomy\n",
    "    '''\n",
    "    synset1 = ewn.synsets(word1, pos='n')#[:2]\n",
    "    synset2 = ewn.synsets(word2, pos='n')#[:2]\n",
    "    shorest_path_lens = []\n",
    "    for syn1 in synset1: \n",
    "        for syn2 in synset2:\n",
    "            lcs_synsets =  wn.taxonomy.lowest_common_hypernyms(syn1,syn2)\n",
    "            for lcs in lcs_synsets:\n",
    "                shortest_path = wn.taxonomy.shortest_path(syn1, lcs)\n",
    "                shorest_path_lens.append(len(shortest_path))\n",
    "    return min(shorest_path_lens)\n",
    "\n",
    "\n",
    "spl = get_distance_to_lcs('dog', 'squirrel')         \n",
    "print(spl)\n",
    "spl = get_distance_to_lcs('dog', 'cat')         \n",
    "print(spl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a57b28a-3abe-43d8-886b-6e7d452b4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[Synset('ewn-02086723-n'), Synset('ewn-10133978-n'), Synset('ewn-10042764-n'), Synset('ewn-09905672-n'), Synset('ewn-07692347-n'), Synset('ewn-03907626-n'), Synset('ewn-02712903-n')]\n"
     ]
    }
   ],
   "source": [
    "word1 = 'dog'\n",
    "synset1 = ewn.synsets(word1, pos='n')\n",
    "print(len(synset1))\n",
    "print(synset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cdad4ef-3721-4318-aea7-45a1cf6395b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Synset('ewn-01320032-n') domestic animal\n",
      "  Synset('ewn-00015568-n') fauna\n",
      "   Synset('ewn-00004475-n') being\n",
      "    Synset('ewn-00004258-n') animate thing\n",
      "     Synset('ewn-00003553-n') whole\n",
      "      Synset('ewn-00002684-n') object\n",
      "       Synset('ewn-00001930-n') physical entity\n",
      "        Synset('ewn-00001740-n') entity\n",
      " Synset('ewn-02085998-n') canine\n",
      "  Synset('ewn-02077948-n') carnivore\n",
      "   Synset('ewn-01889397-n') eutherian mammal\n",
      "    Synset('ewn-01864419-n') mammalian\n",
      "     Synset('ewn-01474323-n') craniate\n",
      "      Synset('ewn-01468898-n') chordate\n",
      "       Synset('ewn-00015568-n') fauna\n",
      "        Synset('ewn-00004475-n') being\n",
      "         Synset('ewn-00004258-n') animate thing\n",
      "          Synset('ewn-00003553-n') whole\n",
      "           Synset('ewn-00002684-n') object\n",
      "            Synset('ewn-00001930-n') physical entity\n",
      "             Synset('ewn-00001740-n') entity\n",
      " Synset('ewn-02332053-n') rodent\n",
      "  Synset('ewn-01889397-n') eutherian mammal\n",
      "   Synset('ewn-01864419-n') mammalian\n",
      "    Synset('ewn-01474323-n') craniate\n",
      "     Synset('ewn-01468898-n') chordate\n",
      "      Synset('ewn-00015568-n') fauna\n",
      "       Synset('ewn-00004475-n') being\n",
      "        Synset('ewn-00004258-n') animate thing\n",
      "         Synset('ewn-00003553-n') whole\n",
      "          Synset('ewn-00002684-n') object\n",
      "           Synset('ewn-00001930-n') physical entity\n",
      "            Synset('ewn-00001740-n') entity\n"
     ]
    }
   ],
   "source": [
    "for path in wn.taxonomy.hypernym_paths(dog):\n",
    "    for i, ss in enumerate(path):\n",
    "        print(' ' * i, ss, ss.lemmas()[0])\n",
    "        \n",
    "for path in wn.taxonomy.hypernym_paths(squirrel):\n",
    "    for i, ss in enumerate(path):\n",
    "        print(' ' * i, ss, ss.lemmas()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd486494-8b14-4bdb-8fb0-885646b51925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: wn[web] in /home/chunhua/.local/lib/python3.8/site-packages (0.9.3)\n",
      "Requirement already satisfied: requests in /usr/local/easybuild-2019/easybuild/software/core/anaconda3/2020.07/lib/python3.8/site-packages (from wn[web]) (2.24.0)\n",
      "Requirement already satisfied: tomli in /home/chunhua/.local/lib/python3.8/site-packages (from wn[web]) (2.0.1)\n",
      "Collecting starlette; extra == \"web\"\n",
      "  Downloading starlette-0.23.1-py3-none-any.whl (64 kB)\n",
      "\u001b[K     || 64 kB 1.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/easybuild-2019/easybuild/software/core/anaconda3/2020.07/lib/python3.8/site-packages (from requests->wn[web]) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/easybuild-2019/easybuild/software/core/anaconda3/2020.07/lib/python3.8/site-packages (from requests->wn[web]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/easybuild-2019/easybuild/software/core/anaconda3/2020.07/lib/python3.8/site-packages (from requests->wn[web]) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/easybuild-2019/easybuild/software/core/anaconda3/2020.07/lib/python3.8/site-packages (from requests->wn[web]) (1.25.9)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0; python_version < \"3.10\" in /home/chunhua/.local/lib/python3.8/site-packages (from starlette; extra == \"web\"->wn[web]) (4.4.0)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "\u001b[K     || 80 kB 15.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sniffio>=1.1\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, anyio, starlette\n",
      "Successfully installed anyio-3.6.2 sniffio-1.3.0 starlette-0.23.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install wn\n",
    "!pip install wn[web]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93852357-6d4f-4e33-9563-23ee8f3491da",
   "metadata": {},
   "source": [
    "# What's the difference of evalauting using singular or plural objectives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d6dd59-9522-4fcf-8c82-95cfa5116403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate, simple_separated_format\n",
    "import pandas as pd\n",
    "from collections import  defaultdict, Counter, OrderedDict\n",
    "from inflection import singularize, pluralize\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_colwidth',500)\n",
    "# from evaluation import mean_average_precision, average_precision_at_k, precision_at_k, recall_at_k\n",
    "def concept_evaluation(label, pred):\n",
    "    '''\n",
    "    \n",
    "    label: a list with the singualr and plural labels (e.g., ['tool', 'tools'])\n",
    "    pred: the top K prediction list \n",
    "\n",
    "    return:\n",
    "        1 if label share with pred else 0  \n",
    "    '''\n",
    "    if not isinstance(label, list):\n",
    "        label = eval(label)\n",
    "        \n",
    "    if not isinstance(pred, list):\n",
    "        pred = eval(pred)\n",
    "\n",
    "    shared = set(label).intersection(set(pred))\n",
    "    return 1 if len(shared)>0 else 0 \n",
    "    # return len(shared)/len(pred)\n",
    "    \n",
    "\n",
    "def get_precision_at_k_concept(df, relation, pred_cols, label_col, k_list, pred_col_suffix='obj_mask_'):\n",
    "    '''\n",
    "    evalaute model predictions in concept level, ignoring the morphology affects (singular, plural)\n",
    "    '''\n",
    "\n",
    "    p_at_x = [] #defaultdict() \n",
    "    for pred_col in pred_cols: \n",
    "        suffix = pred_col.replace(pred_col_suffix, \"\")\n",
    "        prec_cur = defaultdict()\n",
    "        prec_cur['mask_type'] = suffix\n",
    "        for k in k_list: \n",
    "            df[f'p{k}_{suffix}'] = df[[label_col, pred_col]].apply(lambda x: concept_evaluation(x[0], eval(x[1])[:k] if isinstance(x[1], str) else x[1][:k]), axis=1 )\n",
    "            prec_cur[f'p@{k}'] = round(df[f'p{k}_{suffix}'].mean() , 3)*100\n",
    "\n",
    "        p_at_x.append(prec_cur)  \n",
    "\n",
    "    # aggregate the average precision across k \n",
    "    df_res = pd.DataFrame(p_at_x) #, columns=['mask_type', 'mAP'])\n",
    "    df_res['relation'] = [relation]*len(df_res)\n",
    "    return df_res\n",
    "\n",
    "def get_highest_mrr_among_labels(label, pred):\n",
    "    '''\n",
    "    return the highest rank among the multiple labels. This is applicable to single labels as well, if we the single label is put in a list\n",
    "\n",
    "    pred: a list of words (candidates)\n",
    "    label: the true labels, which is a list (different forms of a word, e.g., singular or plurs, like animal and animals)\n",
    "    '''\n",
    "    mrr = 0 \n",
    "    if pred is None: return mrr \n",
    "\n",
    "    rank_list = [ pred.index(item) + 1 for item in label if item in pred] \n",
    "    if len(rank_list)>0:\n",
    "        mrr = 1/min(rank_list)\n",
    "    return mrr \n",
    "\n",
    "def get_mrr(df, relation, pred_cols, label_col, pred_col_suffix):\n",
    "    '''\n",
    "    mrr is calculated based on the top_k rank, all elements in obj_col are used\n",
    "    '''\n",
    "    mrr = [] \n",
    "    for i, pred_col in enumerate(pred_cols):\n",
    "        cur_mrr = defaultdict()\n",
    "        suffix = pred_col.replace(pred_col_suffix, \"\")\n",
    "\n",
    "        df[f'mrr_{suffix}'] = df[[label_col, pred_col]].apply(lambda x: get_highest_mrr_among_labels(x[0], x[1]), axis=1 ) \n",
    "        \n",
    "        cur_mrr['mask_type'] = suffix\n",
    "        cur_mrr[f\"mrr\"] = round(df[f'mrr_{suffix}'].mean(), 3)*100\n",
    "        mrr.append(cur_mrr)\n",
    "\n",
    "    mrr_df =  pd.DataFrame(data = mrr) #, columns=['mask_type', 'mrr'])\n",
    "    # mrr_df['mask_type']= mrr_df['mask_type'].apply(lambda x: x.replace(\"\"))\n",
    "    mrr_df['relation'] = relation\n",
    "    return mrr_df \n",
    "\n",
    "def merge_predictions_in_concept_level(uniform_funcion, words, top_k=None ):\n",
    "    '''\n",
    "    uniform_function: either signualarize or pluralize \n",
    "    '''\n",
    "    words_uniformed = [uniform_funcion(word) for word in words]\n",
    "    concepts = list(OrderedDict.fromkeys(words_uniformed))\n",
    "    return concepts[:top_k] if top_k is not None else concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a5cf63-8163-4158-8def-0423f6cf9603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_mask_sentence\n",
      "obj_mask_sentence_score\n",
      "obj_mask_def_sap\n",
      "obj_mask_def_sap_score\n",
      "obj_mask_lsp_sap\n",
      "obj_mask_lsp_sap_score\n",
      "obj_mask_sentence_dap\n",
      "obj_mask_sentence_dap_score\n",
      "obj_mask_def_dap\n",
      "obj_mask_def_dap_score\n",
      "obj_mask_lsp_dap\n",
      "obj_mask_lsp_dap_score\n",
      "obj_label_sg\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mask_type</th>\n",
       "      <th>p@1</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>mrr</th>\n",
       "      <th>mask_type_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>def_sap</td>\n",
       "      <td>23.8</td>\n",
       "      <td>46.9</td>\n",
       "      <td>55.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lsp_sap</td>\n",
       "      <td>21.8</td>\n",
       "      <td>46.2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>def_dap</td>\n",
       "      <td>22.4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lsp_dap</td>\n",
       "      <td>21.5</td>\n",
       "      <td>44.1</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mask_type   p@1   p@5  p@10  mrr  mask_type_id\n",
       "1   def_sap  23.8  46.9  55.6  0.0             1\n",
       "2   lsp_sap  21.8  46.2  56.2  0.0             3\n",
       "4   def_dap  22.4  43.0  51.5  0.0             2\n",
       "5   lsp_dap  21.5  44.1  54.2  0.0             4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# path = '../../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv'\n",
    "path = '../../log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.startswith('obj_mask') or \"obj_label_\" in col:\n",
    "        if col == 'obj_label_single': continue \n",
    "        print(col)\n",
    "        df[col] = df[col].apply(lambda x: eval(x))\n",
    "\n",
    "df_res_all = []\n",
    "top_k=10\n",
    "relation = 'IsA'\n",
    "print(\"-\"*40,\"obj_label evaluation\", \"-\"*40)\n",
    "pred_col_suffix='obj_mask_'\n",
    "df['obj_label_sg'] = df['obj_label'] #.apply(lambda x: [singularize(word) for word in x])\n",
    "label_col = 'obj_label_sg'\n",
    "\n",
    "pred_cols  =[col  for col in df.columns if col.startswith(pred_col_suffix) and \"_score\" not in col]  #predicted target cols, e\n",
    "df_prec = get_precision_at_k_concept(df, relation, pred_cols, label_col, k_list=[1, 5, 10, top_k],pred_col_suffix=pred_col_suffix ) ##note that this would be super slow when top_k is large (>1000) \n",
    "df_mrr =  get_mrr(df, relation, pred_cols, label_col, pred_col_suffix)\n",
    "df_prec['mrr'] = df_prec['mask_type'].apply(lambda x:  df_mrr.loc[df_mrr['mask_type']==x, f'mrr'].values[0])\n",
    "\n",
    "df_prec_display = df_prec[[\"mask_type\", 'p@1', 'p@5', 'p@10', \"mrr\"]] #, \"anchor_wordnet_avg_path\", \"anchor_wordnet_coverage\"]] # \"mAP@1\", \"mAP@5\", \"mAP@10\", \"mAP@1\", \"mAP@5\", \"mAP@10\",  'recall@1', 'recall@5', 'recall@10', \"relation\",\n",
    "\n",
    "mask_type_id = { \"def_sap\": 1, \"def_dap\": 2, \"lsp_sap\": 3, \"lsp_dap\":4} #\"sentence\": 1, \"sentence_dap\":2, \n",
    "df_prec_display = df_prec_display.query(f\"mask_type in {list(mask_type_id.keys())}\")\n",
    "df_prec_display['mask_type_id'] = df_prec_display['mask_type'].apply(lambda x: mask_type_id.get(x))\n",
    "\n",
    "df_prec_display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d1e7142-dafd-4e51-8f6e-4fbfb19b3a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>def_dap_with_subj_anchor</th>\n",
       "      <th>lsp_dap_with_subj_anchor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['An aeroplane or airplane is a [MASK].', 'An aeroplane or plane is a [MASK].', 'An aeroplane or helicopter is a [MASK].', 'An aeroplane or balloon is a [MASK].', 'An aeroplane or boat is a [MASK].', 'An aeroplane or airship is a [MASK].', 'An aeroplane or spacecraft is a [MASK].', 'An aeroplane or ship is a [MASK].', 'An aeroplane or rocket is a [MASK].', 'An aeroplane or airplane is a type of [MASK].', 'An aeroplane or plane is a type of [MASK].', 'An aeroplane or helicopter is a type of [...</td>\n",
       "      <td>['[MASK] such as aeroplanes and airplanes.', '[MASK] such as aeroplanes and planes.', '[MASK] such as aeroplanes and helicopters.', '[MASK] such as aeroplanes and balloons.', '[MASK] such as aeroplanes and boats.', '[MASK] such as aeroplanes and airships.', '[MASK] such as aeroplanes and spacecrafts.', '[MASK] such as aeroplanes and ships.', '[MASK] such as aeroplanes and rockets.', '[MASK], including aeroplanes and airplanes.', '[MASK], including aeroplanes and planes.', '[MASK], including ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...</td>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...</td>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...</td>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...</td>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>['A yoyo or mexico is a [MASK].', 'A yoyo or california is a [MASK].', 'A yoyo or texas is a [MASK].', 'A yoyo or fish is a [MASK].', 'A yoyo or spain is a [MASK].', 'A yoyo or arizona is a [MASK].', 'A yoyo or salsa is a [MASK].', 'A yoyo or etc is a [MASK].', 'A yoyo or dance is a [MASK].', 'A yoyo or indian is a [MASK].', 'A yoyo or mexico is a type of [MASK].', 'A yoyo or california is a type of [MASK].', 'A yoyo or texas is a type of [MASK].', 'A yoyo or fish is a type of [MASK].', 'A y...</td>\n",
       "      <td>['[MASK] such as yoyos and mexicos.', '[MASK] such as yoyos and californias.', '[MASK] such as yoyos and texases.', '[MASK] such as yoyos and fishes.', '[MASK] such as yoyos and spains.', '[MASK] such as yoyos and arizonas.', '[MASK] such as yoyos and salsas.', '[MASK] such as yoyos and etcs.', '[MASK] such as yoyos and dances.', '[MASK] such as yoyos and indians.', '[MASK], including yoyos and mexicos.', '[MASK], including yoyos and californias.', '[MASK], including yoyos and texases.', '[M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>['A yoyo or mexico is a [MASK].', 'A yoyo or california is a [MASK].', 'A yoyo or texas is a [MASK].', 'A yoyo or fish is a [MASK].', 'A yoyo or spain is a [MASK].', 'A yoyo or arizona is a [MASK].', 'A yoyo or salsa is a [MASK].', 'A yoyo or etc is a [MASK].', 'A yoyo or dance is a [MASK].', 'A yoyo or indian is a [MASK].', 'A yoyo or mexico is a type of [MASK].', 'A yoyo or california is a type of [MASK].', 'A yoyo or texas is a type of [MASK].', 'A yoyo or fish is a type of [MASK].', 'A y...</td>\n",
       "      <td>['[MASK] such as yoyos and mexicos.', '[MASK] such as yoyos and californias.', '[MASK] such as yoyos and texases.', '[MASK] such as yoyos and fishes.', '[MASK] such as yoyos and spains.', '[MASK] such as yoyos and arizonas.', '[MASK] such as yoyos and salsas.', '[MASK] such as yoyos and etcs.', '[MASK] such as yoyos and dances.', '[MASK] such as yoyos and indians.', '[MASK], including yoyos and mexicos.', '[MASK], including yoyos and californias.', '[MASK], including yoyos and texases.', '[M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>['A zebra or elephant is a [MASK].', 'A zebra or horse is a [MASK].', 'A zebra or rhino is a [MASK].', 'A zebra or lion is a [MASK].', 'A zebra or bear is a [MASK].', 'A zebra or cow is a [MASK].', 'A zebra or bull is a [MASK].', 'A zebra or deer is a [MASK].', 'A zebra or goat is a [MASK].', 'A zebra or pig is a [MASK].', 'A zebra or elephant is a type of [MASK].', 'A zebra or horse is a type of [MASK].', 'A zebra or rhino is a type of [MASK].', 'A zebra or lion is a type of [MASK].', 'A ze...</td>\n",
       "      <td>['[MASK] such as zebras and elephants.', '[MASK] such as zebras and horses.', '[MASK] such as zebras and rhinos.', '[MASK] such as zebras and lions.', '[MASK] such as zebras and bears.', '[MASK] such as zebras and cows.', '[MASK] such as zebras and bulls.', '[MASK] such as zebras and deer.', '[MASK] such as zebras and goats.', '[MASK] such as zebras and pigs.', '[MASK], including zebras and elephants.', '[MASK], including zebras and horses.', '[MASK], including zebras and rhinos.', '[MASK], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>['A zebra or elephant is a [MASK].', 'A zebra or horse is a [MASK].', 'A zebra or rhino is a [MASK].', 'A zebra or lion is a [MASK].', 'A zebra or bear is a [MASK].', 'A zebra or cow is a [MASK].', 'A zebra or bull is a [MASK].', 'A zebra or deer is a [MASK].', 'A zebra or goat is a [MASK].', 'A zebra or pig is a [MASK].', 'A zebra or elephant is a type of [MASK].', 'A zebra or horse is a type of [MASK].', 'A zebra or rhino is a type of [MASK].', 'A zebra or lion is a type of [MASK].', 'A ze...</td>\n",
       "      <td>['[MASK] such as zebras and elephants.', '[MASK] such as zebras and horses.', '[MASK] such as zebras and rhinos.', '[MASK] such as zebras and lions.', '[MASK] such as zebras and bears.', '[MASK] such as zebras and cows.', '[MASK] such as zebras and bulls.', '[MASK] such as zebras and deer.', '[MASK] such as zebras and goats.', '[MASK] such as zebras and pigs.', '[MASK], including zebras and elephants.', '[MASK], including zebras and horses.', '[MASK], including zebras and rhinos.', '[MASK], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>['A zebra or elephant is a [MASK].', 'A zebra or horse is a [MASK].', 'A zebra or rhino is a [MASK].', 'A zebra or lion is a [MASK].', 'A zebra or bear is a [MASK].', 'A zebra or cow is a [MASK].', 'A zebra or bull is a [MASK].', 'A zebra or deer is a [MASK].', 'A zebra or goat is a [MASK].', 'A zebra or pig is a [MASK].', 'A zebra or elephant is a type of [MASK].', 'A zebra or horse is a type of [MASK].', 'A zebra or rhino is a type of [MASK].', 'A zebra or lion is a type of [MASK].', 'A ze...</td>\n",
       "      <td>['[MASK] such as zebras and elephants.', '[MASK] such as zebras and horses.', '[MASK] such as zebras and rhinos.', '[MASK] such as zebras and lions.', '[MASK] such as zebras and bears.', '[MASK] such as zebras and cows.', '[MASK] such as zebras and bulls.', '[MASK] such as zebras and deer.', '[MASK] such as zebras and goats.', '[MASK] such as zebras and pigs.', '[MASK], including zebras and elephants.', '[MASK], including zebras and horses.', '[MASK], including zebras and rhinos.', '[MASK], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 def_dap_with_subj_anchor  \\\n",
       "0     ['An aeroplane or airplane is a [MASK].', 'An aeroplane or plane is a [MASK].', 'An aeroplane or helicopter is a [MASK].', 'An aeroplane or balloon is a [MASK].', 'An aeroplane or boat is a [MASK].', 'An aeroplane or airship is a [MASK].', 'An aeroplane or spacecraft is a [MASK].', 'An aeroplane or ship is a [MASK].', 'An aeroplane or rocket is a [MASK].', 'An aeroplane or airplane is a type of [MASK].', 'An aeroplane or plane is a type of [MASK].', 'An aeroplane or helicopter is a type of [...   \n",
       "1     ['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...   \n",
       "2     ['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...   \n",
       "3     ['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...   \n",
       "4     ['An alligator or snake is a [MASK].', 'An alligator or crocodile is a [MASK].', 'An alligator or turtle is a [MASK].', 'An alligator or lizard is a [MASK].', 'An alligator or fox is a [MASK].', 'An alligator or frog is a [MASK].', 'An alligator or bird is a [MASK].', 'An alligator or fish is a [MASK].', 'An alligator or dragon is a [MASK].', 'An alligator or shark is a [MASK].', 'An alligator or snake is a type of [MASK].', 'An alligator or crocodile is a type of [MASK].', 'An alligator or ...   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...   \n",
       "1305  ['A yoyo or mexico is a [MASK].', 'A yoyo or california is a [MASK].', 'A yoyo or texas is a [MASK].', 'A yoyo or fish is a [MASK].', 'A yoyo or spain is a [MASK].', 'A yoyo or arizona is a [MASK].', 'A yoyo or salsa is a [MASK].', 'A yoyo or etc is a [MASK].', 'A yoyo or dance is a [MASK].', 'A yoyo or indian is a [MASK].', 'A yoyo or mexico is a type of [MASK].', 'A yoyo or california is a type of [MASK].', 'A yoyo or texas is a type of [MASK].', 'A yoyo or fish is a type of [MASK].', 'A y...   \n",
       "1306  ['A yoyo or mexico is a [MASK].', 'A yoyo or california is a [MASK].', 'A yoyo or texas is a [MASK].', 'A yoyo or fish is a [MASK].', 'A yoyo or spain is a [MASK].', 'A yoyo or arizona is a [MASK].', 'A yoyo or salsa is a [MASK].', 'A yoyo or etc is a [MASK].', 'A yoyo or dance is a [MASK].', 'A yoyo or indian is a [MASK].', 'A yoyo or mexico is a type of [MASK].', 'A yoyo or california is a type of [MASK].', 'A yoyo or texas is a type of [MASK].', 'A yoyo or fish is a type of [MASK].', 'A y...   \n",
       "1307  ['A zebra or elephant is a [MASK].', 'A zebra or horse is a [MASK].', 'A zebra or rhino is a [MASK].', 'A zebra or lion is a [MASK].', 'A zebra or bear is a [MASK].', 'A zebra or cow is a [MASK].', 'A zebra or bull is a [MASK].', 'A zebra or deer is a [MASK].', 'A zebra or goat is a [MASK].', 'A zebra or pig is a [MASK].', 'A zebra or elephant is a type of [MASK].', 'A zebra or horse is a type of [MASK].', 'A zebra or rhino is a type of [MASK].', 'A zebra or lion is a type of [MASK].', 'A ze...   \n",
       "1308  ['A zebra or elephant is a [MASK].', 'A zebra or horse is a [MASK].', 'A zebra or rhino is a [MASK].', 'A zebra or lion is a [MASK].', 'A zebra or bear is a [MASK].', 'A zebra or cow is a [MASK].', 'A zebra or bull is a [MASK].', 'A zebra or deer is a [MASK].', 'A zebra or goat is a [MASK].', 'A zebra or pig is a [MASK].', 'A zebra or elephant is a type of [MASK].', 'A zebra or horse is a type of [MASK].', 'A zebra or rhino is a type of [MASK].', 'A zebra or lion is a type of [MASK].', 'A ze...   \n",
       "1309  ['A zebra or elephant is a [MASK].', 'A zebra or horse is a [MASK].', 'A zebra or rhino is a [MASK].', 'A zebra or lion is a [MASK].', 'A zebra or bear is a [MASK].', 'A zebra or cow is a [MASK].', 'A zebra or bull is a [MASK].', 'A zebra or deer is a [MASK].', 'A zebra or goat is a [MASK].', 'A zebra or pig is a [MASK].', 'A zebra or elephant is a type of [MASK].', 'A zebra or horse is a type of [MASK].', 'A zebra or rhino is a type of [MASK].', 'A zebra or lion is a type of [MASK].', 'A ze...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 lsp_dap_with_subj_anchor  \n",
       "0     ['[MASK] such as aeroplanes and airplanes.', '[MASK] such as aeroplanes and planes.', '[MASK] such as aeroplanes and helicopters.', '[MASK] such as aeroplanes and balloons.', '[MASK] such as aeroplanes and boats.', '[MASK] such as aeroplanes and airships.', '[MASK] such as aeroplanes and spacecrafts.', '[MASK] such as aeroplanes and ships.', '[MASK] such as aeroplanes and rockets.', '[MASK], including aeroplanes and airplanes.', '[MASK], including aeroplanes and planes.', '[MASK], including ...  \n",
       "1     ['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...  \n",
       "2     ['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...  \n",
       "3     ['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...  \n",
       "4     ['[MASK] such as alligators and snakes.', '[MASK] such as alligators and crocodiles.', '[MASK] such as alligators and turtles.', '[MASK] such as alligators and lizards.', '[MASK] such as alligators and foxes.', '[MASK] such as alligators and frogs.', '[MASK] such as alligators and birds.', '[MASK] such as alligators and fishes.', '[MASK] such as alligators and dragons.', '[MASK] such as alligators and sharks.', '[MASK], including alligators and snakes.', '[MASK], including alligators and cro...  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ...  \n",
       "1305  ['[MASK] such as yoyos and mexicos.', '[MASK] such as yoyos and californias.', '[MASK] such as yoyos and texases.', '[MASK] such as yoyos and fishes.', '[MASK] such as yoyos and spains.', '[MASK] such as yoyos and arizonas.', '[MASK] such as yoyos and salsas.', '[MASK] such as yoyos and etcs.', '[MASK] such as yoyos and dances.', '[MASK] such as yoyos and indians.', '[MASK], including yoyos and mexicos.', '[MASK], including yoyos and californias.', '[MASK], including yoyos and texases.', '[M...  \n",
       "1306  ['[MASK] such as yoyos and mexicos.', '[MASK] such as yoyos and californias.', '[MASK] such as yoyos and texases.', '[MASK] such as yoyos and fishes.', '[MASK] such as yoyos and spains.', '[MASK] such as yoyos and arizonas.', '[MASK] such as yoyos and salsas.', '[MASK] such as yoyos and etcs.', '[MASK] such as yoyos and dances.', '[MASK] such as yoyos and indians.', '[MASK], including yoyos and mexicos.', '[MASK], including yoyos and californias.', '[MASK], including yoyos and texases.', '[M...  \n",
       "1307  ['[MASK] such as zebras and elephants.', '[MASK] such as zebras and horses.', '[MASK] such as zebras and rhinos.', '[MASK] such as zebras and lions.', '[MASK] such as zebras and bears.', '[MASK] such as zebras and cows.', '[MASK] such as zebras and bulls.', '[MASK] such as zebras and deer.', '[MASK] such as zebras and goats.', '[MASK] such as zebras and pigs.', '[MASK], including zebras and elephants.', '[MASK], including zebras and horses.', '[MASK], including zebras and rhinos.', '[MASK], ...  \n",
       "1308  ['[MASK] such as zebras and elephants.', '[MASK] such as zebras and horses.', '[MASK] such as zebras and rhinos.', '[MASK] such as zebras and lions.', '[MASK] such as zebras and bears.', '[MASK] such as zebras and cows.', '[MASK] such as zebras and bulls.', '[MASK] such as zebras and deer.', '[MASK] such as zebras and goats.', '[MASK] such as zebras and pigs.', '[MASK], including zebras and elephants.', '[MASK], including zebras and horses.', '[MASK], including zebras and rhinos.', '[MASK], ...  \n",
       "1309  ['[MASK] such as zebras and elephants.', '[MASK] such as zebras and horses.', '[MASK] such as zebras and rhinos.', '[MASK] such as zebras and lions.', '[MASK] such as zebras and bears.', '[MASK] such as zebras and cows.', '[MASK] such as zebras and bulls.', '[MASK] such as zebras and deer.', '[MASK] such as zebras and goats.', '[MASK] such as zebras and pigs.', '[MASK], including zebras and elephants.', '[MASK], including zebras and horses.', '[MASK], including zebras and rhinos.', '[MASK], ...  \n",
       "\n",
       "[1310 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['obj_label', 'obj_mask_def_sap', 'obj_mask_lsp_sap']]\n",
    "# for col in df.colu\n",
    "# print(df.columns)\n",
    "# df[['def_dap_with_subj_anchor', 'lsp_dap_with_subj_anchor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64ee9755-40c8-451a-9735-887bef9e06ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'building': 80})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['obj_label_sg'] = df['obj_label'].apply(lambda x: [singularize(word) for word in x])\n",
    "Counter( [x[0] for x in df.query(\"obj_label_sg != obj_label\")[['sub_label','obj_label', 'obj_label_sg' ]]['obj_label']] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "817cde4c-88ff-47e0-b726-16a23fad046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mask_type</th>\n",
       "      <th>p@1</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>relation</th>\n",
       "      <th>mrr</th>\n",
       "      <th>anchor_wordnet_avg_path</th>\n",
       "      <th>anchor_wordnet_coverage</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>anchor_col_all</td>\n",
       "      <td>22.9</td>\n",
       "      <td>32.3</td>\n",
       "      <td>32.3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>27.3</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>sub_sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>def_dap</td>\n",
       "      <td>35.8</td>\n",
       "      <td>60.1</td>\n",
       "      <td>70.7</td>\n",
       "      <td>IsA</td>\n",
       "      <td>46.3</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>def_dap_uniform</td>\n",
       "      <td>35.8</td>\n",
       "      <td>60.1</td>\n",
       "      <td>70.7</td>\n",
       "      <td>IsA</td>\n",
       "      <td>46.3</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>def_sap</td>\n",
       "      <td>31.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>41.1</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>def_sap_uniform</td>\n",
       "      <td>31.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>64.4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>41.1</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>lsp_dap</td>\n",
       "      <td>38.5</td>\n",
       "      <td>51.9</td>\n",
       "      <td>60.4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>44.7</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>lsp_dap_uniform</td>\n",
       "      <td>41.8</td>\n",
       "      <td>59.9</td>\n",
       "      <td>70.1</td>\n",
       "      <td>IsA</td>\n",
       "      <td>49.9</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>lsp_sap</td>\n",
       "      <td>27.1</td>\n",
       "      <td>44.1</td>\n",
       "      <td>53.6</td>\n",
       "      <td>IsA</td>\n",
       "      <td>34.8</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>lsp_sap_uniform</td>\n",
       "      <td>30.2</td>\n",
       "      <td>51.2</td>\n",
       "      <td>63.9</td>\n",
       "      <td>IsA</td>\n",
       "      <td>39.7</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sentence</td>\n",
       "      <td>25.9</td>\n",
       "      <td>47.0</td>\n",
       "      <td>54.2</td>\n",
       "      <td>IsA</td>\n",
       "      <td>35.8</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>sentence_dap</td>\n",
       "      <td>31.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>58.2</td>\n",
       "      <td>IsA</td>\n",
       "      <td>39.9</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>obj_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>subj_anchors_sg</td>\n",
       "      <td>22.9</td>\n",
       "      <td>32.3</td>\n",
       "      <td>32.3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>27.3</td>\n",
       "      <td>7.08</td>\n",
       "      <td>0.982</td>\n",
       "      <td>sub_sister</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0        mask_type   p@1   p@5  p@10 relation   mrr  \\\n",
       "1            1   anchor_col_all  22.9  32.3  32.3      IsA  27.3   \n",
       "6            4          def_dap  35.8  60.1  70.7      IsA  46.3   \n",
       "10           8  def_dap_uniform  35.8  60.1  70.7      IsA  46.3   \n",
       "3            1          def_sap  31.1  54.0  64.4      IsA  41.1   \n",
       "8            6  def_sap_uniform  31.1  54.0  64.4      IsA  41.1   \n",
       "7            5          lsp_dap  38.5  51.9  60.4      IsA  44.7   \n",
       "11           9  lsp_dap_uniform  41.8  59.9  70.1      IsA  49.9   \n",
       "4            2          lsp_sap  27.1  44.1  53.6      IsA  34.8   \n",
       "9            7  lsp_sap_uniform  30.2  51.2  63.9      IsA  39.7   \n",
       "2            0         sentence  25.9  47.0  54.2      IsA  35.8   \n",
       "5            3     sentence_dap  31.4  49.5  58.2      IsA  39.9   \n",
       "0            0  subj_anchors_sg  22.9  32.3  32.3      IsA  27.3   \n",
       "\n",
       "    anchor_wordnet_avg_path  anchor_wordnet_coverage       label  \n",
       "1                      7.08                    0.982  sub_sister  \n",
       "6                      7.08                    0.982   obj_label  \n",
       "10                     7.08                    0.982   obj_label  \n",
       "3                      7.08                    0.982   obj_label  \n",
       "8                      7.08                    0.982   obj_label  \n",
       "7                      7.08                    0.982   obj_label  \n",
       "11                     7.08                    0.982   obj_label  \n",
       "4                      7.08                    0.982   obj_label  \n",
       "9                      7.08                    0.982   obj_label  \n",
       "2                      7.08                    0.982   obj_label  \n",
       "5                      7.08                    0.982   obj_label  \n",
       "0                      7.08                    0.982  sub_sister  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../log/bert-large-uncased/lm_diagnostic_extended/singular/df_all_use_global_dap_True_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.tsv'\n",
    "\n",
    "\n",
    "df_res = pd.read_csv(path, sep='\\t')\n",
    "df_res.sort_values(by=['mask_type'])\n",
    "# df_res.query(\"mask_type.str.contains()\")\n",
    "# print(singularize('buildings'))\n",
    "# print(singularize('building'))\n",
    "# print(pluralize('building'))\n",
    "# print(singularize(pluralize('building')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d94ba9fc-25f6-4ca6-9b51-e3553e4f64f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['obj_mask_lsp_sap_sg_new'] = df['obj_mask_lsp_sap'].apply(lambda x: merge_predictions_in_concept_level(singularize, x, top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ddbef12-fd48-42a7-83ed-b24a182f8415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buildings'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['sub_label', 'obj_label', 'obj_mask_lsp_sap', 'obj_mask_lsp_sap_sg_new']].sample(20)\n",
    "# df.query(\"sub_label == 'whorehouses'\")[['sub_label', 'obj_label', 'obj_mask_lsp_sap', 'obj_mask_lsp_sap_sg_new']]\n",
    "# df.query(\"obj_label == ['building']\")\n",
    "pluralize('buildings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83402984-1b0d-43a0-a826-90456edfef75",
   "metadata": {},
   "source": [
    "## Evaluate DFP with singular, LSP with Plural "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "032d9087-af38-4a81-896c-330cb4651849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sg_label_in_pred_old    0.536458\n",
       "sg_label_in_pred_new    0.638889\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>masked_sentences</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>sub_label</th>\n",
       "      <th>sub_label_pl</th>\n",
       "      <th>relation</th>\n",
       "      <th>sub_sister</th>\n",
       "      <th>uuid</th>\n",
       "      <th>sub_position</th>\n",
       "      <th>sub_label_sg</th>\n",
       "      <th>...</th>\n",
       "      <th>mrr_sentence_dap</th>\n",
       "      <th>mrr_def_dap</th>\n",
       "      <th>mrr_lsp_dap</th>\n",
       "      <th>mrr_def_sap_uniform</th>\n",
       "      <th>mrr_lsp_sap_uniform</th>\n",
       "      <th>mrr_def_dap_uniform</th>\n",
       "      <th>mrr_lsp_dap_uniform</th>\n",
       "      <th>sg_label_in_pred_old</th>\n",
       "      <th>obj_mask_lsp_sap_sg</th>\n",
       "      <th>sg_label_in_pred_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows  94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, masked_sentences, obj_label, sub_label, sub_label_pl, relation, sub_sister, uuid, sub_position, sub_label_sg, def_sap, def_dap, lsp_sap, lsp_dap, anchor_lsp_sap, sub_label_sgpl, obj_mask_sentence, obj_mask_sentence_score, obj_mask_def_sap, obj_mask_def_sap_score, obj_mask_lsp_sap, obj_mask_lsp_sap_score, subj_anchors, subj_anchors_score, subj_anchors_sg, subj_anchors_pl, anchor_col_all, subj_anchors_combined, masked_sentences_with_subj_anchor, def_dap_with_subj_anchor, lsp_dap_with_subj_anchor, obj_mask_sentence_dap, obj_mask_sentence_dap_score, obj_mask_def_dap, obj_mask_def_dap_score, obj_mask_lsp_dap, obj_mask_lsp_dap_score, obj_mask_def_sap_uniform, obj_mask_lsp_sap_uniform, obj_mask_def_dap_uniform, obj_mask_lsp_dap_uniform, p1_subj_anchors_sg, p5_subj_anchors_sg, p10_subj_anchors_sg, p1_anchor_col_all, p5_anchor_col_all, p10_anchor_col_all, mrr_subj_anchors_sg, mrr_anchor_col_all, anchor_wordnet_path_len, obj_label_sg, p1_sentence, p5_sentence, p10_sentence, p1_def_sap, p5_def_sap, p10_def_sap, p1_lsp_sap, p5_lsp_sap, p10_lsp_sap, p1_sentence_dap, p5_sentence_dap, p10_sentence_dap, p1_def_dap, p5_def_dap, p10_def_dap, p1_lsp_dap, p5_lsp_dap, p10_lsp_dap, p1_def_sap_uniform, p5_def_sap_uniform, p10_def_sap_uniform, p1_lsp_sap_uniform, p5_lsp_sap_uniform, p10_lsp_sap_uniform, p1_def_dap_uniform, p5_def_dap_uniform, p10_def_dap_uniform, p1_lsp_dap_uniform, p5_lsp_dap_uniform, p10_lsp_dap_uniform, mrr_sentence, mrr_def_sap, mrr_lsp_sap, mrr_sentence_dap, mrr_def_dap, mrr_lsp_dap, mrr_def_sap_uniform, mrr_lsp_sap_uniform, mrr_def_dap_uniform, mrr_lsp_dap_uniform, sg_label_in_pred_old, obj_mask_lsp_sap_sg, sg_label_in_pred_new]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 94 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv'\n",
    "df = pd.read_csv(path)\n",
    "for col in df.columns:\n",
    "    if col.startswith('obj_mask') or \"obj_label\" in col:\n",
    "        df[col] = df[col].apply(lambda x: eval(x))\n",
    "\n",
    "df['sg_label_in_pred_old'] = df[['obj_label_sg', 'obj_mask_lsp_sap']].apply(lambda x: 1 if x[0][0] in x[1] else 0 , axis=1)\n",
    "\n",
    "df['obj_mask_lsp_sap_sg'] = df['obj_mask_lsp_sap'].apply(lambda x: [singularize(word) for word in x])\n",
    "df['sg_label_in_pred_new'] = df[['obj_label_sg', 'obj_mask_lsp_sap_sg']].apply(lambda x: 1 if x[0][0] in x[1] else 0 , axis=1)\n",
    "\n",
    "display( df[['sg_label_in_pred_old', 'sg_label_in_pred_new']].mean() ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7aec0b2b-5806-48dc-bc6c-be7b93ff8420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_sg</th>\n",
       "      <th>obj_label_sg</th>\n",
       "      <th>obj_mask_lsp_sap</th>\n",
       "      <th>obj_mask_lsp_sap_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cafeteria</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, thing, place, school, building, area, classroom, location, infrastructure, hospital]</td>\n",
       "      <td>[facility, thing, place, school, build, area, classroom, location, infrastructure, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>stable</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]</td>\n",
       "      <td>[build, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>parsonage</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, church, structure, place, thing, memorial, house, cottage, monument, example]</td>\n",
       "      <td>[build, church, structure, place, thing, memorial, house, cottage, monument, example]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>chalet</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[ski, building, structure, place, cottage, thing, accommodation, hotel, resort, cabin]</td>\n",
       "      <td>[ski, build, structure, place, cottage, thing, accommodation, hotel, resort, cabin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, business, place, facility, retail, establishment, service, venue, building, hotel]</td>\n",
       "      <td>[thing, business, place, facility, retail, establishment, service, venue, build, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>alcazar</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, palace, structure, thing, temple, castle, church, monument, site]</td>\n",
       "      <td>[build, place, palace, structure, thing, temple, castle, church, monument, site]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>orangery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, agriculture, orchard, business, place, building, institution, industry, garden, plantation]</td>\n",
       "      <td>[thing, agriculture, orchard, business, place, build, institution, industry, garden, plantation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ziggurat</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, thing, building, place, architecture, object, carpet, construction, furniture, sculpture]</td>\n",
       "      <td>[structure, thing, build, place, architecture, object, carpet, construction, furniture, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>greenhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, thing, garden, structure, agriculture, facility, place, plant, farm, area]</td>\n",
       "      <td>[build, thing, garden, structure, agriculture, facility, place, plant, farm, area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>shed</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, thing, place, house, cottage, shelter, indoor, workshop, dwelling]</td>\n",
       "      <td>[build, structure, thing, place, house, cottage, shelter, indoor, workshop, dwell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>dispensary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[institution, hospital, facility, thing, place, service, establishment, building, church, shop]</td>\n",
       "      <td>[institution, hospital, facility, thing, place, service, establishment, build, church, shop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>hotel</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, facility, building, place, business, establishment, accommodation, institution, structure, tourism]</td>\n",
       "      <td>[thing, facility, build, place, business, establishment, accommodation, institution, structure, tourism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>carport</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, structure, garage, facility, parking, amenity, building, place, park, landscape]</td>\n",
       "      <td>[thing, structure, garage, facility, parking, amenity, build, place, park, landscape]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, building, structure, thing, shelter, facility, hotel, road, restaurant, area]</td>\n",
       "      <td>[place, build, structure, thing, shelter, facility, hotel, road, restaurant, area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>posthouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, structure, thing, hotel, church, facility, road, office, shelter]</td>\n",
       "      <td>[build, place, structure, thing, hotel, church, facility, road, office, shelter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>saltbox</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, place, thing, fortification, cave, area, quarry, shelter, building, feature]</td>\n",
       "      <td>[structure, place, thing, fortification, cave, area, quarry, shelter, build, feature]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>smokehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]</td>\n",
       "      <td>[build, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>pagoda</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, temple, building, thing, monument, place, example, church, architecture, memorial]</td>\n",
       "      <td>[structure, temple, build, thing, monument, place, example, church, architecture, memorial]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>motel</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[hotel, place, thing, accommodation, building, facility, area, lodge, location, business]</td>\n",
       "      <td>[hotel, place, thing, accommodation, build, facility, area, lodge, location, business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>clubhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[club, building, thing, place, facility, structure, area, location, housing, amenity]</td>\n",
       "      <td>[club, build, thing, place, facility, structure, area, location, housing, amenity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>feedlot</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, facility, agriculture, place, structure, farm, area, location, building, site]</td>\n",
       "      <td>[thing, facility, agriculture, place, structure, farm, area, location, build, site]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>shebeen</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[yes, thing, restaurant, place, yeah, building, business, establishment, oh, hotel]</td>\n",
       "      <td>[yes, thing, restaurant, place, yeah, build, business, establishment, oh, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>rink</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, thing, ice, venue, place, skate, hockey, structure, building, infrastructure]</td>\n",
       "      <td>[facility, thing, ice, venue, place, skate, hockey, structure, build, infrastructure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>alehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[pub, place, thing, establishment, venue, business, facility, restaurant, bar, building]</td>\n",
       "      <td>[pub, place, thing, establishment, venue, business, facility, restaurant, bar, build]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>abattoir</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, restaurant, hotel, facility, business, building, place, establishment, warehouse, shop]</td>\n",
       "      <td>[thing, restaurant, hotel, facility, business, build, place, establishment, warehouse, shop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>stupa</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[temple, structure, monument, thing, place, monastery, building, site, cave, buddhism]</td>\n",
       "      <td>[temple, structure, monument, thing, place, monastery, build, site, cave, buddhism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>kennel</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, dog, place, thing, building, animal, stable, pet, structure, housing]</td>\n",
       "      <td>[facility, dog, place, thing, build, animal, stable, pet, structure, housing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>kirk</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, story, poem, place, company, book, structure, scot, institution, thing]</td>\n",
       "      <td>[build, story, poem, place, company, book, structure, scot, institution, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>mosque</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, church, temple, thing, place, institution, house, religious, religion]</td>\n",
       "      <td>[build, structure, church, temple, thing, place, institution, house, religious, religion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>friary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[monastery, institution, place, building, thing, church, structure, establishment, house, facility]</td>\n",
       "      <td>[monastery, institution, place, build, thing, church, structure, establishment, house, facility]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>icehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, building, thing, restaurant, place, structure, hotel, ice, store, indoor]</td>\n",
       "      <td>[facility, build, thing, restaurant, place, structure, hotel, ice, store, indoor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>guildhall</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, church, place, thing, structure, institution, venue, hall, area, facility]</td>\n",
       "      <td>[build, church, place, thing, structure, institution, venue, hall, area, facility]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>synagogue</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, church, building, institution, place, structure, temple, religion, mosque, judaism]</td>\n",
       "      <td>[thing, church, build, institution, place, structure, temple, religion, mosque, judaism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>flophouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, yes, hotel, thing, prostitution, establishment, bar, business, building, club]</td>\n",
       "      <td>[place, yes, hotel, thing, prostitution, establishment, bar, business, build, club]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>charterhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[institution, school, building, place, thing, university, college, church, structure, monastery]</td>\n",
       "      <td>[institution, school, build, place, thing, university, college, church, structure, monastery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>caravansary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]</td>\n",
       "      <td>[build, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>monastery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, church, building, place, structure, institution, temple, establishment, town, site]</td>\n",
       "      <td>[thing, church, build, place, structure, institution, temple, establishment, town, site]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>presbytery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[church, thing, institution, office, place, parish, organization, body, building, structure]</td>\n",
       "      <td>[church, thing, institution, office, place, parish, organization, body, build, structure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>dacha</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, hotel, thing, building, landmark, restaurant, car, chair, shelter, object]</td>\n",
       "      <td>[place, hotel, thing, build, landmark, restaurant, car, chair, shelter, object]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>morgue</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[hospital, place, thing, facility, cemetery, location, institution, site, building, body]</td>\n",
       "      <td>[hospital, place, thing, facility, cemetery, location, institution, site, build, body]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>gatehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[fortification, structure, thing, building, gate, castle, place, wall, feature, tower]</td>\n",
       "      <td>[fortification, structure, thing, build, gate, castle, place, wall, feature, tower]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>customhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, port, thing, ship, facility, structure, hotel, custom, institution]</td>\n",
       "      <td>[build, place, port, thing, ship, facility, structure, hotel, custom, institution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>statehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, place, thing, government, washington, house, church, state, library]</td>\n",
       "      <td>[build, structure, place, thing, government, washington, house, church, state, library]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>chateau</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, castle, place, thing, structure, estate, house, countryside, property, village]</td>\n",
       "      <td>[build, castle, place, thing, structure, estate, house, countryside, property, village]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>bungalow</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, house, thing, structure, housing, villa, place, cottage, area, home]</td>\n",
       "      <td>[build, house, thing, structure, housing, villa, place, cottage, area, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>tavern</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, pub, thing, establishment, building, bar, hotel, venue, restaurant, business]</td>\n",
       "      <td>[place, pub, thing, establishment, build, bar, hotel, venue, restaurant, business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>boathouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, building, thing, boat, facility, place, dock, clubhouse, beach, hotel]</td>\n",
       "      <td>[structure, build, thing, boat, facility, place, dock, clubhouse, beach, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>shrine</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[temple, structure, building, thing, place, church, institution, facility, site, monastery]</td>\n",
       "      <td>[temple, structure, build, thing, place, church, institution, facility, site, monastery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>apiary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, facility, agriculture, place, institution, building, museum, garden, structure, library]</td>\n",
       "      <td>[thing, facility, agriculture, place, institution, build, museum, garden, structure, library]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>guesthouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[hotel, place, facility, building, thing, accommodation, structure, amenity, area, institution]</td>\n",
       "      <td>[hotel, place, facility, build, thing, accommodation, structure, amenity, area, institution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[monastery, place, institution, church, thing, building, establishment, foundation, structure, order]</td>\n",
       "      <td>[monastery, place, institution, church, thing, build, establishment, foundation, structure, order]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>farmhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, farm, structure, thing, place, house, barn, countryside, cottage, village]</td>\n",
       "      <td>[build, farm, structure, thing, place, house, barn, countryside, cottage, village]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>aviary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[bird, building, place, facility, thing, museum, structure, garden, area, institution]</td>\n",
       "      <td>[bird, build, place, facility, thing, museum, structure, garden, area, institution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>outhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, thing, yes, place, shelter, yeah, facility, shed, oh]</td>\n",
       "      <td>[build, structure, thing, yes, place, shelter, yeah, facility, shed, oh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>masjid</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[mosque, place, thing, building, temple, structure, institution, church, facility, shrine]</td>\n",
       "      <td>[mosque, place, thing, build, temple, structure, institution, church, facility, shrine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>chancellery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[government, institution, office, document, place, thing, building, ministry, structure, cabinet]</td>\n",
       "      <td>[government, institution, office, document, place, thing, build, ministry, structure, cabinet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>priory</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[monastery, institution, thing, church, structure, parish, place, building, establishment, body]</td>\n",
       "      <td>[monastery, institution, thing, church, structure, parish, place, build, establishment, body]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>tenement</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, building, structure, place, suburb, housing, house, dwelling, factory, residential]</td>\n",
       "      <td>[thing, build, structure, place, suburb, housing, house, dwell, factory, residential]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>minster</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, church, child, building, story, poem, parish, musician, monastery, woman]</td>\n",
       "      <td>[place, church, child, build, story, poem, parish, musician, monastery, woman]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub_label_sg obj_label_sg  \\\n",
       "18      cafeteria      [build]   \n",
       "37         stable      [build]   \n",
       "53      parsonage      [build]   \n",
       "62         chalet      [build]   \n",
       "77     restaurant      [build]   \n",
       "79        alcazar      [build]   \n",
       "85       orangery      [build]   \n",
       "86       ziggurat      [build]   \n",
       "88     greenhouse      [build]   \n",
       "111          shed      [build]   \n",
       "114    dispensary      [build]   \n",
       "126         hotel      [build]   \n",
       "142       carport      [build]   \n",
       "144     roadhouse      [build]   \n",
       "154     posthouse      [build]   \n",
       "163       saltbox      [build]   \n",
       "175    smokehouse      [build]   \n",
       "207        pagoda      [build]   \n",
       "214         motel      [build]   \n",
       "229     clubhouse      [build]   \n",
       "238       feedlot      [build]   \n",
       "272       shebeen      [build]   \n",
       "287          rink      [build]   \n",
       "290      alehouse      [build]   \n",
       "293      abattoir      [build]   \n",
       "305         stupa      [build]   \n",
       "310        kennel      [build]   \n",
       "314          kirk      [build]   \n",
       "320        mosque      [build]   \n",
       "326        friary      [build]   \n",
       "332      icehouse      [build]   \n",
       "337     guildhall      [build]   \n",
       "342     synagogue      [build]   \n",
       "363     flophouse      [build]   \n",
       "375  charterhouse      [build]   \n",
       "378   caravansary      [build]   \n",
       "385     monastery      [build]   \n",
       "386    presbytery      [build]   \n",
       "396         dacha      [build]   \n",
       "399        morgue      [build]   \n",
       "400     gatehouse      [build]   \n",
       "407   customhouse      [build]   \n",
       "411    statehouse      [build]   \n",
       "413       chateau      [build]   \n",
       "415      bungalow      [build]   \n",
       "417        tavern      [build]   \n",
       "422     boathouse      [build]   \n",
       "431        shrine      [build]   \n",
       "434        apiary      [build]   \n",
       "454    guesthouse      [build]   \n",
       "459       nunnery      [build]   \n",
       "466     farmhouse      [build]   \n",
       "467        aviary      [build]   \n",
       "468      outhouse      [build]   \n",
       "481        masjid      [build]   \n",
       "483   chancellery      [build]   \n",
       "511        priory      [build]   \n",
       "518      tenement      [build]   \n",
       "519       minster      [build]   \n",
       "\n",
       "                                                                                                obj_mask_lsp_sap  \\\n",
       "18               [facility, thing, place, school, building, area, classroom, location, infrastructure, hospital]   \n",
       "37                                [building, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]   \n",
       "53                      [building, church, structure, place, thing, memorial, house, cottage, monument, example]   \n",
       "62                        [ski, building, structure, place, cottage, thing, accommodation, hotel, resort, cabin]   \n",
       "77                    [thing, business, place, facility, retail, establishment, service, venue, building, hotel]   \n",
       "79                           [building, place, palace, structure, thing, temple, castle, church, monument, site]   \n",
       "85           [thing, agriculture, orchard, business, place, building, institution, industry, garden, plantation]   \n",
       "86         [structure, thing, building, place, architecture, object, carpet, construction, furniture, sculpture]   \n",
       "88                         [building, thing, garden, structure, agriculture, facility, place, plant, farm, area]   \n",
       "111                     [building, structure, thing, place, house, cottage, shelter, indoor, workshop, dwelling]   \n",
       "114              [institution, hospital, facility, thing, place, service, establishment, building, church, shop]   \n",
       "126  [thing, facility, building, place, business, establishment, accommodation, institution, structure, tourism]   \n",
       "142                     [thing, structure, garage, facility, parking, amenity, building, place, park, landscape]   \n",
       "144                        [place, building, structure, thing, shelter, facility, hotel, road, restaurant, area]   \n",
       "154                          [building, place, structure, thing, hotel, church, facility, road, office, shelter]   \n",
       "163                     [structure, place, thing, fortification, cave, area, quarry, shelter, building, feature]   \n",
       "175                          [building, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]   \n",
       "207               [structure, temple, building, thing, monument, place, example, church, architecture, memorial]   \n",
       "214                    [hotel, place, thing, accommodation, building, facility, area, lodge, location, business]   \n",
       "229                        [club, building, thing, place, facility, structure, area, location, housing, amenity]   \n",
       "238                       [thing, facility, agriculture, place, structure, farm, area, location, building, site]   \n",
       "272                          [yes, thing, restaurant, place, yeah, building, business, establishment, oh, hotel]   \n",
       "287                     [facility, thing, ice, venue, place, skate, hockey, structure, building, infrastructure]   \n",
       "290                     [pub, place, thing, establishment, venue, business, facility, restaurant, bar, building]   \n",
       "293              [thing, restaurant, hotel, facility, business, building, place, establishment, warehouse, shop]   \n",
       "305                       [temple, structure, monument, thing, place, monastery, building, site, cave, buddhism]   \n",
       "310                             [facility, dog, place, thing, building, animal, stable, pet, structure, housing]   \n",
       "314                           [building, story, poem, place, company, book, structure, scot, institution, thing]   \n",
       "320                 [building, structure, church, temple, thing, place, institution, house, religious, religion]   \n",
       "326          [monastery, institution, place, building, thing, church, structure, establishment, house, facility]   \n",
       "332                         [facility, building, thing, restaurant, place, structure, hotel, ice, store, indoor]   \n",
       "337                        [building, church, place, thing, structure, institution, venue, hall, area, facility]   \n",
       "342                  [thing, church, building, institution, place, structure, temple, religion, mosque, judaism]   \n",
       "363                       [place, yes, hotel, thing, prostitution, establishment, bar, business, building, club]   \n",
       "375             [institution, school, building, place, thing, university, college, church, structure, monastery]   \n",
       "378                  [building, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]   \n",
       "385                  [thing, church, building, place, structure, institution, temple, establishment, town, site]   \n",
       "386                 [church, thing, institution, office, place, parish, organization, body, building, structure]   \n",
       "396                           [place, hotel, thing, building, landmark, restaurant, car, chair, shelter, object]   \n",
       "399                    [hospital, place, thing, facility, cemetery, location, institution, site, building, body]   \n",
       "400                       [fortification, structure, thing, building, gate, castle, place, wall, feature, tower]   \n",
       "407                        [building, place, port, thing, ship, facility, structure, hotel, custom, institution]   \n",
       "411                   [building, structure, place, thing, government, washington, house, church, state, library]   \n",
       "413                   [building, castle, place, thing, structure, estate, house, countryside, property, village]   \n",
       "415                              [building, house, thing, structure, housing, villa, place, cottage, area, home]   \n",
       "417                        [place, pub, thing, establishment, building, bar, hotel, venue, restaurant, business]   \n",
       "422                           [structure, building, thing, boat, facility, place, dock, clubhouse, beach, hotel]   \n",
       "431                  [temple, structure, building, thing, place, church, institution, facility, site, monastery]   \n",
       "434             [thing, facility, agriculture, place, institution, building, museum, garden, structure, library]   \n",
       "454              [hotel, place, facility, building, thing, accommodation, structure, amenity, area, institution]   \n",
       "459        [monastery, place, institution, church, thing, building, establishment, foundation, structure, order]   \n",
       "466                        [building, farm, structure, thing, place, house, barn, countryside, cottage, village]   \n",
       "467                       [bird, building, place, facility, thing, museum, structure, garden, area, institution]   \n",
       "468                                  [building, structure, thing, yes, place, shelter, yeah, facility, shed, oh]   \n",
       "481                   [mosque, place, thing, building, temple, structure, institution, church, facility, shrine]   \n",
       "483            [government, institution, office, document, place, thing, building, ministry, structure, cabinet]   \n",
       "511             [monastery, institution, thing, church, structure, parish, place, building, establishment, body]   \n",
       "518                  [thing, building, structure, place, suburb, housing, house, dwelling, factory, residential]   \n",
       "519                            [place, church, child, building, story, poem, parish, musician, monastery, woman]   \n",
       "\n",
       "                                                                                         obj_mask_lsp_sap_new  \n",
       "18               [facility, thing, place, school, build, area, classroom, location, infrastructure, hospital]  \n",
       "37                                [build, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]  \n",
       "53                      [build, church, structure, place, thing, memorial, house, cottage, monument, example]  \n",
       "62                        [ski, build, structure, place, cottage, thing, accommodation, hotel, resort, cabin]  \n",
       "77                    [thing, business, place, facility, retail, establishment, service, venue, build, hotel]  \n",
       "79                           [build, place, palace, structure, thing, temple, castle, church, monument, site]  \n",
       "85           [thing, agriculture, orchard, business, place, build, institution, industry, garden, plantation]  \n",
       "86         [structure, thing, build, place, architecture, object, carpet, construction, furniture, sculpture]  \n",
       "88                         [build, thing, garden, structure, agriculture, facility, place, plant, farm, area]  \n",
       "111                        [build, structure, thing, place, house, cottage, shelter, indoor, workshop, dwell]  \n",
       "114              [institution, hospital, facility, thing, place, service, establishment, build, church, shop]  \n",
       "126  [thing, facility, build, place, business, establishment, accommodation, institution, structure, tourism]  \n",
       "142                     [thing, structure, garage, facility, parking, amenity, build, place, park, landscape]  \n",
       "144                        [place, build, structure, thing, shelter, facility, hotel, road, restaurant, area]  \n",
       "154                          [build, place, structure, thing, hotel, church, facility, road, office, shelter]  \n",
       "163                     [structure, place, thing, fortification, cave, area, quarry, shelter, build, feature]  \n",
       "175                          [build, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]  \n",
       "207               [structure, temple, build, thing, monument, place, example, church, architecture, memorial]  \n",
       "214                    [hotel, place, thing, accommodation, build, facility, area, lodge, location, business]  \n",
       "229                        [club, build, thing, place, facility, structure, area, location, housing, amenity]  \n",
       "238                       [thing, facility, agriculture, place, structure, farm, area, location, build, site]  \n",
       "272                          [yes, thing, restaurant, place, yeah, build, business, establishment, oh, hotel]  \n",
       "287                     [facility, thing, ice, venue, place, skate, hockey, structure, build, infrastructure]  \n",
       "290                     [pub, place, thing, establishment, venue, business, facility, restaurant, bar, build]  \n",
       "293              [thing, restaurant, hotel, facility, business, build, place, establishment, warehouse, shop]  \n",
       "305                       [temple, structure, monument, thing, place, monastery, build, site, cave, buddhism]  \n",
       "310                             [facility, dog, place, thing, build, animal, stable, pet, structure, housing]  \n",
       "314                           [build, story, poem, place, company, book, structure, scot, institution, thing]  \n",
       "320                 [build, structure, church, temple, thing, place, institution, house, religious, religion]  \n",
       "326          [monastery, institution, place, build, thing, church, structure, establishment, house, facility]  \n",
       "332                         [facility, build, thing, restaurant, place, structure, hotel, ice, store, indoor]  \n",
       "337                        [build, church, place, thing, structure, institution, venue, hall, area, facility]  \n",
       "342                  [thing, church, build, institution, place, structure, temple, religion, mosque, judaism]  \n",
       "363                       [place, yes, hotel, thing, prostitution, establishment, bar, business, build, club]  \n",
       "375             [institution, school, build, place, thing, university, college, church, structure, monastery]  \n",
       "378                  [build, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]  \n",
       "385                  [thing, church, build, place, structure, institution, temple, establishment, town, site]  \n",
       "386                 [church, thing, institution, office, place, parish, organization, body, build, structure]  \n",
       "396                           [place, hotel, thing, build, landmark, restaurant, car, chair, shelter, object]  \n",
       "399                    [hospital, place, thing, facility, cemetery, location, institution, site, build, body]  \n",
       "400                       [fortification, structure, thing, build, gate, castle, place, wall, feature, tower]  \n",
       "407                        [build, place, port, thing, ship, facility, structure, hotel, custom, institution]  \n",
       "411                   [build, structure, place, thing, government, washington, house, church, state, library]  \n",
       "413                   [build, castle, place, thing, structure, estate, house, countryside, property, village]  \n",
       "415                              [build, house, thing, structure, housing, villa, place, cottage, area, home]  \n",
       "417                        [place, pub, thing, establishment, build, bar, hotel, venue, restaurant, business]  \n",
       "422                           [structure, build, thing, boat, facility, place, dock, clubhouse, beach, hotel]  \n",
       "431                  [temple, structure, build, thing, place, church, institution, facility, site, monastery]  \n",
       "434             [thing, facility, agriculture, place, institution, build, museum, garden, structure, library]  \n",
       "454              [hotel, place, facility, build, thing, accommodation, structure, amenity, area, institution]  \n",
       "459        [monastery, place, institution, church, thing, build, establishment, foundation, structure, order]  \n",
       "466                        [build, farm, structure, thing, place, house, barn, countryside, cottage, village]  \n",
       "467                       [bird, build, place, facility, thing, museum, structure, garden, area, institution]  \n",
       "468                                  [build, structure, thing, yes, place, shelter, yeah, facility, shed, oh]  \n",
       "481                   [mosque, place, thing, build, temple, structure, institution, church, facility, shrine]  \n",
       "483            [government, institution, office, document, place, thing, build, ministry, structure, cabinet]  \n",
       "511             [monastery, institution, thing, church, structure, parish, place, build, establishment, body]  \n",
       "518                     [thing, build, structure, place, suburb, housing, house, dwell, factory, residential]  \n",
       "519                            [place, church, child, build, story, poem, parish, musician, monastery, woman]  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['obj_mask_lsp_sap_new'] = df['obj_mask_lsp_sap'].apply(lambda x: merge_predictions_in_concept_level(singularize, x, top_k))\n",
    "df.query(\"sg_label_in_pred_new==1 and sg_label_in_pred_old==0\")[['sub_label_sg','obj_label_sg', 'obj_mask_lsp_sap', 'obj_mask_lsp_sap_new']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58bbf182-f6a8-4ea6-a2f7-7f4fd3057ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['facility', 'thing', 'place', 'school', 'build', 'area', 'classroom', 'location', 'infrastructure', 'hospital']\n",
      "['facility', 'thing', 'place', 'school', 'build', 'area', 'classroom', 'location', 'infrastructure', 'hospital']\n"
     ]
    }
   ],
   "source": [
    "singularize('building')\n",
    "words = [\"facility\", \"thing\", \"place\", \"school\", \"building\", \"area\", \"classroom\", \"location\", \"infrastructure\", \"hospital\"]\t\n",
    "words_uniformed = merge_predictions_in_concept_level(singularize,words,top_k )\n",
    "print(words_uniformed)\n",
    "words_uniformed = merge_predictions_in_concept_level(singularize,words,top_k )\n",
    "print(words_uniformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98198be8-af97-4239-89fa-abd42daa3de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label_sg</th>\n",
       "      <th>obj_label_sg</th>\n",
       "      <th>obj_mask_lsp_sap</th>\n",
       "      <th>obj_mask_lsp_sap_sg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cafeteria</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, thing, place, school, building, area, classroom, location, infrastructure, hospital]</td>\n",
       "      <td>[facility, thing, place, school, build, area, classroom, location, infrastructure, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>stable</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]</td>\n",
       "      <td>[build, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>parsonage</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, church, structure, place, thing, memorial, house, cottage, monument, example]</td>\n",
       "      <td>[build, church, structure, place, thing, memorial, house, cottage, monument, example]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>chalet</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[ski, building, structure, place, cottage, thing, accommodation, hotel, resort, cabin]</td>\n",
       "      <td>[ski, build, structure, place, cottage, thing, accommodation, hotel, resort, cabin]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, business, place, facility, retail, establishment, service, venue, building, hotel]</td>\n",
       "      <td>[thing, business, place, facility, retail, establishment, service, venue, build, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>alcazar</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, palace, structure, thing, temple, castle, church, monument, site]</td>\n",
       "      <td>[build, place, palace, structure, thing, temple, castle, church, monument, site]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>orangery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, agriculture, orchard, business, place, building, institution, industry, garden, plantation]</td>\n",
       "      <td>[thing, agriculture, orchard, business, place, build, institution, industry, garden, plantation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>ziggurat</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, thing, building, place, architecture, object, carpet, construction, furniture, sculpture]</td>\n",
       "      <td>[structure, thing, build, place, architecture, object, carpet, construction, furniture, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>greenhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, thing, garden, structure, agriculture, facility, place, plant, farm, area]</td>\n",
       "      <td>[build, thing, garden, structure, agriculture, facility, place, plant, farm, area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>shed</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, thing, place, house, cottage, shelter, indoor, workshop, dwelling]</td>\n",
       "      <td>[build, structure, thing, place, house, cottage, shelter, indoor, workshop, dwell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>dispensary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[institution, hospital, facility, thing, place, service, establishment, building, church, shop]</td>\n",
       "      <td>[institution, hospital, facility, thing, place, service, establishment, build, church, shop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>hotel</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, facility, building, place, business, establishment, accommodation, institution, structure, tourism]</td>\n",
       "      <td>[thing, facility, build, place, business, establishment, accommodation, institution, structure, tourism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>carport</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, structure, garage, facility, parking, amenity, building, place, park, landscape]</td>\n",
       "      <td>[thing, structure, garage, facility, parking, amenity, build, place, park, landscape]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>roadhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, building, structure, thing, shelter, facility, hotel, road, restaurant, area]</td>\n",
       "      <td>[place, build, structure, thing, shelter, facility, hotel, road, restaurant, area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>posthouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, structure, thing, hotel, church, facility, road, office, shelter]</td>\n",
       "      <td>[build, place, structure, thing, hotel, church, facility, road, office, shelter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>saltbox</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, place, thing, fortification, cave, area, quarry, shelter, building, feature]</td>\n",
       "      <td>[structure, place, thing, fortification, cave, area, quarry, shelter, build, feature]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>smokehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]</td>\n",
       "      <td>[build, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>pagoda</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, temple, building, thing, monument, place, example, church, architecture, memorial]</td>\n",
       "      <td>[structure, temple, build, thing, monument, place, example, church, architecture, memorial]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>motel</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[hotel, place, thing, accommodation, building, facility, area, lodge, location, business]</td>\n",
       "      <td>[hotel, place, thing, accommodation, build, facility, area, lodge, location, business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>clubhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[club, building, thing, place, facility, structure, area, location, housing, amenity]</td>\n",
       "      <td>[club, build, thing, place, facility, structure, area, location, housing, amenity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>feedlot</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, facility, agriculture, place, structure, farm, area, location, building, site]</td>\n",
       "      <td>[thing, facility, agriculture, place, structure, farm, area, location, build, site]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>shebeen</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[yes, thing, restaurant, place, yeah, building, business, establishment, oh, hotel]</td>\n",
       "      <td>[yes, thing, restaurant, place, yeah, build, business, establishment, oh, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>rink</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, thing, ice, venue, place, skate, hockey, structure, building, infrastructure]</td>\n",
       "      <td>[facility, thing, ice, venue, place, skate, hockey, structure, build, infrastructure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>alehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[pub, place, thing, establishment, venue, business, facility, restaurant, bar, building]</td>\n",
       "      <td>[pub, place, thing, establishment, venue, business, facility, restaurant, bar, build]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>abattoir</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, restaurant, hotel, facility, business, building, place, establishment, warehouse, shop]</td>\n",
       "      <td>[thing, restaurant, hotel, facility, business, build, place, establishment, warehouse, shop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>stupa</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[temple, structure, monument, thing, place, monastery, building, site, cave, buddhism]</td>\n",
       "      <td>[temple, structure, monument, thing, place, monastery, build, site, cave, buddhism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>kennel</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, dog, place, thing, building, animal, stable, pet, structure, housing]</td>\n",
       "      <td>[facility, dog, place, thing, build, animal, stable, pet, structure, housing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>kirk</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, story, poem, place, company, book, structure, scot, institution, thing]</td>\n",
       "      <td>[build, story, poem, place, company, book, structure, scot, institution, thing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>mosque</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, church, temple, thing, place, institution, house, religious, religion]</td>\n",
       "      <td>[build, structure, church, temple, thing, place, institution, house, religious, religion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>friary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[monastery, institution, place, building, thing, church, structure, establishment, house, facility]</td>\n",
       "      <td>[monastery, institution, place, build, thing, church, structure, establishment, house, facility]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>icehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[facility, building, thing, restaurant, place, structure, hotel, ice, store, indoor]</td>\n",
       "      <td>[facility, build, thing, restaurant, place, structure, hotel, ice, store, indoor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>guildhall</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, church, place, thing, structure, institution, venue, hall, area, facility]</td>\n",
       "      <td>[build, church, place, thing, structure, institution, venue, hall, area, facility]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>synagogue</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, church, building, institution, place, structure, temple, religion, mosque, judaism]</td>\n",
       "      <td>[thing, church, build, institution, place, structure, temple, religion, mosque, judaism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>flophouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, yes, hotel, thing, prostitution, establishment, bar, business, building, club]</td>\n",
       "      <td>[place, yes, hotel, thing, prostitution, establishment, bar, business, build, club]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>charterhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[institution, school, building, place, thing, university, college, church, structure, monastery]</td>\n",
       "      <td>[institution, school, build, place, thing, university, college, church, structure, monastery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>caravansary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]</td>\n",
       "      <td>[build, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>monastery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, church, building, place, structure, institution, temple, establishment, town, site]</td>\n",
       "      <td>[thing, church, build, place, structure, institution, temple, establishment, town, site]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>presbytery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[church, thing, institution, office, place, parish, organization, body, building, structure]</td>\n",
       "      <td>[church, thing, institution, office, place, parish, organization, body, build, structure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>dacha</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, hotel, thing, building, landmark, restaurant, car, chair, shelter, object]</td>\n",
       "      <td>[place, hotel, thing, build, landmark, restaurant, car, chair, shelter, object]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>morgue</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[hospital, place, thing, facility, cemetery, location, institution, site, building, body]</td>\n",
       "      <td>[hospital, place, thing, facility, cemetery, location, institution, site, build, body]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>gatehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[fortification, structure, thing, building, gate, castle, place, wall, feature, tower]</td>\n",
       "      <td>[fortification, structure, thing, build, gate, castle, place, wall, feature, tower]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>customhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, place, port, thing, ship, facility, structure, hotel, custom, institution]</td>\n",
       "      <td>[build, place, port, thing, ship, facility, structure, hotel, custom, institution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>statehouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, place, thing, government, washington, house, church, state, library]</td>\n",
       "      <td>[build, structure, place, thing, government, washington, house, church, state, library]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>chateau</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, castle, place, thing, structure, estate, house, countryside, property, village]</td>\n",
       "      <td>[build, castle, place, thing, structure, estate, house, countryside, property, village]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>bungalow</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, house, thing, structure, housing, villa, place, cottage, area, home]</td>\n",
       "      <td>[build, house, thing, structure, housing, villa, place, cottage, area, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>tavern</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, pub, thing, establishment, building, bar, hotel, venue, restaurant, business]</td>\n",
       "      <td>[place, pub, thing, establishment, build, bar, hotel, venue, restaurant, business]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>boathouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[structure, building, thing, boat, facility, place, dock, clubhouse, beach, hotel]</td>\n",
       "      <td>[structure, build, thing, boat, facility, place, dock, clubhouse, beach, hotel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>shrine</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[temple, structure, building, thing, place, church, institution, facility, site, monastery]</td>\n",
       "      <td>[temple, structure, build, thing, place, church, institution, facility, site, monastery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>apiary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, facility, agriculture, place, institution, building, museum, garden, structure, library]</td>\n",
       "      <td>[thing, facility, agriculture, place, institution, build, museum, garden, structure, library]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>guesthouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[hotel, place, facility, building, thing, accommodation, structure, amenity, area, institution]</td>\n",
       "      <td>[hotel, place, facility, build, thing, accommodation, structure, amenity, area, institution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>nunnery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[monastery, place, institution, church, thing, building, establishment, foundation, structure, order]</td>\n",
       "      <td>[monastery, place, institution, church, thing, build, establishment, foundation, structure, order]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>farmhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, farm, structure, thing, place, house, barn, countryside, cottage, village]</td>\n",
       "      <td>[build, farm, structure, thing, place, house, barn, countryside, cottage, village]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>aviary</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[bird, building, place, facility, thing, museum, structure, garden, area, institution]</td>\n",
       "      <td>[bird, build, place, facility, thing, museum, structure, garden, area, institution]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>outhouse</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[building, structure, thing, yes, place, shelter, yeah, facility, shed, oh]</td>\n",
       "      <td>[build, structure, thing, yes, place, shelter, yeah, facility, shed, oh]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>masjid</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[mosque, place, thing, building, temple, structure, institution, church, facility, shrine]</td>\n",
       "      <td>[mosque, place, thing, build, temple, structure, institution, church, facility, shrine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>chancellery</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[government, institution, office, document, place, thing, building, ministry, structure, cabinet]</td>\n",
       "      <td>[government, institution, office, document, place, thing, build, ministry, structure, cabinet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>priory</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[monastery, institution, thing, church, structure, parish, place, building, establishment, body]</td>\n",
       "      <td>[monastery, institution, thing, church, structure, parish, place, build, establishment, body]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>tenement</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[thing, building, structure, place, suburb, housing, house, dwelling, factory, residential]</td>\n",
       "      <td>[thing, build, structure, place, suburb, housing, house, dwell, factory, residential]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>minster</td>\n",
       "      <td>[build]</td>\n",
       "      <td>[place, church, child, building, story, poem, parish, musician, monastery, woman]</td>\n",
       "      <td>[place, church, child, build, story, poem, parish, musician, monastery, woman]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sub_label_sg obj_label_sg  \\\n",
       "18      cafeteria      [build]   \n",
       "37         stable      [build]   \n",
       "53      parsonage      [build]   \n",
       "62         chalet      [build]   \n",
       "77     restaurant      [build]   \n",
       "79        alcazar      [build]   \n",
       "85       orangery      [build]   \n",
       "86       ziggurat      [build]   \n",
       "88     greenhouse      [build]   \n",
       "111          shed      [build]   \n",
       "114    dispensary      [build]   \n",
       "126         hotel      [build]   \n",
       "142       carport      [build]   \n",
       "144     roadhouse      [build]   \n",
       "154     posthouse      [build]   \n",
       "163       saltbox      [build]   \n",
       "175    smokehouse      [build]   \n",
       "207        pagoda      [build]   \n",
       "214         motel      [build]   \n",
       "229     clubhouse      [build]   \n",
       "238       feedlot      [build]   \n",
       "272       shebeen      [build]   \n",
       "287          rink      [build]   \n",
       "290      alehouse      [build]   \n",
       "293      abattoir      [build]   \n",
       "305         stupa      [build]   \n",
       "310        kennel      [build]   \n",
       "314          kirk      [build]   \n",
       "320        mosque      [build]   \n",
       "326        friary      [build]   \n",
       "332      icehouse      [build]   \n",
       "337     guildhall      [build]   \n",
       "342     synagogue      [build]   \n",
       "363     flophouse      [build]   \n",
       "375  charterhouse      [build]   \n",
       "378   caravansary      [build]   \n",
       "385     monastery      [build]   \n",
       "386    presbytery      [build]   \n",
       "396         dacha      [build]   \n",
       "399        morgue      [build]   \n",
       "400     gatehouse      [build]   \n",
       "407   customhouse      [build]   \n",
       "411    statehouse      [build]   \n",
       "413       chateau      [build]   \n",
       "415      bungalow      [build]   \n",
       "417        tavern      [build]   \n",
       "422     boathouse      [build]   \n",
       "431        shrine      [build]   \n",
       "434        apiary      [build]   \n",
       "454    guesthouse      [build]   \n",
       "459       nunnery      [build]   \n",
       "466     farmhouse      [build]   \n",
       "467        aviary      [build]   \n",
       "468      outhouse      [build]   \n",
       "481        masjid      [build]   \n",
       "483   chancellery      [build]   \n",
       "511        priory      [build]   \n",
       "518      tenement      [build]   \n",
       "519       minster      [build]   \n",
       "\n",
       "                                                                                                obj_mask_lsp_sap  \\\n",
       "18               [facility, thing, place, school, building, area, classroom, location, infrastructure, hospital]   \n",
       "37                                [building, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]   \n",
       "53                      [building, church, structure, place, thing, memorial, house, cottage, monument, example]   \n",
       "62                        [ski, building, structure, place, cottage, thing, accommodation, hotel, resort, cabin]   \n",
       "77                    [thing, business, place, facility, retail, establishment, service, venue, building, hotel]   \n",
       "79                           [building, place, palace, structure, thing, temple, castle, church, monument, site]   \n",
       "85           [thing, agriculture, orchard, business, place, building, institution, industry, garden, plantation]   \n",
       "86         [structure, thing, building, place, architecture, object, carpet, construction, furniture, sculpture]   \n",
       "88                         [building, thing, garden, structure, agriculture, facility, place, plant, farm, area]   \n",
       "111                     [building, structure, thing, place, house, cottage, shelter, indoor, workshop, dwelling]   \n",
       "114              [institution, hospital, facility, thing, place, service, establishment, building, church, shop]   \n",
       "126  [thing, facility, building, place, business, establishment, accommodation, institution, structure, tourism]   \n",
       "142                     [thing, structure, garage, facility, parking, amenity, building, place, park, landscape]   \n",
       "144                        [place, building, structure, thing, shelter, facility, hotel, road, restaurant, area]   \n",
       "154                          [building, place, structure, thing, hotel, church, facility, road, office, shelter]   \n",
       "163                     [structure, place, thing, fortification, cave, area, quarry, shelter, building, feature]   \n",
       "175                          [building, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]   \n",
       "207               [structure, temple, building, thing, monument, place, example, church, architecture, memorial]   \n",
       "214                    [hotel, place, thing, accommodation, building, facility, area, lodge, location, business]   \n",
       "229                        [club, building, thing, place, facility, structure, area, location, housing, amenity]   \n",
       "238                       [thing, facility, agriculture, place, structure, farm, area, location, building, site]   \n",
       "272                          [yes, thing, restaurant, place, yeah, building, business, establishment, oh, hotel]   \n",
       "287                     [facility, thing, ice, venue, place, skate, hockey, structure, building, infrastructure]   \n",
       "290                     [pub, place, thing, establishment, venue, business, facility, restaurant, bar, building]   \n",
       "293              [thing, restaurant, hotel, facility, business, building, place, establishment, warehouse, shop]   \n",
       "305                       [temple, structure, monument, thing, place, monastery, building, site, cave, buddhism]   \n",
       "310                             [facility, dog, place, thing, building, animal, stable, pet, structure, housing]   \n",
       "314                           [building, story, poem, place, company, book, structure, scot, institution, thing]   \n",
       "320                 [building, structure, church, temple, thing, place, institution, house, religious, religion]   \n",
       "326          [monastery, institution, place, building, thing, church, structure, establishment, house, facility]   \n",
       "332                         [facility, building, thing, restaurant, place, structure, hotel, ice, store, indoor]   \n",
       "337                        [building, church, place, thing, structure, institution, venue, hall, area, facility]   \n",
       "342                  [thing, church, building, institution, place, structure, temple, religion, mosque, judaism]   \n",
       "363                       [place, yes, hotel, thing, prostitution, establishment, bar, business, building, club]   \n",
       "375             [institution, school, building, place, thing, university, college, church, structure, monastery]   \n",
       "378                  [building, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]   \n",
       "385                  [thing, church, building, place, structure, institution, temple, establishment, town, site]   \n",
       "386                 [church, thing, institution, office, place, parish, organization, body, building, structure]   \n",
       "396                           [place, hotel, thing, building, landmark, restaurant, car, chair, shelter, object]   \n",
       "399                    [hospital, place, thing, facility, cemetery, location, institution, site, building, body]   \n",
       "400                       [fortification, structure, thing, building, gate, castle, place, wall, feature, tower]   \n",
       "407                        [building, place, port, thing, ship, facility, structure, hotel, custom, institution]   \n",
       "411                   [building, structure, place, thing, government, washington, house, church, state, library]   \n",
       "413                   [building, castle, place, thing, structure, estate, house, countryside, property, village]   \n",
       "415                              [building, house, thing, structure, housing, villa, place, cottage, area, home]   \n",
       "417                        [place, pub, thing, establishment, building, bar, hotel, venue, restaurant, business]   \n",
       "422                           [structure, building, thing, boat, facility, place, dock, clubhouse, beach, hotel]   \n",
       "431                  [temple, structure, building, thing, place, church, institution, facility, site, monastery]   \n",
       "434             [thing, facility, agriculture, place, institution, building, museum, garden, structure, library]   \n",
       "454              [hotel, place, facility, building, thing, accommodation, structure, amenity, area, institution]   \n",
       "459        [monastery, place, institution, church, thing, building, establishment, foundation, structure, order]   \n",
       "466                        [building, farm, structure, thing, place, house, barn, countryside, cottage, village]   \n",
       "467                       [bird, building, place, facility, thing, museum, structure, garden, area, institution]   \n",
       "468                                  [building, structure, thing, yes, place, shelter, yeah, facility, shed, oh]   \n",
       "481                   [mosque, place, thing, building, temple, structure, institution, church, facility, shrine]   \n",
       "483            [government, institution, office, document, place, thing, building, ministry, structure, cabinet]   \n",
       "511             [monastery, institution, thing, church, structure, parish, place, building, establishment, body]   \n",
       "518                  [thing, building, structure, place, suburb, housing, house, dwelling, factory, residential]   \n",
       "519                            [place, church, child, building, story, poem, parish, musician, monastery, woman]   \n",
       "\n",
       "                                                                                          obj_mask_lsp_sap_sg  \n",
       "18               [facility, thing, place, school, build, area, classroom, location, infrastructure, hospital]  \n",
       "37                                [build, thing, facility, place, yes, horse, structure, farm, farmhouse, oh]  \n",
       "53                      [build, church, structure, place, thing, memorial, house, cottage, monument, example]  \n",
       "62                        [ski, build, structure, place, cottage, thing, accommodation, hotel, resort, cabin]  \n",
       "77                    [thing, business, place, facility, retail, establishment, service, venue, build, hotel]  \n",
       "79                           [build, place, palace, structure, thing, temple, castle, church, monument, site]  \n",
       "85           [thing, agriculture, orchard, business, place, build, institution, industry, garden, plantation]  \n",
       "86         [structure, thing, build, place, architecture, object, carpet, construction, furniture, sculpture]  \n",
       "88                         [build, thing, garden, structure, agriculture, facility, place, plant, farm, area]  \n",
       "111                        [build, structure, thing, place, house, cottage, shelter, indoor, workshop, dwell]  \n",
       "114              [institution, hospital, facility, thing, place, service, establishment, build, church, shop]  \n",
       "126  [thing, facility, build, place, business, establishment, accommodation, institution, structure, tourism]  \n",
       "142                     [thing, structure, garage, facility, parking, amenity, build, place, park, landscape]  \n",
       "144                        [place, build, structure, thing, shelter, facility, hotel, road, restaurant, area]  \n",
       "154                          [build, place, structure, thing, hotel, church, facility, road, office, shelter]  \n",
       "163                     [structure, place, thing, fortification, cave, area, quarry, shelter, build, feature]  \n",
       "175                          [build, structure, place, thing, hotel, pub, facility, warehouse, club, shelter]  \n",
       "207               [structure, temple, build, thing, monument, place, example, church, architecture, memorial]  \n",
       "214                    [hotel, place, thing, accommodation, build, facility, area, lodge, location, business]  \n",
       "229                        [club, build, thing, place, facility, structure, area, location, housing, amenity]  \n",
       "238                       [thing, facility, agriculture, place, structure, farm, area, location, build, site]  \n",
       "272                          [yes, thing, restaurant, place, yeah, build, business, establishment, oh, hotel]  \n",
       "287                     [facility, thing, ice, venue, place, skate, hockey, structure, build, infrastructure]  \n",
       "290                     [pub, place, thing, establishment, venue, business, facility, restaurant, bar, build]  \n",
       "293              [thing, restaurant, hotel, facility, business, build, place, establishment, warehouse, shop]  \n",
       "305                       [temple, structure, monument, thing, place, monastery, build, site, cave, buddhism]  \n",
       "310                             [facility, dog, place, thing, build, animal, stable, pet, structure, housing]  \n",
       "314                           [build, story, poem, place, company, book, structure, scot, institution, thing]  \n",
       "320                 [build, structure, church, temple, thing, place, institution, house, religious, religion]  \n",
       "326          [monastery, institution, place, build, thing, church, structure, establishment, house, facility]  \n",
       "332                         [facility, build, thing, restaurant, place, structure, hotel, ice, store, indoor]  \n",
       "337                        [build, church, place, thing, structure, institution, venue, hall, area, facility]  \n",
       "342                  [thing, church, build, institution, place, structure, temple, religion, mosque, judaism]  \n",
       "363                       [place, yes, hotel, thing, prostitution, establishment, bar, business, build, club]  \n",
       "375             [institution, school, build, place, thing, university, college, church, structure, monastery]  \n",
       "378                  [build, place, mosque, structure, warehouse, market, thing, bazaar, merchant, monastery]  \n",
       "385                  [thing, church, build, place, structure, institution, temple, establishment, town, site]  \n",
       "386                 [church, thing, institution, office, place, parish, organization, body, build, structure]  \n",
       "396                           [place, hotel, thing, build, landmark, restaurant, car, chair, shelter, object]  \n",
       "399                    [hospital, place, thing, facility, cemetery, location, institution, site, build, body]  \n",
       "400                       [fortification, structure, thing, build, gate, castle, place, wall, feature, tower]  \n",
       "407                        [build, place, port, thing, ship, facility, structure, hotel, custom, institution]  \n",
       "411                   [build, structure, place, thing, government, washington, house, church, state, library]  \n",
       "413                   [build, castle, place, thing, structure, estate, house, countryside, property, village]  \n",
       "415                              [build, house, thing, structure, housing, villa, place, cottage, area, home]  \n",
       "417                        [place, pub, thing, establishment, build, bar, hotel, venue, restaurant, business]  \n",
       "422                           [structure, build, thing, boat, facility, place, dock, clubhouse, beach, hotel]  \n",
       "431                  [temple, structure, build, thing, place, church, institution, facility, site, monastery]  \n",
       "434             [thing, facility, agriculture, place, institution, build, museum, garden, structure, library]  \n",
       "454              [hotel, place, facility, build, thing, accommodation, structure, amenity, area, institution]  \n",
       "459        [monastery, place, institution, church, thing, build, establishment, foundation, structure, order]  \n",
       "466                        [build, farm, structure, thing, place, house, barn, countryside, cottage, village]  \n",
       "467                       [bird, build, place, facility, thing, museum, structure, garden, area, institution]  \n",
       "468                                  [build, structure, thing, yes, place, shelter, yeah, facility, shed, oh]  \n",
       "481                   [mosque, place, thing, build, temple, structure, institution, church, facility, shrine]  \n",
       "483            [government, institution, office, document, place, thing, build, ministry, structure, cabinet]  \n",
       "511             [monastery, institution, thing, church, structure, parish, place, build, establishment, body]  \n",
       "518                     [thing, build, structure, place, suburb, housing, house, dwell, factory, residential]  \n",
       "519                            [place, church, child, build, story, poem, parish, musician, monastery, woman]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter( [ x[0] for x in df.query(\"sg_label_in_pred_new==1 and sg_label_in_pred_old==0\")['obj_label_sg']])\n",
    "# [['sub_label', 'obj_label_sg', 'obj_mask_lsp_sap', 'obj_mask_lsp_sap_sg']]\n",
    "df.query(\"sg_label_in_pred_new==1 and sg_label_in_pred_old==0\")[['sub_label_sg','obj_label_sg', 'obj_mask_lsp_sap', 'obj_mask_lsp_sap_sg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a1d89-bd07-4dad-9ac6-7e701b92282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c90fc712-0f68-47fc-a5b9-ea04e562e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_mask_sentence\n",
      "obj_mask_sentence_score\n",
      "obj_mask_def_sap\n",
      "obj_mask_def_sap_score\n",
      "obj_mask_lsp_sap\n",
      "obj_mask_lsp_sap_score\n",
      "obj_mask_sentence_dap\n",
      "obj_mask_sentence_dap_score\n",
      "obj_mask_def_dap\n",
      "obj_mask_def_dap_score\n",
      "obj_mask_lsp_dap\n",
      "obj_mask_lsp_dap_score\n",
      "obj_label_sg\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "begin{tabular}{}\n",
      "hline\n",
      " mask_type   \t p@1   \t p@5   \t p@10   \t relation   \t mrr   \t mask_type_id   \n",
      "hline\n",
      "hline\n",
      "end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# path = '../../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv'\n",
    "path = '../../log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.startswith('obj_mask') or \"obj_label\" in col:\n",
    "        if col == 'obj_label_single': continue \n",
    "        print(col)\n",
    "        df[col] = df[col].apply(lambda x: eval(x))\n",
    "\n",
    "df['obj_label_pl'] = df['obj_label'].apply(lambda x: [pluralize(eval(x)[0] )] )\n",
    "# df = df.head(5)\n",
    "for col in df.columns:\n",
    "    if col in ['obj_mask_lsp_sap', 'obj_mask_lsp_dap']:\n",
    "        df[col]  = df[col].apply(lambda x: [pluralize(word) for word in x])\n",
    "\n",
    "def get_res(pred_col_suffix, label_col):\n",
    "    df_res_all = []\n",
    "    pred_cols  =[col  for col in df.columns if col.startswith(pred_col_suffix) and \"_score\" not in col]  #predicted target cols, e\n",
    "    df_prec = get_precision_at_k_concept(df, relation, pred_cols, label_col, k_list=[1, 5, 10, top_k],pred_col_suffix=pred_col_suffix ) ##note that this would be super slow when top_k is large (>1000) \n",
    "    df_mrr =  get_mrr(df, relation, pred_cols, label_col, pred_col_suffix)\n",
    "    df_prec['mrr'] = df_prec['mask_type'].apply(lambda x:  df_mrr.loc[df_mrr['mask_type']==x, f'mrr'].values[0])\n",
    "\n",
    "    ## add WordNet path score for evaluation \n",
    "    #anchor_wordnet_avg_path, anchor_wordnet_coverage = get_wordnet_avg_path_between_sub_and_anchors(df, oov_path_len = 100)\n",
    "    #df_prec['anchor_wordnet_avg_path'] = anchor_wordnet_avg_path\n",
    "    #df_prec['anchor_wordnet_coverage'] = anchor_wordnet_coverage\n",
    "    ## df_prec = df_prec[['mask_type', 'p@1', 'p@10', 'mrr', 'p@3', 'mAP', 'relation' ]]\n",
    "\n",
    "    df_prec_display = df_prec[[\"mask_type\", 'p@1', 'p@5', 'p@10', \"mrr\"]] #, \"anchor_wordnet_avg_path\", \"anchor_wordnet_coverage\"]] # \"mAP@1\", \"mAP@5\", \"mAP@10\", \"mAP@1\", \"mAP@5\", \"mAP@10\",  'recall@1', 'recall@5', 'recall@10', \"relation\",\n",
    "    df_res_all.append(df_prec )\n",
    "    df_res_all = pd.concat(df_res_all).reset_index(drop=True)\n",
    "    # df_res_all['label'] = 'obj_label'\n",
    "    return df_res_all\n",
    "\n",
    "relation = 'IsA'\n",
    "print(\"-\"*40,\"obj_label evaluation\", \"-\"*40)\n",
    "# df['obj_label_sg'] = df['obj_label'].apply(lambda x: [singularize(word) for word in x])\n",
    "\n",
    "df_res_dfp = get_res(pred_col_suffix='obj_mask_def', label_col = 'obj_label')\n",
    "df_res_lsp =  get_res(pred_col_suffix='obj_mask_lsp', label_col = 'obj_label_pl')\n",
    "\n",
    "display(df_res_dfp)\n",
    "display(df_res_lsp)\n",
    "df_prec_display = pd.concat([df_res_dfp, df_res_lsp], axis=0)\n",
    "mask_type = ['_sap', '_dap']\n",
    "df_prec_display.query(f\"mask_type in {mask_type}\")\n",
    "\n",
    "# mask_type_id = { \"def_sap\": 1, \"def_dap\": 2, \"lsp_sap\": 3, \"lsp_dap\":4} #\"sentence\": 1, \"sentence_dap\":2, \n",
    "# df_prec_display = df_prec_display.query(f\"mask_type in {list(mask_type_id.keys())}\")\n",
    "# df_prec_display['mask_type_id'] = df_prec_display['mask_type'].apply(lambda x: mask_type_id.get(x))\n",
    "print(tabulate(df_prec_display, tablefmt='latex', headers=df_prec_display.columns).replace(\"\\\\\", \"\").replace(\"&\", \"\\t\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "237bf83c-6433-4213-8cc9-60c587f93077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>obj_label</th>\n",
       "      <th>obj_mask_def_sap</th>\n",
       "      <th>obj_mask_def_dap</th>\n",
       "      <th>subj_anchors_sg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alligators</td>\n",
       "      <td>['reptile']</td>\n",
       "      <td>[animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]</td>\n",
       "      <td>[animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]</td>\n",
       "      <td>['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alligators</td>\n",
       "      <td>['animal']</td>\n",
       "      <td>[animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]</td>\n",
       "      <td>[animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]</td>\n",
       "      <td>['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alligators</td>\n",
       "      <td>['carnivore']</td>\n",
       "      <td>[animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]</td>\n",
       "      <td>[animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]</td>\n",
       "      <td>['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alligators</td>\n",
       "      <td>['predator']</td>\n",
       "      <td>[animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]</td>\n",
       "      <td>[animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]</td>\n",
       "      <td>['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>alligators</td>\n",
       "      <td>['amphibian']</td>\n",
       "      <td>[animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]</td>\n",
       "      <td>[animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]</td>\n",
       "      <td>['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sub_label      obj_label  \\\n",
       "1  alligators    ['reptile']   \n",
       "2  alligators     ['animal']   \n",
       "3  alligators  ['carnivore']   \n",
       "4  alligators   ['predator']   \n",
       "5  alligators  ['amphibian']   \n",
       "\n",
       "                                                                 obj_mask_def_sap  \\\n",
       "1  [animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]   \n",
       "2  [animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]   \n",
       "3  [animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]   \n",
       "4  [animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]   \n",
       "5  [animal, fish, turtle, mammal, crocodile, monster, lizard, snake, human, bird]   \n",
       "\n",
       "                                                               obj_mask_def_dap  \\\n",
       "1  [animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]   \n",
       "2  [animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]   \n",
       "3  [animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]   \n",
       "4  [animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]   \n",
       "5  [animal, shark, fish, frog, predator, dragon, mammal, lizard, turtle, snake]   \n",
       "\n",
       "                                                                                subj_anchors_sg  \n",
       "1  ['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']  \n",
       "2  ['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']  \n",
       "3  ['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']  \n",
       "4  ['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']  \n",
       "5  ['snake', 'crocodile', 'turtle', 'lizard', 'fox', 'frog', 'bird', 'fish', 'dragon', 'shark']  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"sub_label=='alligators'\")[['sub_label','obj_label', 'obj_mask_def_sap', 'obj_mask_def_dap', 'subj_anchors_sg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2776e919-6a11-419b-ab28-42718f616064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mask_type</th>\n",
       "      <th>p@1</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>relation</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_sap</td>\n",
       "      <td>23.8</td>\n",
       "      <td>46.9</td>\n",
       "      <td>55.6</td>\n",
       "      <td>IsA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_dap</td>\n",
       "      <td>22.4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>IsA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mask_type   p@1   p@5  p@10 relation  mrr\n",
       "0      _sap  23.8  46.9  55.6      IsA  0.0\n",
       "1      _dap  22.4  43.0  51.5      IsA  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mask_type</th>\n",
       "      <th>p@1</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>relation</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_sap</td>\n",
       "      <td>21.8</td>\n",
       "      <td>46.4</td>\n",
       "      <td>56.6</td>\n",
       "      <td>IsA</td>\n",
       "      <td>31.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_dap</td>\n",
       "      <td>21.5</td>\n",
       "      <td>44.1</td>\n",
       "      <td>54.3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mask_type   p@1   p@5  p@10 relation   mrr\n",
       "0      _sap  21.8  46.4  56.6      IsA  31.8\n",
       "1      _dap  21.5  44.1  54.3      IsA  30.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mask_type</th>\n",
       "      <th>p@1</th>\n",
       "      <th>p@5</th>\n",
       "      <th>p@10</th>\n",
       "      <th>relation</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_sap</td>\n",
       "      <td>23.8</td>\n",
       "      <td>46.9</td>\n",
       "      <td>55.6</td>\n",
       "      <td>IsA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_dap</td>\n",
       "      <td>22.4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>IsA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_sap</td>\n",
       "      <td>21.8</td>\n",
       "      <td>46.4</td>\n",
       "      <td>56.6</td>\n",
       "      <td>IsA</td>\n",
       "      <td>31.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_dap</td>\n",
       "      <td>21.5</td>\n",
       "      <td>44.1</td>\n",
       "      <td>54.3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>30.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mask_type   p@1   p@5  p@10 relation   mrr\n",
       "0      _sap  23.8  46.9  55.6      IsA   0.0\n",
       "1      _dap  22.4  43.0  51.5      IsA   0.0\n",
       "0      _sap  21.8  46.4  56.6      IsA  31.8\n",
       "1      _dap  21.5  44.1  54.3      IsA  30.6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5d5e1e-3b2f-4d6c-bb7c-e62ea8967f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['obj_mask_lsp_sap_sg'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-de7b485cb82a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df[['obj_label_pl', 'obj_mask_lsp_sap']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obj_label_sg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'obj_mask_lsp_sap_sg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3511\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3513\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5780\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5782\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5784\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5844\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5845\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5847\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['obj_mask_lsp_sap_sg'] not in index\""
     ]
    }
   ],
   "source": [
    "# df['']\n",
    "what I'm trying to examine? \n",
    "whether the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea0e07b-471a-4601-b856-f7d931ed78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['obj_mask_lsp_sap_sg'] = df['obj_mask_lsp_sap'].apply(lambda x: [singularize(word) for word in x])\n",
    "df['sg_label_in_pred'] = df[['obj_label_sg', 'obj_mask_lsp_sap_sg']].apply(lambda x: 1 if x[0][0] in x[1] else 0 , axis=1)\n",
    "df['pl_label_in_pred'] = df[['obj_label_pl', 'obj_mask_lsp_sap']].apply(lambda x: 1 if x[0][0] in x[1] else 0 , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad444aea-31da-488c-8f26-15f12cfa2f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sg_label_in_pred    0.638889\n",
       "pl_label_in_pred    0.638889\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sg_mrr    0.397176\n",
       "pl_mrr    0.397176\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df[['obj_label_sg', 'obj_label_pl',  'obj_mask_lsp_sap_sg', 'obj_mask_lsp_sap']]\n",
    "display( df[['sg_label_in_pred', 'pl_label_in_pred']].mean() ) \n",
    "df.query(\"pl_label_in_pred==1 and sg_label_in_pred==0\")\n",
    "\n",
    "df['sg_mrr'] = df[['obj_label_sg', 'obj_mask_lsp_sap_sg']].apply(lambda x:get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "df['pl_mrr'] = df[['obj_label_pl', 'obj_mask_lsp_sap']].apply(lambda x:get_highest_mrr_among_labels(x[0], x[1]), axis=1)\n",
    "display( df[['sg_mrr', 'pl_mrr']].mean() ) \n",
    "# for x in df['obj_mask_lsp_sap']:\n",
    "#     print(x, type(x))\n",
    "#     break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0933c12-7b2b-441c-8168-81217d4614a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_mask_lsp_sap_sg</th>\n",
       "      <th>obj_mask_lsp_sap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[grave, people, dead, burial, thing, worker, b...</td>\n",
       "      <td>[graves, people, dead, burials, things, worker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[fish, catfish, specie, thing, animal, bass, r...</td>\n",
       "      <td>[fishes, catfish, species, things, animals, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bird, animal, thing, dolphin, specie, fish, w...</td>\n",
       "      <td>[birds, animals, things, dolphins, species, fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[snake, reptile, animal, insect, predator, peo...</td>\n",
       "      <td>[snakes, reptiles, animals, insects, predators...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[story, poem, artist, people, thing, tribe, mu...</td>\n",
       "      <td>[stories, poems, artists, people, things, trib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>[aircraft, thing, airplane, plane, type, examp...</td>\n",
       "      <td>[aircraft, things, airplanes, planes, types, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>[tree, thing, plant, vegetable, africa, animal...</td>\n",
       "      <td>[trees, things, plants, vegetables, africa, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>[thing, vehicle, item, equipment, material, ai...</td>\n",
       "      <td>[things, vehicles, items, equipments, material...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>[story, poem, thing, book, writing, herb, anim...</td>\n",
       "      <td>[stories, poems, things, books, writings, herb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>[tool, thing, poem, story, device, instrument,...</td>\n",
       "      <td>[tools, things, poems, stories, devices, instr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   obj_mask_lsp_sap_sg  \\\n",
       "0    [grave, people, dead, burial, thing, worker, b...   \n",
       "1    [fish, catfish, specie, thing, animal, bass, r...   \n",
       "2    [bird, animal, thing, dolphin, specie, fish, w...   \n",
       "3    [snake, reptile, animal, insect, predator, peo...   \n",
       "4    [story, poem, artist, people, thing, tribe, mu...   \n",
       "..                                                 ...   \n",
       "571  [aircraft, thing, airplane, plane, type, examp...   \n",
       "572  [tree, thing, plant, vegetable, africa, animal...   \n",
       "573  [thing, vehicle, item, equipment, material, ai...   \n",
       "574  [story, poem, thing, book, writing, herb, anim...   \n",
       "575  [tool, thing, poem, story, device, instrument,...   \n",
       "\n",
       "                                      obj_mask_lsp_sap  \n",
       "0    [graves, people, dead, burials, things, worker...  \n",
       "1    [fishes, catfish, species, things, animals, ba...  \n",
       "2    [birds, animals, things, dolphins, species, fi...  \n",
       "3    [snakes, reptiles, animals, insects, predators...  \n",
       "4    [stories, poems, artists, people, things, trib...  \n",
       "..                                                 ...  \n",
       "571  [aircraft, things, airplanes, planes, types, e...  \n",
       "572  [trees, things, plants, vegetables, africa, an...  \n",
       "573  [things, vehicles, items, equipments, material...  \n",
       "574  [stories, poems, things, books, writings, herb...  \n",
       "575  [tools, things, poems, stories, devices, instr...  \n",
       "\n",
       "[576 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[['obj_mask_lsp_sap_sg', 'obj_mask_lsp_sap']] \n",
    "for x in ['obj_mask_lsp_sap']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee3732-33a2-4560-90d7-8e11807a057a",
   "metadata": {},
   "source": [
    "# Plot: single patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfa404-d7cb-4702-82b9-e7b78e49bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max.columns', 100)\n",
    "pd.set_option('display.max.colwidth', 500)\n",
    "\n",
    "path = '../log/paper_results/analysis/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_False_cpt_False.CLSB.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()\n",
    "df.query(\"sub_label == 'satsumas'\")[['sub_label', 'obj_label', 'subj_anchors', ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f4fb48-f710-4956-83b4-78fe02b22802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '../../log/bert-large-uncased/clsb/consistency_group/IsA.lsp_sap.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a45c025-8859-4d3b-8a8e-f37c0acec158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sub_label_singular</th>\n",
       "      <th>obj_label_singular</th>\n",
       "      <th>sub_label_plural</th>\n",
       "      <th>obj_label_plural</th>\n",
       "      <th>uuid</th>\n",
       "      <th>relation</th>\n",
       "      <th>mask_sentences_singular_1</th>\n",
       "      <th>mask_sentences_singular_2</th>\n",
       "      <th>mask_sentences_singular_3</th>\n",
       "      <th>...</th>\n",
       "      <th>p1_pl_2</th>\n",
       "      <th>p1_sg_3</th>\n",
       "      <th>p1_pl_3</th>\n",
       "      <th>p1_sg_4</th>\n",
       "      <th>p1_pl_4</th>\n",
       "      <th>p1_sg_5</th>\n",
       "      <th>p1_pl_5</th>\n",
       "      <th>p1_sg</th>\n",
       "      <th>p1_pl</th>\n",
       "      <th>p1_sgpl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aeroplane</td>\n",
       "      <td>vehicle</td>\n",
       "      <td>aeroplanes</td>\n",
       "      <td>vehicles</td>\n",
       "      <td>1</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as an aeroplane.</td>\n",
       "      <td>[MASK], including an aeroplane.</td>\n",
       "      <td>[MASK], especially an aeroplane.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>alligator</td>\n",
       "      <td>reptile</td>\n",
       "      <td>alligators</td>\n",
       "      <td>reptiles</td>\n",
       "      <td>2</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as an alligator.</td>\n",
       "      <td>[MASK], including an alligator.</td>\n",
       "      <td>[MASK], especially an alligator.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>alligator</td>\n",
       "      <td>animal</td>\n",
       "      <td>alligators</td>\n",
       "      <td>animals</td>\n",
       "      <td>3</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as an alligator.</td>\n",
       "      <td>[MASK], including an alligator.</td>\n",
       "      <td>[MASK], especially an alligator.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>alligator</td>\n",
       "      <td>carnivore</td>\n",
       "      <td>alligators</td>\n",
       "      <td>carnivores</td>\n",
       "      <td>4</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as an alligator.</td>\n",
       "      <td>[MASK], including an alligator.</td>\n",
       "      <td>[MASK], especially an alligator.</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>alligator</td>\n",
       "      <td>predator</td>\n",
       "      <td>alligators</td>\n",
       "      <td>predators</td>\n",
       "      <td>5</td>\n",
       "      <td>IsA</td>\n",
       "      <td>[MASK] such as an alligator.</td>\n",
       "      <td>[MASK], including an alligator.</td>\n",
       "      <td>[MASK], especially an alligator.</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 sub_label_singular obj_label_singular sub_label_plural  \\\n",
       "0           0          aeroplane            vehicle       aeroplanes   \n",
       "1           1          alligator            reptile       alligators   \n",
       "2           2          alligator             animal       alligators   \n",
       "3           3          alligator          carnivore       alligators   \n",
       "4           4          alligator           predator       alligators   \n",
       "\n",
       "  obj_label_plural  uuid relation     mask_sentences_singular_1  \\\n",
       "0         vehicles     1      IsA  [MASK] such as an aeroplane.   \n",
       "1         reptiles     2      IsA  [MASK] such as an alligator.   \n",
       "2          animals     3      IsA  [MASK] such as an alligator.   \n",
       "3       carnivores     4      IsA  [MASK] such as an alligator.   \n",
       "4        predators     5      IsA  [MASK] such as an alligator.   \n",
       "\n",
       "         mask_sentences_singular_2         mask_sentences_singular_3  ...  \\\n",
       "0  [MASK], including an aeroplane.  [MASK], especially an aeroplane.  ...   \n",
       "1  [MASK], including an alligator.  [MASK], especially an alligator.  ...   \n",
       "2  [MASK], including an alligator.  [MASK], especially an alligator.  ...   \n",
       "3  [MASK], including an alligator.  [MASK], especially an alligator.  ...   \n",
       "4  [MASK], including an alligator.  [MASK], especially an alligator.  ...   \n",
       "\n",
       "  p1_pl_2 p1_sg_3 p1_pl_3 p1_sg_4 p1_pl_4 p1_sg_5 p1_pl_5 p1_sg p1_pl p1_sgpl  \n",
       "0       1       1       1       1       1       1       1     1     1       1  \n",
       "1       1       1       1       1       1       1       1     1     1       1  \n",
       "2       1       1       1       1       1       1       1     1     1       1  \n",
       "3       0       0       0       0       0       0       0     0     0       0  \n",
       "4       1       1       1       1       1       1       1     1     1       1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba3fb540-823a-45fd-8809-ed5d834e3143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n",
      "---------------------------------------- obj_label evaluation ----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Group_And</th>\n",
       "      <th>Group_Best</th>\n",
       "      <th>Group_Or</th>\n",
       "      <th>Group_Best_Pattern_ID</th>\n",
       "      <th>mask_type</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>42.6</td>\n",
       "      <td>61.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>4</td>\n",
       "      <td>lsp_sap</td>\n",
       "      <td>CLSB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>21.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>46.7</td>\n",
       "      <td>1</td>\n",
       "      <td>lsp_sap</td>\n",
       "      <td>BLESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>14.3</td>\n",
       "      <td>37.5</td>\n",
       "      <td>53.6</td>\n",
       "      <td>4</td>\n",
       "      <td>lsp_sap</td>\n",
       "      <td>EVAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>33.4</td>\n",
       "      <td>54.9</td>\n",
       "      <td>64.0</td>\n",
       "      <td>4</td>\n",
       "      <td>lsp_sap</td>\n",
       "      <td>LEDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>43.2</td>\n",
       "      <td>68.9</td>\n",
       "      <td>79.3</td>\n",
       "      <td>4</td>\n",
       "      <td>lsp_sap</td>\n",
       "      <td>LMDIAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>48.2</td>\n",
       "      <td>60.9</td>\n",
       "      <td>64.6</td>\n",
       "      <td>1</td>\n",
       "      <td>lsp_dap</td>\n",
       "      <td>CLSB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>25.1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>44.1</td>\n",
       "      <td>1</td>\n",
       "      <td>lsp_dap</td>\n",
       "      <td>BLESS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>17.8</td>\n",
       "      <td>38.0</td>\n",
       "      <td>49.6</td>\n",
       "      <td>5</td>\n",
       "      <td>lsp_dap</td>\n",
       "      <td>EVAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>42.2</td>\n",
       "      <td>57.8</td>\n",
       "      <td>65.7</td>\n",
       "      <td>1</td>\n",
       "      <td>lsp_dap</td>\n",
       "      <td>LEDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>57.5</td>\n",
       "      <td>72.4</td>\n",
       "      <td>75.9</td>\n",
       "      <td>1</td>\n",
       "      <td>lsp_dap</td>\n",
       "      <td>LMDIAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K  Group_And  Group_Best  Group_Or  Group_Best_Pattern_ID mask_type  \\\n",
       "0  10       42.6        61.0      67.0                      4   lsp_sap   \n",
       "0  10       21.0        41.6      46.7                      1   lsp_sap   \n",
       "0  10       14.3        37.5      53.6                      4   lsp_sap   \n",
       "0  10       33.4        54.9      64.0                      4   lsp_sap   \n",
       "0  10       43.2        68.9      79.3                      4   lsp_sap   \n",
       "0  10       48.2        60.9      64.6                      1   lsp_dap   \n",
       "0  10       25.1        39.2      44.1                      1   lsp_dap   \n",
       "0  10       17.8        38.0      49.6                      5   lsp_dap   \n",
       "0  10       42.2        57.8      65.7                      1   lsp_dap   \n",
       "0  10       57.5        72.4      75.9                      1   lsp_dap   \n",
       "\n",
       "  dataset  \n",
       "0    CLSB  \n",
       "0   BLESS  \n",
       "0    EVAL  \n",
       "0    LEDS  \n",
       "0  LMDIAG  \n",
       "0    CLSB  \n",
       "0   BLESS  \n",
       "0    EVAL  \n",
       "0    LEDS  \n",
       "0  LMDIAG  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict \n",
    "import pandas as pd \n",
    "def concept_evaluation(label, pred):\n",
    "    '''\n",
    "    \n",
    "    label: a list with the singualr and plural labels (e.g., ['tool', 'tools'])\n",
    "    pred: the top K prediction list \n",
    "\n",
    "    return:\n",
    "        1 if label share with pred else 0  \n",
    "    '''\n",
    "    if not isinstance(label, list):\n",
    "        # label = eval(label)\n",
    "        label = [label]\n",
    "        \n",
    "    if not isinstance(pred, list):\n",
    "        pred = eval(pred)\n",
    "\n",
    "    shared = set(label).intersection(set(pred))\n",
    "    return 1 if len(shared)>0 else 0 \n",
    "\n",
    "\n",
    "# def post_evaluation():\n",
    "file = '../../log/bert-large-uncased/clsb/consistency_group/IsA.lsp_sap.csv'\n",
    "dataset_to_file_lsp_dap = {\n",
    "    \"CLSB\": \"../../log/bert-large-uncased/clsb/consistency_group/IsA.lsp_dap.csv\",\n",
    "    \"BLESS\": \"../../log/bert-large-uncased/BLESS/consistency_group/IsA.lsp_dap.csv\",\n",
    "    \"EVAL\": \"../../log/bert-large-uncased/EVAL/consistency_group/IsA.lsp_dap.csv\",\n",
    "    \"LEDS\": \"../../log/bert-large-uncased/LEDS/consistency_group/IsA.lsp_dap.csv\",\n",
    "    \"LMDIAG\": \"../../log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.lsp_dap.csv\"}\n",
    "\n",
    "dataset_to_file_lsp_sap = {\n",
    "    \"CLSB\": \"../../log/bert-large-uncased/clsb/consistency_group/IsA.lsp_sap.csv\",\n",
    "    \"BLESS\": \"../../log/bert-large-uncased/BLESS/consistency_group/IsA.lsp_sap.csv\",\n",
    "    \"EVAL\": \"../../log/bert-large-uncased/EVAL/consistency_group/IsA.lsp_sap.csv\",\n",
    "    \"LEDS\": \"../../log/bert-large-uncased/LEDS/consistency_group/IsA.lsp_sap.csv\",\n",
    "    \"LMDIAG\": \"../../log/bert-large-uncased/lm_diagnostic_extended/consistency_group/IsA.lsp_sap.csv\"}\n",
    "\n",
    "\n",
    "dataset_to_df_res = []\n",
    "for dataset_to_file in [dataset_to_file_lsp_sap, dataset_to_file_lsp_dap]:\n",
    "    for dataset, file in dataset_to_file.items(): \n",
    "        df = pd.read_csv(file)\n",
    "        mask_type = file.split('/')[-1].replace(\".csv\", \"\").replace(\"IsA.\", \"\")\n",
    "        pattern_num = 6\n",
    "        print(\"-\"*40,\"obj_label evaluation\", \"-\"*40)\n",
    "        pred_col_sg=[x for x in df.columns if 'obj_mask_sentence_sg_' in x and 'score' not in x]\n",
    "        pred_col_pl=[x for x in df.columns if 'obj_mask_sentence_pl_' in x and 'score' not in x]\n",
    "\n",
    "\n",
    "        k=1\n",
    "        df_res = []\n",
    "        for k in [10]: #[1,10, 50]:\n",
    "            # for i, (pred_col_sg, pred_col_pl) in enumerate(zip(pred_col_sg, pred_col_pl), start=1):\n",
    "            for i in range(1, pattern_num):\n",
    "                df[f'p1_sg_{i}'] = df[['obj_label_singular', f'obj_mask_sentence_sg_{i}']].apply(lambda x: concept_evaluation(x[0], eval(x[1])[:k]), axis=1 )\n",
    "                df[f'p1_pl_{i}'] = df[['obj_label_plural', f'obj_mask_sentence_pl_{i}']].apply(lambda x: concept_evaluation(x[0], eval(x[1])[:k]), axis=1 )\n",
    "\n",
    "            pred_col_sg_p1 = [x for x in df.columns if 'p1_sg_' in x ]\n",
    "            pred_col_pl_p1 = [x for x in df.columns if 'p1_pl_' in x ]\n",
    "\n",
    "\n",
    "\n",
    "            df['p1_sg'] = df[pred_col_sg_p1].apply(lambda x: int(all(ele == 1 for ele in x)), axis=1)\n",
    "            df['p1_pl'] = df[pred_col_pl_p1].apply(lambda x: int(all(ele == 1 for ele in x)), axis=1)\n",
    "\n",
    "            df['p1_pl_or'] = df[pred_col_pl_p1].apply(lambda x: int(any(ele == 1 for ele in x)), axis=1)\n",
    "        #     df['p1_pl'] = df[pred_col_pl_p1].apply(lambda x: int(all(ele == 1 for ele in x)), axis=1)\n",
    "\n",
    "\n",
    "            df['p1_sgpl'] = df[['p1_sg', 'p1_pl']].apply(lambda x: 1 if x[0]==1 and x[1]==1 else 0, axis=1)\n",
    "\n",
    "            acc_sg = round(df['p1_sg'].sum()/len(df.index), 3) * 100\n",
    "            acc_pl = round(df['p1_pl'].sum()/len(df.index), 3) * 100\n",
    "            acc_sgpl = round(df['p1_sgpl'].sum()/len(df.index), 3) * 100\n",
    "\n",
    "            acc_pl_list = defaultdict()\n",
    "            for i in range(1, pattern_num):\n",
    "                acc_pl_list[i] =  round(df[f'p1_pl_{i}'].sum()/len(df.index), 3) * 100 \n",
    "    #             acc_pl_list.append(f'acc_pl{i}')\n",
    "\n",
    "            acc_pl_best_one_pattern = max(acc_pl_list.values())\n",
    "            best_pattern_id = max(zip(acc_pl_list.values(), acc_pl_list.keys()))[1]\n",
    "\n",
    "            df_res.append({\"K\":k, \n",
    "                           \"Group_And\": acc_pl, \n",
    "                           \"Group_Best\": acc_pl_best_one_pattern,\n",
    "                           \"Group_Or\": round(df['p1_pl_or'].sum()/len(df.index), 3) * 100, \n",
    "                           \"Group_Best_Pattern_ID\": best_pattern_id, \n",
    "                          }) #Singular': acc_sg, 'Paired Singular-Plural': acc_sgpl,\n",
    "\n",
    "        df_res = pd.DataFrame(data=df_res)\n",
    "        df_res['mask_type'] = mask_type\n",
    "        df_res['dataset'] = dataset \n",
    "        dataset_to_df_res.append(df_res)\n",
    "    #     display(df_res)\n",
    "        # display(df_res)\n",
    "        # outpath = f'{save_dir}/{file.replace(\"jsonl\", \"csv\")}'\n",
    "        # df.to_csv(outpath)\n",
    "\n",
    "        # res_outpath = f'{save_dir}/{file.replace(\"jsonl\", \"tsv\")}'\n",
    "        # df_res.to_csv(res_outpath)\n",
    "        # print(f\"Save {outpath}\")\n",
    "        # print(f\"Save {res_outpath}\")\n",
    "        # print(\"\")\n",
    "dataset_to_df_res = pd.concat(dataset_to_df_res)\n",
    "display(dataset_to_df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97d81b3c-aff5-47ff-b94b-deb7c9b65491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>BLESS</th>\n",
       "      <th>LMDIAG</th>\n",
       "      <th>CLSB</th>\n",
       "      <th>EVAL</th>\n",
       "      <th>LEDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>BLESS</td>\n",
       "      <td>LMDIAG</td>\n",
       "      <td>CLSB</td>\n",
       "      <td>EVAL</td>\n",
       "      <td>LEDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group_And</th>\n",
       "      <td>21.0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>42.6</td>\n",
       "      <td>14.3</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group_Best</th>\n",
       "      <td>41.6</td>\n",
       "      <td>68.9</td>\n",
       "      <td>61.0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>54.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group_Or</th>\n",
       "      <td>46.7</td>\n",
       "      <td>79.3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset     BLESS  LMDIAG  CLSB  EVAL  LEDS\n",
       "dataset     BLESS  LMDIAG  CLSB  EVAL  LEDS\n",
       "Group_And    21.0    43.2  42.6  14.3  33.4\n",
       "Group_Best   41.6    68.9  61.0  37.5  54.9\n",
       "Group_Or     46.7    79.3  67.0  53.6  64.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>BLESS</th>\n",
       "      <th>LMDIAG</th>\n",
       "      <th>CLSB</th>\n",
       "      <th>EVAL</th>\n",
       "      <th>LEDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <td>BLESS</td>\n",
       "      <td>LMDIAG</td>\n",
       "      <td>CLSB</td>\n",
       "      <td>EVAL</td>\n",
       "      <td>LEDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group_And</th>\n",
       "      <td>25.1</td>\n",
       "      <td>57.5</td>\n",
       "      <td>48.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>42.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group_Best</th>\n",
       "      <td>39.2</td>\n",
       "      <td>72.4</td>\n",
       "      <td>60.9</td>\n",
       "      <td>38.0</td>\n",
       "      <td>57.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group_Or</th>\n",
       "      <td>44.1</td>\n",
       "      <td>75.9</td>\n",
       "      <td>64.6</td>\n",
       "      <td>49.6</td>\n",
       "      <td>65.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset     BLESS  LMDIAG  CLSB  EVAL  LEDS\n",
       "dataset     BLESS  LMDIAG  CLSB  EVAL  LEDS\n",
       "Group_And    25.1    57.5  48.2  17.8  42.2\n",
       "Group_Best   39.2    72.4  60.9  38.0  57.8\n",
       "Group_Or     44.1    75.9  64.6  49.6  65.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "dataset &  BLESS &  LMDIAG &  CLSB &  EVAL &  LEDS \\\\\n",
      "\\midrule\n",
      "dataset    &  BLESS &  LMDIAG &  CLSB &  EVAL &  LEDS \\\\\n",
      "Group\\_And  &   21.0 &    43.2 &  42.6 &  14.3 &  33.4 \\\\\n",
      "Group\\_Best &   41.6 &    68.9 &  61.0 &  37.5 &  54.9 \\\\\n",
      "Group\\_Or   &   46.7 &    79.3 &  67.0 &  53.6 &  64.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "dataset &  BLESS &  LMDIAG &  CLSB &  EVAL &  LEDS \\\\\n",
      "\\midrule\n",
      "dataset    &  BLESS &  LMDIAG &  CLSB &  EVAL &  LEDS \\\\\n",
      "Group\\_And  &   25.1 &    57.5 &  48.2 &  17.8 &  42.2 \\\\\n",
      "Group\\_Best &   39.2 &    72.4 &  60.9 &  38.0 &  57.8 \\\\\n",
      "Group\\_Or   &   44.1 &    75.9 &  64.6 &  49.6 &  65.7 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-16a2fc632b30>:22: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df1.to_latex())\n",
      "<ipython-input-19-16a2fc632b30>:23: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df2.to_latex())\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEmCAYAAAB7zsvVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeVElEQVR4nO3de7RVdb338fcHxDAgUARygAoUoYiACJaCIHIULRPEvCKCN/TJk2KelDwjC8/JwThWltmj0Xm49UAhmkpkFuJDhHVEwA14QUFE5USKmCSelNv3+WNNNpvNviz2ba651uc1BmPN+Ztzrf3da7A/67d+c87fVERgZmbZ0yztAszMrG4c4GZmGeUANzPLKAe4mVlGOcDNzDLKAW5mllF5BbikdpIelrRW0suSTpV0hKSFktYlj4c3drFmZrZPvj3wHwFPRsRxQF/gZWASsCgiegCLknUzM2siqu1CHkmfAlYB3aPCzpJeAc6IiM2SjgIWR0TPml7ryCOPjK5du9a/ajOzErJixYp3I6JD5fZD8nhud2ALMF1SX2AFcDPQKSI2AyQh3rGqJ0uaAEwAOOaYY1i+fHkdfwUzs9Ik6Y2q2vMZQjkE6A88EBEnAR9yEMMlETE1IgZExIAOHQ74ADEzszrKJ8A3AZsi4tlk/WFygf52MnRC8vhO45RoZmZVqTXAI+KvwFuS9o5vDwdeAuYD45K2ccDjjVKhmZlVKZ8xcICvAbMlHQpsAK4iF/4PSboGeBO4qC4F7Ny5k02bNvHRRx/V5ekloWXLlnTp0oUWLVqkXYqZFZC8AjwiyoABVWwaXt8CNm3aRJs2bejatSuS6vtyRSci2Lp1K5s2baJbt25pl2NmBST1KzE/+ugj2rdv7/CuhiTat2/vbyhmdoDUAxxweNfC74+ZVaUgAtzMzA5evgcxzcxKjibX/9tvfLvxbltZ0j3wjRs30rt377z2LSsr44knnmjkiszM8lfSAX4wHOBmVmgyFeAbN27kuOOO49prr6V3796MGTOGp556ikGDBtGjRw+WLVvGsmXLOO200zjppJM47bTTeOWVVwB48cUXOeWUU+jXrx99+vRh3bp1+732hg0bOOmkk3juuecO+Lk7duzgzjvvZO7cufTr14+5c+fSo0cPtmzZAsCePXv47Gc/y7vvvsv48eO54YYbOP300/nc5z7HggULANi9ezff+MY3GDhwIH369OGnP/1pI79bZlbsMjcGvn79eubNm8fUqVMZOHAgc+bMYenSpcyfP5+7776bWbNmsWTJEg455BCeeuop7rjjDh555BEefPBBbr75ZsaMGcOOHTvYvXs3b7/9NgCvvPIKl156KdOnT6dfv34H/MxDDz2Uu+66i+XLl3P//fcDsHbtWmbPns3EiRN56qmn6Nu3L0ceeSSQ+6D5wx/+wGuvvcawYcNYv349s2bNom3btjz33HN8/PHHDBo0iLPPPtvndptZnWUuwLt168aJJ54IwAknnMDw4cORxIknnsjGjRvZtm0b48aNY926dUhi586dAJx66ql897vfZdOmTYwePZoePXoAsGXLFkaOHMkjjzzCCSeckHcdV199NSNHjmTixIlMmzaNq666qnzbxRdfTLNmzejRowfdu3dn7dq1/P73v2f16tU8/PDDAGzbto1169Y5wM2szjI1hALwiU98ony5WbNm5evNmjVj165dfOtb32LYsGG88MIL/PrXvy6/AObyyy9n/vz5HHbYYYwYMYKnn34agLZt23L00UfzzDPPHFQdRx99NJ06deLpp5/m2Wef5dxzzy3fVvm8bUlEBD/+8Y8pKyujrKyM119/nbPPPrtO74GZGWQwwGuzbds2OnfuDMCMGTPK2zds2ED37t256aabOP/881m9ejWQGx557LHHmDVrFnPmzKn2ddu0acMHH3ywX9u1117LFVdcwcUXX0zz5s3L2+fNm8eePXt47bXX2LBhAz179mTEiBE88MAD5d8IXn31VT788MOG+rXNrAQVXYDfdtttfPOb32TQoEHs3r27vH3u3Ln07t2bfv36sXbtWq688sryba1atWLBggXce++9PP541ZMqDhs2jJdeeqn8ICbA+eefz/bt2/cbPgHo2bMnQ4cO5dxzz+XBBx+kZcuWXHvttfTq1Yv+/fvTu3dvrr/+enbt2tUI74CZlYpab6nWkAYMGBCV78jz8ssvc/zxxzdZDQ1p+fLl3HLLLfzxj38sbxs/fjznnXceX/nKVxr0Z2X5fTLLqkK5kEfSiog4YELBzB3ELBRTpkzhgQceYPbs2WmXYmYlygFeye9+9ztuv/32/dq6devGo48+ul/bpEmTmDTpwDvLVRx3NzNrTA7wSkaMGMGIESPSLsPMrFZFdxDTzKxUOMDNzDLKAW5mllEFNwY+efLkBn29b3/72w36emZmhcI9cKB169Zpl2BmdtAc4GZmGeUAr2Dz5s0MGTKEfv360bt37/IrLFu3bs2tt95K//79GT58ePk84FW577776NWrF3369OHSSy8FqHaO8hkzZjBy5EjOOeccevbs2eDDR2ZW3BzgFcyZM4cRI0ZQVlbGqlWryucG//DDD+nfvz8rV65k6NChNQbtlClTeP7551m9ejUPPvggAMcddxxLlizh+eef56677uKOO+4o33/ZsmXMnj2bsrIy5s2bR+WpBszMqlNwBzHTNHDgQK6++mp27tzJqFGjygO8WbNmXHLJJQBcccUVjB49utrX6NOnD2PGjGHUqFGMGjUKoNo5ygHOOuss2rdvD8Do0aNZunQpAwYcMOWBmdkB3AOvYMiQISxZsoTOnTszduxYZs2aVeV+lef7rug3v/kNN954IytWrODkk0+ucY7yql6rptc2M6uo4HrgaZ7298Ybb9C5c2euu+46PvzwQ1auXMmVV17Jnj17ePjhh7n00kuZM2cOgwcPrvL5e/bs4a233mLYsGEMHjyYOXPmsH379mrnKAdYuHAh7733HocddhiPPfYY06ZNa+xf08yKRF4BLmkj8AGwG9gVEQMkHQHMBboCG4GLI+JvjVNm01i8eDH33HMPLVq0oHXr1uU98FatWvHiiy9y8skn07Zt2/L5wCvbvXs3V1xxBdu2bSMiuOWWW2jXrh233XYb48aN4wc/+AFnnnnmfs8ZPHgwY8eOZf369Vx++eUePjGzvOU1H3gS4AMi4t0Kbf8BvBcRUyRNAg6PiNurew3I7nzgrVu3Zvv27Q3+ujNmzNjvRsk1ycL7ZFZsCn0+8PqMgY8EZibLM4FR9XgtMzM7SPmOgQfwe0kB/DQipgKdImIzQERsltSxqidKmgBMADjmmGMaoOSmV1Xv+8YbbzzgRsg333zzAbdXq8n48eMZP358fcszsxKVb4APioi/JCG9UNLafH9AEvZTITeEUocaC9JPfvKTtEswsxKX1xBKRPwleXwHeBQ4BXhb0lEAyeM7jVWkmZkdqNYAl9RKUpu9y8DZwAvAfGBcsts4oOrbuZuZWaPIZwilE/BocoHJIcCciHhS0nPAQ5KuAd4ELmq8Ms3MrLJaAzwiNgB9q2jfCgxv6IIa4rSdihriFB4zs0LkS+lpvPnAN27cSO/evRvltc3MCu5Sems6hXKRgpnVjXvgFTTEfOArVqygb9++nHrqqfudarhx40ZOP/10+vfvT//+/fnTn/4E5C7fHzJkCBdccAG9evXihhtuYM+ePY37i5pZUXCAV9AQ84FfddVV3Hffffz5z3/er71jx44sXLiQlStXMnfuXG666abybcuWLeP73/8+a9as4bXXXuNXv/pV4/yCZlZUHOAVDBw4kOnTp/Od73yHNWvW0KZNG+DA+cCXLl1a5fO3bdvG+++/z9ChQwEYO3Zs+badO3dy3XXXceKJJ3LRRRfx0ksvlW875ZRT6N69O82bN+eyyy6r9vXNzCpygFdQ3/nAI6Labffeey+dOnVi1apVLF++nB07dlT7ep4T3MzyUXAHMdM8KFbf+cDbtWtH27ZtWbp0KYMHD2b27Nnl27Zt20aXLl1o1qwZM2fOZPfu3eXbli1bxuuvv86xxx7L3LlzmTBhQqP/rmaWfQUX4Gmq73zgANOnT+fqq6/mk5/8JCNGjChv/+pXv8qFF17IvHnzGDZsGK1atSrfduqppzJp0iTWrFlTfkDTzKw2ec0H3lA8H/iBFi9ezPe+9z0WLFhQ436N8T75NEKzmhXK30hjzAduZmYp8hBKHhprPnCAM844gzPOOKM+5ZlZiSqIAK/p7I1C1ZTzgTflMJeZZUfqQygtW7Zk69atDqlqRARbt26lZcuWaZdiZgUm9R54ly5d2LRpU42Xp5e6li1b0qVLl7TLMLMCk3qAt2jRgm7duqVdhplZ5qQ+hGJmZnXjADczyygHuJlZRjnAzcwyKvWDmGZmjaWmufuLgXvgZmYZ5R54hhV778LMauYeuJlZRrkHbmb7KZQpVK127oGbmWWUA9zMLKMc4GZmGZV3gEtqLul5SQuS9SMkLZS0Lnk8vPHKNDOzyg6mB34z8HKF9UnAoojoASxK1s3MrInkFeCSugBfAv6zQvNIYGayPBMY1bClmZlZTfLtgf8QuA3YU6GtU0RsBkgeO1b1REkTJC2XtNw3bTAzazi1Brik84B3ImJFXX5AREyNiAERMaBDhw51eQkzM6tCPhfyDALOl/RFoCXwKUn/F3hb0lERsVnSUcA7jVmomZntr9YeeER8MyK6RERX4FLg6Yi4ApgPjEt2Gwc83mhVmpnZAepzHvgU4CxJ64CzknUzM2siBzUXSkQsBhYny1uB4Q1fkpmZ5cNXYpqZZZQD3MwsoxzgZmYZ5QA3M8soB7iZWUY5wM3MMsoBbmaWUQ5wM7OMcoCbmWWUA9zMLKMc4GZmGeUANzPLKAe4mVlGOcDNzDLKAW5mllEOcDOzjHKAm5lllAPczCyjDuqWamZW+CZPnpx2CdZE3AM3M8soB7iZWUY5wM3MMsoBbmaWUQ5wM7OMcoCbmWWUA9zMLKMc4GZmGVVrgEtqKWmZpFWSXpQ0OWk/QtJCSeuSx8Mbv1wzM9srnx74x8CZEdEX6AecI+kLwCRgUUT0ABYl62Zm1kRqDfDI2Z6stkj+BTASmJm0zwRGNUqFZmZWpbzGwCU1l1QGvAMsjIhngU4RsRkgeezYeGWamVlleQV4ROyOiH5AF+AUSb3z/QGSJkhaLmn5li1b6lqnmZlVclBnoUTE+8Bi4BzgbUlHASSP71TznKkRMSAiBnTo0KGe5ZqZ2V75nIXSQVK7ZPkw4J+AtcB8YFyy2zjg8cYq0szMDpTPfOBHATMlNScX+A9FxAJJfwYeknQN8CZwUSPWaWZmldQa4BGxGjipivatwPDGKMrMzGrnKzHNzDLKAW5mllEOcDOzjHKAm5lllAPczCyjHOBmZhnlADczyygHuJlZRjnAzcwyygFuZpZRDnAzs4xygJuZZVQ+sxEWFU1WvV8jvh0NUImZWf24B25mllEOcDOzjHKAm5lllAPczCyjHOBmZhnlADczyygHuJlZRjnAzcwyygFuZpZRDnAzs4xygJuZZZQD3MwsoxzgZmYZ5QA3M8uoWqeTlXQ0MAv4NLAHmBoRP5J0BDAX6ApsBC6OiL81Xqk5kydPbuwfYWaWCfn0wHcBt0bE8cAXgBsl9QImAYsiogewKFk3M7MmUmuAR8TmiFiZLH8AvAx0BkYCM5PdZgKjGqtIMzM70EGNgUvqCpwEPAt0iojNkAt5oGNDF2dmZtXLO8AltQYeASZGxN8P4nkTJC2XtHzLli11qdHMzKqQV4BLakEuvGdHxK+S5rclHZVsPwp4p6rnRsTUiBgQEQM6dOjQEDWbmRl5BLgkAf8HeDkiflBh03xgXLI8Dni84cszM7Pq5HNX+kHAWGCNpLKk7Q5gCvCQpGuAN4GLGqdEMzOrSq0BHhFLAVWzeXjDlmNmZvnylZhmZhnlADczy6h8xsDNip4mVzdKmL/4djRAJWb5cw/czCyjHOBmZhnlADczyygHuJlZRjnAzcwyygFuZpZRDnAzs4xygJuZZZQD3MwsoxzgZmYZ5QA3M8soB7iZWUZ5MisrCpMnT067BLMm5x64mVlGOcDNzDLKAW5mllEOcDOzjHKAm5lllAPczCyjHOBmZhnlADczyygHuJlZRjnAzcwyygFuZpZRtQa4pGmS3pH0QoW2IyQtlLQueTy8ccs0M7PK8umBzwDOqdQ2CVgUET2ARcm6mZk1oVoDPCKWAO9Vah4JzEyWZwKjGrguMzOrRV3HwDtFxGaA5LFjw5VkZmb5aPSDmJImSFouafmWLVsa+8eZmZWMugb425KOAkge36lux4iYGhEDImJAhw4d6vjjzMyssroG+HxgXLI8Dni8YcoxM7N85XMa4S+APwM9JW2SdA0wBThL0jrgrGTdzMyaUK33xIyIy6rZNLyBazEzs4PgKzHNzDLKAW5mllEOcDOzjHKAm5lllAPczCyjHOBmZhnlADczyygHuJlZRjnAzcwyygFuZpZRDnAzs4xygJuZZZQD3MwsoxzgZmYZ5QA3M8soB7iZWUY5wM3MMsoBbmaWUQ5wM7OMcoCbmWWUA9zMLKMc4GZmGeUANzPLKAe4mVlGOcDNzDLKAW5mllEOcDOzjKpXgEs6R9IrktZLmtRQRZmZWe3qHOCSmgM/Ac4FegGXSerVUIWZmVnN6tMDPwVYHxEbImIH8EtgZMOUZWZmtalPgHcG3qqwvilpMzOzJqCIqNsTpYuAERFxbbI+FjglIr5Wab8JwIRktSfwSt3LbRBHAu+mXEOh8Huxj9+Lffxe7FMo78WxEdGhcuMh9XjBTcDRFda7AH+pvFNETAWm1uPnNChJyyNiQNp1FAK/F/v4vdjH78U+hf5e1GcI5Tmgh6Rukg4FLgXmN0xZZmZWmzr3wCNil6R/Bn4HNAemRcSLDVaZmZnVqD5DKETEE8ATDVRLUymY4ZwC4PdiH78X+/i92Keg34s6H8Q0M7N0+VJ6M7OMcoCbmWWUA9zMLKOKOsAlHSupbYX1YZJ+JOnryamPZvuR9EzaNaRJUgtJJ0nqmHYtVruiDnDgIaAVgKR+wDzgTaAv8L9TrKvJSWopaZyk85Vzu6QFyQfakWnXV0COSbuApiTpQUknJMttgVXALOB5SZelWlwTk/QpST0qrF8k6crkX6c0a6tOUZ+FIml1RPRJlr8H7ImI2yQ1A8r2bisFkh4CdpL7QDsceAH4NTAY6BcR56VYXsGQ9GZElEyIS3oxIvYG+ETgjIgYJenTwG8j4qR0K2w6kqYCf4qIGcn6euC3wGHAroi4IcXyqlSv88AzQBWWzwS+CRAReyRV/Yzi1Ssieks6BNgUEUOT9iclrUqzsKYmaXR1m8j9sZaSHRWWzyL3LZWI+GsJ/o0MBK6vsP7B3rmdJC1Np6SaFXuAP530PDeT63U+DSDpKPb/j1sKdkD5FbSV56zZnUI9afpyDdsWNFkVheF9SecB/w0MAq4BSD7oS+3D7JDYf0hibIXldk1dTD6KPcAnApcARwGDI2Jn0v5p4F9TqyodXSTdR66XuXeZZL2kpgGOiKuq21aoY52N6HrgPnJ/ExMj4q9J+3DgN6lVlY49kj699z2IiBcAJHUG9qRaWTWKegy8MkntgSHAmxGxIu16mpKkcTVtj4iZTVVLoUkO3l0IXA4cHxEl9YFmOZKuAG4GbgWeT5r7A98D7ouIn6dVW3WKOsAlLQAmRcQLybDJSmA58BlgakT8MNUCUybpcOD9KOb/BNWQdBhwPrnQ7g+0AUYBSyKiIHtbjUXSMOCfgeOSppeB+yNicWpFpUTSOcAdwAlJ0wvAlIj4bXpVVa/YTyPstvdrEHAVsDAivgx8Hrg6vbKanqQ7JR2XLH9C0tPAa8Dbkv4p3eqalqTZwKvA2cD9QFfgbxGxuATD+0vANHJj/5cDY8hNUDdN0hfTrC0NEfFkRAyJiPbJv6HA/0tuYFNwij3Ad1ZYHk4yc2JEfECBjmk1okvYdzekceTGvjsAQ4G70yoqJb2Bv5Hraa6NiN1AyX0LSXwDGBUR0yNiVUSURcQ0ct9Gbk+5ttRIai7pXEmzgDfI/f0UnGI/iPmWpK+Ru3tQf+BJKP/63CLNwlKwo8JQyQjgl0lwvZyccVAyIqJv8m3kcuApSe8AbSoewCohn46IA04jjYjVJXhAF0lDyP2/+BKwjNyZOd0i4n9SLawaxd4Dv4bcWNZ44JKIeD9p/wIwPa2iUvKxpN6SOgDDgN9X2NYqpZpSExFrI+LOiOgJ3ELu6sNlkv6UcmlN7cM6bis6kjYBU4BnyF03cSHwj0INbyjyg5g1kXRIROxKu46mIunzwExywyY/jIh/S9q/CIyNiJK5bFrSS8Bsct9CXqvQLmBIRPwhteKamKT3gSVVbSJ36u3hTVxSaiT9iNzQ0RpgDvA4sCYiuqdaWA2KOsAlLY2IwcnyzyNibIVtKyOif3rVFQ5JF0bEI2nX0VQk9SV3D9eLyd1x/BfAQxFxwE25i52koTVtL6UPMyj/EB8GXAZ8EfgUuW/yT0TE9jRrq0qxB/jze+dyqBzYFbeVulKb/6MiSV8gd4DqQmA98IuI+Fm6VTUdSZ+KiL9Xs+2YiHizqWsqFJJaAOeS+7A/OyIKbtK3Yh8Dr+nTqXg/uQ5eyU16sVdE/FdE3AJcSW66hftTLqmpLd67IGlRpW2PNW0phSUidkbE/Ii4HDg67XqqUuxnH7STdAG5D6p2FSYxEtC2+qeVnJL8MJM0kNxX5QuBjeRuYDsvzZpSUPHD+4gathU9SWuo+W+h4GYvLfYA/wO5q+32LlecxKiqAzdFq4b/nAJK6nQxSXeTGzb5G/BLYFBEbEq3qtRENctVrRe7zE2pXNQBXsukRRc2ZS0FYDS5oH6rUvuxQKkdvPsYODciXk27kALQUdLXyX2Q712GfRd6lYyIeANAUjtg740dXo2IbelVVbNiHwOvyb1pF9DE7gX+HhFvVPwH/A+l9178Y294V75EOumdl5KfkZsHpnWF5b3r/5liXU1O0qGSZrBvOO1nwEZJ0wr1FoxFfRZKTSS9FREFeWCiMUh6ISJ6V7NtTUSc2NQ1paXiGUlVnJ3k00sTkiaW0oRvku4iN9HdDcl0G0hqA/wEeCMivpVmfVUp5R54qX1ytaxhW6lN3K9qlqtaL2Vfr32XojIauG5veEP5vElfBS5IraoaFPUYuA/c7ec5SddVPsdZ0jVASc2Njg/c5avUPsz2VHXZfERsl1SQ/y+KOsDJ4FHlRjQReFTSGPYF9gDgUAq0d9GI+kr6O8k9MJNlkvWavqmUmoIMrUYUyRz5VX1wFeTspSU3Bi7pSGBrKd7EAMon7987Fv5iRDydZj2WLkkfUP231MMiotg7eeUkbSQX1FUFeBTinChFHeDJZdJTgPeAfwN+DhxJbuz/yoh4MsXyzMzqpdgDfDm52yO1JXda0LkR8V/JXNC/8FwoZraXpBrPPoqIlU1VS76KPcDLIqJfsvxyRBxfYZsnszKzcpL2AC8CW/Y2VdgcEXFm01dVs2If36p44OEflbYV7yeXmdXFreTmxfkHuSkWHi3EKWQrKvYe+G5ydxURuXOd954iJKBlRJTabdXMrBaSupGb5Gwkufth3h0RZelWVbWi7oFHRPO0azCzbImI1yU9Tq7TNxb4HFCQAV7UPXAzs3xJ6k7u5g0jyU369ktgQUR8lGphNXCAm5lRfhBzNbl7Yf6dSsfJIuIHadRVk6IeQjEzOwh3sS+0W1faVpA9XffAzcxqUagzMzrAzcxqUag3/i7l6WTNzPJVkDMzOsDNzGpXkEMVPohpZkbtMzM2cTl58Ri4mVlGeQjFzCyjHOBmZhnlALeiIuk7kv6lhu2jJPVq4J/ZVdLlDfmaZvlwgFupGQU0aIADXQEHuDU5B7hlnqR/lfSKpKeAnknbdZKek7RK0iOSPinpNOB84B5JZZI+U9V+yfMvkvRC0r4kaWsu6Z5k/9WSrk9KmAKcnrzmLSm8BVaifBaKZZqkk4EZwOfJnRa7EngQmB4RW5N9/h14OyJ+LGkGuRnmHk62ta9mvzXAORHx35LaRcT7kiYAHSPi3yV9AngGuAg4FviXiDivCX91M58Hbpl3Ork7p/wPgKT5SXvvJJDbkZuY6HfVPL+6/Z4BZkh6CPhV0nY20EfSV5L1tkAPYEcD/j5meXOAWzGo6mvkDGBURKySNB44o5rnVrlfRNwg6fPAl4AySf3IXdDxtYjY78NAUnWvbdaoPAZuWbcEuEDSYZLaAF9O2tsAmyW1AMZU2P+DZBs17SfpMxHxbETcCbwLHE2ud/6/kn2R9DlJrap4TbMm4R64ZVpErJQ0l9wtr94A/phs+hbwbNK2hn0B+0vgZ5JuAr5Sw373SOpBrte9CFhFbrL/rsBKSSJ39/JRSfsuSauAGRFxb6P9wmYV+CCmmVlGeQjFzCyjHOBmZhnlADczyygHuJlZRjnAzcwyygFuZpZRDnAzs4z6//u8p4LUSRIhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for name, group in dataset_to_df_res.groupby('dataset'):\n",
    "#     display(group)\n",
    "\n",
    "dataset_to_df_res[['dataset','Group_And', 'mask_type']].pivot(index='dataset',\n",
    "                                                              columns=['mask_type'], \n",
    "                                                              values='Group_And').reindex(['lsp_sap', 'lsp_dap'], axis=1).plot(kind='bar',\n",
    "                                                                                                                              color=['grey','green'])\n",
    "\n",
    "df1 = dataset_to_df_res.query(\"mask_type=='lsp_sap'\")[['dataset','Group_And', 'Group_Best', 'Group_Or']]\n",
    "df1.plot(x='dataset',  kind='bar', color=['orange', 'green', 'grey'], title='lsp_sap')\n",
    "df1.index = df1['dataset']\n",
    "df1 = df1.reindex(['BLESS', 'LMDIAG', 'CLSB', 'EVAL', 'LEDS']).T\n",
    "\n",
    "\n",
    "df2 = dataset_to_df_res.query(\"mask_type=='lsp_dap'\")[['dataset','Group_And', 'Group_Best', 'Group_Or']]\n",
    "df2.plot(x='dataset',  kind='bar', color=['orange', 'green', 'grey'], title='lsp_dap' )\n",
    "df2.index = df2['dataset']\n",
    "df2 = df2.reindex(['BLESS', 'LMDIAG', 'CLSB', 'EVAL', 'LEDS']).T\n",
    "\n",
    "display(df1)\n",
    "display(df2)\n",
    "print(df1.to_latex())\n",
    "print(df2.to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d009efa7-63aa-4bf7-83fa-b1cf1f3f2255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mask_sentences_plural_1</th>\n",
       "      <th>mask_sentences_plural_2</th>\n",
       "      <th>mask_sentences_plural_3</th>\n",
       "      <th>mask_sentences_plural_4</th>\n",
       "      <th>mask_sentences_plural_5</th>\n",
       "      <th>mask_sentences_plural_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['[MASK] such as aeroplanes and airplanes.', '...</td>\n",
       "      <td>['[MASK], including aeroplanes and airplanes.'...</td>\n",
       "      <td>['[MASK], especially aeroplanes and airplanes....</td>\n",
       "      <td>['aeroplanes, airplanes and other [MASK].', 'a...</td>\n",
       "      <td>['aeroplanes, airplanes or other [MASK].', 'ae...</td>\n",
       "      <td>['such [MASK] as aeroplanes and airplanes.', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MA...</td>\n",
       "      <td>['[MASK], including alligators and snakes.', '...</td>\n",
       "      <td>['[MASK], especially alligators and snakes.', ...</td>\n",
       "      <td>['alligators, snakes and other [MASK].', 'alli...</td>\n",
       "      <td>['alligators, snakes or other [MASK].', 'allig...</td>\n",
       "      <td>['such [MASK] as alligators and snakes.', 'suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MA...</td>\n",
       "      <td>['[MASK], including alligators and snakes.', '...</td>\n",
       "      <td>['[MASK], especially alligators and snakes.', ...</td>\n",
       "      <td>['alligators, snakes and other [MASK].', 'alli...</td>\n",
       "      <td>['alligators, snakes or other [MASK].', 'allig...</td>\n",
       "      <td>['such [MASK] as alligators and snakes.', 'suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MA...</td>\n",
       "      <td>['[MASK], including alligators and snakes.', '...</td>\n",
       "      <td>['[MASK], especially alligators and snakes.', ...</td>\n",
       "      <td>['alligators, snakes and other [MASK].', 'alli...</td>\n",
       "      <td>['alligators, snakes or other [MASK].', 'allig...</td>\n",
       "      <td>['such [MASK] as alligators and snakes.', 'suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['[MASK] such as alligators and snakes.', '[MA...</td>\n",
       "      <td>['[MASK], including alligators and snakes.', '...</td>\n",
       "      <td>['[MASK], especially alligators and snakes.', ...</td>\n",
       "      <td>['alligators, snakes and other [MASK].', 'alli...</td>\n",
       "      <td>['alligators, snakes or other [MASK].', 'allig...</td>\n",
       "      <td>['such [MASK] as alligators and snakes.', 'suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>['[MASK] such as yoyos and mexicos.', '[MASK] ...</td>\n",
       "      <td>['[MASK], including yoyos and mexicos.', '[MAS...</td>\n",
       "      <td>['[MASK], especially yoyos and mexicos.', '[MA...</td>\n",
       "      <td>['yoyos, mexicos and other [MASK].', 'yoyos, c...</td>\n",
       "      <td>['yoyos, mexicos or other [MASK].', 'yoyos, ca...</td>\n",
       "      <td>['such [MASK] as yoyos and mexicos.', 'such [M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>['[MASK] such as yoyos and mexicos.', '[MASK] ...</td>\n",
       "      <td>['[MASK], including yoyos and mexicos.', '[MAS...</td>\n",
       "      <td>['[MASK], especially yoyos and mexicos.', '[MA...</td>\n",
       "      <td>['yoyos, mexicos and other [MASK].', 'yoyos, c...</td>\n",
       "      <td>['yoyos, mexicos or other [MASK].', 'yoyos, ca...</td>\n",
       "      <td>['such [MASK] as yoyos and mexicos.', 'such [M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>['[MASK] such as zebras and elephants.', '[MAS...</td>\n",
       "      <td>['[MASK], including zebras and elephants.', '[...</td>\n",
       "      <td>['[MASK], especially zebras and elephants.', '...</td>\n",
       "      <td>['zebras, elephants and other [MASK].', 'zebra...</td>\n",
       "      <td>['zebras, elephants or other [MASK].', 'zebras...</td>\n",
       "      <td>['such [MASK] as zebras and elephants.', 'such...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>['[MASK] such as zebras and elephants.', '[MAS...</td>\n",
       "      <td>['[MASK], including zebras and elephants.', '[...</td>\n",
       "      <td>['[MASK], especially zebras and elephants.', '...</td>\n",
       "      <td>['zebras, elephants and other [MASK].', 'zebra...</td>\n",
       "      <td>['zebras, elephants or other [MASK].', 'zebras...</td>\n",
       "      <td>['such [MASK] as zebras and elephants.', 'such...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>['[MASK] such as zebras and elephants.', '[MAS...</td>\n",
       "      <td>['[MASK], including zebras and elephants.', '[...</td>\n",
       "      <td>['[MASK], especially zebras and elephants.', '...</td>\n",
       "      <td>['zebras, elephants and other [MASK].', 'zebra...</td>\n",
       "      <td>['zebras, elephants or other [MASK].', 'zebras...</td>\n",
       "      <td>['such [MASK] as zebras and elephants.', 'such...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1310 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                mask_sentences_plural_1  \\\n",
       "0     ['[MASK] such as aeroplanes and airplanes.', '...   \n",
       "1     ['[MASK] such as alligators and snakes.', '[MA...   \n",
       "2     ['[MASK] such as alligators and snakes.', '[MA...   \n",
       "3     ['[MASK] such as alligators and snakes.', '[MA...   \n",
       "4     ['[MASK] such as alligators and snakes.', '[MA...   \n",
       "...                                                 ...   \n",
       "1305  ['[MASK] such as yoyos and mexicos.', '[MASK] ...   \n",
       "1306  ['[MASK] such as yoyos and mexicos.', '[MASK] ...   \n",
       "1307  ['[MASK] such as zebras and elephants.', '[MAS...   \n",
       "1308  ['[MASK] such as zebras and elephants.', '[MAS...   \n",
       "1309  ['[MASK] such as zebras and elephants.', '[MAS...   \n",
       "\n",
       "                                mask_sentences_plural_2  \\\n",
       "0     ['[MASK], including aeroplanes and airplanes.'...   \n",
       "1     ['[MASK], including alligators and snakes.', '...   \n",
       "2     ['[MASK], including alligators and snakes.', '...   \n",
       "3     ['[MASK], including alligators and snakes.', '...   \n",
       "4     ['[MASK], including alligators and snakes.', '...   \n",
       "...                                                 ...   \n",
       "1305  ['[MASK], including yoyos and mexicos.', '[MAS...   \n",
       "1306  ['[MASK], including yoyos and mexicos.', '[MAS...   \n",
       "1307  ['[MASK], including zebras and elephants.', '[...   \n",
       "1308  ['[MASK], including zebras and elephants.', '[...   \n",
       "1309  ['[MASK], including zebras and elephants.', '[...   \n",
       "\n",
       "                                mask_sentences_plural_3  \\\n",
       "0     ['[MASK], especially aeroplanes and airplanes....   \n",
       "1     ['[MASK], especially alligators and snakes.', ...   \n",
       "2     ['[MASK], especially alligators and snakes.', ...   \n",
       "3     ['[MASK], especially alligators and snakes.', ...   \n",
       "4     ['[MASK], especially alligators and snakes.', ...   \n",
       "...                                                 ...   \n",
       "1305  ['[MASK], especially yoyos and mexicos.', '[MA...   \n",
       "1306  ['[MASK], especially yoyos and mexicos.', '[MA...   \n",
       "1307  ['[MASK], especially zebras and elephants.', '...   \n",
       "1308  ['[MASK], especially zebras and elephants.', '...   \n",
       "1309  ['[MASK], especially zebras and elephants.', '...   \n",
       "\n",
       "                                mask_sentences_plural_4  \\\n",
       "0     ['aeroplanes, airplanes and other [MASK].', 'a...   \n",
       "1     ['alligators, snakes and other [MASK].', 'alli...   \n",
       "2     ['alligators, snakes and other [MASK].', 'alli...   \n",
       "3     ['alligators, snakes and other [MASK].', 'alli...   \n",
       "4     ['alligators, snakes and other [MASK].', 'alli...   \n",
       "...                                                 ...   \n",
       "1305  ['yoyos, mexicos and other [MASK].', 'yoyos, c...   \n",
       "1306  ['yoyos, mexicos and other [MASK].', 'yoyos, c...   \n",
       "1307  ['zebras, elephants and other [MASK].', 'zebra...   \n",
       "1308  ['zebras, elephants and other [MASK].', 'zebra...   \n",
       "1309  ['zebras, elephants and other [MASK].', 'zebra...   \n",
       "\n",
       "                                mask_sentences_plural_5  \\\n",
       "0     ['aeroplanes, airplanes or other [MASK].', 'ae...   \n",
       "1     ['alligators, snakes or other [MASK].', 'allig...   \n",
       "2     ['alligators, snakes or other [MASK].', 'allig...   \n",
       "3     ['alligators, snakes or other [MASK].', 'allig...   \n",
       "4     ['alligators, snakes or other [MASK].', 'allig...   \n",
       "...                                                 ...   \n",
       "1305  ['yoyos, mexicos or other [MASK].', 'yoyos, ca...   \n",
       "1306  ['yoyos, mexicos or other [MASK].', 'yoyos, ca...   \n",
       "1307  ['zebras, elephants or other [MASK].', 'zebras...   \n",
       "1308  ['zebras, elephants or other [MASK].', 'zebras...   \n",
       "1309  ['zebras, elephants or other [MASK].', 'zebras...   \n",
       "\n",
       "                                mask_sentences_plural_6  \n",
       "0     ['such [MASK] as aeroplanes and airplanes.', '...  \n",
       "1     ['such [MASK] as alligators and snakes.', 'suc...  \n",
       "2     ['such [MASK] as alligators and snakes.', 'suc...  \n",
       "3     ['such [MASK] as alligators and snakes.', 'suc...  \n",
       "4     ['such [MASK] as alligators and snakes.', 'suc...  \n",
       "...                                                 ...  \n",
       "1305  ['such [MASK] as yoyos and mexicos.', 'such [M...  \n",
       "1306  ['such [MASK] as yoyos and mexicos.', 'such [M...  \n",
       "1307  ['such [MASK] as zebras and elephants.', 'such...  \n",
       "1308  ['such [MASK] as zebras and elephants.', 'such...  \n",
       "1309  ['such [MASK] as zebras and elephants.', 'such...  \n",
       "\n",
       "[1310 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../log/bert-large-uncased/clsb/consistency_group/IsA.lsp_dap.csv\")\n",
    "# df.head()\n",
    "\n",
    "pred_col_sg=[x for x in df.columns if 'mask_sentences_singular_' in x and 'score' not in x]\n",
    "pred_col_pl=[x for x in df.columns if 'mask_sentences_plural_' in x and 'score' not in x]\n",
    "df[pred_col_pl]\n",
    "# pred_col_pl\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11cfa52e-1fda-42ff-9828-0064bcd4a976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GameOfThrones\n"
     ]
    }
   ],
   "source": [
    "Tv = {'BreakingBad':100, 'GameOfThrones':1292, 'TMKUC' : 88}\n",
    " \n",
    "Keymax = max(zip(Tv.values(), Tv.keys()))[1]\n",
    "print(Keymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9af9311b-7e61-4184-9d3c-2aec5ed6ec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv\n",
      "\n",
      "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv ../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv\n",
      "\n",
      "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv ../log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv\n",
      "\n",
      "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv\n",
      "\n",
      "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv\n",
      "\n",
      "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "def get_dataset_to_respath(print_flag=False):\n",
    "    # remote path \n",
    "    dataset_to_respath = {'hypernymsuite-BLESS': 'log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'lm_diagnostic_extended-singular': 'log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv', 'clsb-singular': 'log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv', 'hypernymsuite-LEDS': 'log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-EVAL': 'log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv', 'hypernymsuite-SHWARTZ': 'log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv'}\n",
    "\n",
    "    source_dir = 'spartan:~/cogsci/DAP/'\n",
    "    target_dir = '../'\n",
    "    dataset_to_localpath = defaultdict()\n",
    "    dataset_rename = {\n",
    "        'hypernymsuite-BLESS': 'BLESS', 'lm_diagnostic_extended-singular': 'LMDIAG', 'clsb-singular':'CLSB', 'hypernymsuite-LEDS': 'LEDS', 'hypernymsuite-EVAL': 'EVAL', 'hypernymsuite-SHWARTZ': \n",
    "        \"SHWARTZ\"\n",
    "    }\n",
    "    for dataset, path in dataset_to_respath.items():\n",
    "        path = path.replace(\".tsv\", \".csv\")\n",
    "        source_path = source_dir + path \n",
    "        dataset_l1 = dataset.split(\"-\")[0]\n",
    "        dataset_l2 = dataset.split(\"-\")[1] \n",
    "        target_path = target_dir + path\n",
    "        scp_string = f\"!scp {source_path} {target_path}\"\n",
    "        if print_flag:\n",
    "            print(scp_string)\n",
    "            print()\n",
    "#         print(target_path)\n",
    "        dataset_to_localpath[dataset_rename[dataset]] = target_path \n",
    "#     print(dataset_to_localpath)\n",
    "    return dataset_to_localpath\n",
    "dataset_to_localpath = get_dataset_to_respath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2bf95dc-3018-4c54-b44a-4722a669586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "exp_data_results_anchor_type_Coordinate_remov 100%   13MB  85.7MB/s   00:00    \n",
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "exp_data_results_anchor_type_Coordinate_remov 100% 6674KB  70.3MB/s   00:00    \n",
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "exp_data_results_anchor_type_Coordinate_remov 100%   14MB  77.0MB/s   00:00    \n",
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "exp_data_results_anchor_type_Coordinate_remov 100%   13MB  73.2MB/s   00:00    \n",
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "exp_data_results_anchor_type_Coordinate_remov 100%   10MB  72.7MB/s   00:00    \n",
      "/home/chunhua/.bashrc: line 103: bind: warning: line editing not enabled\n",
      "/home/chunhua/.bashrc: line 104: bind: warning: line editing not enabled\n",
      "exp_data_results_anchor_type_Coordinate_remov 100%  124MB 101.9MB/s   00:01    \n"
     ]
    }
   ],
   "source": [
    "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/BLESS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv\n",
    "\n",
    "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv ../log/bert-large-uncased/lm_diagnostic_extended/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.LM_DIAGNOSTIC_EXTENDED.csv\n",
    "\n",
    "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv ../log/bert-large-uncased/clsb/singular/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.CLSB.csv\n",
    "\n",
    "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/LEDS/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv\n",
    "\n",
    "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/EVAL/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv\n",
    "\n",
    "!scp spartan:~/cogsci/DAP/log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv ../log/bert-large-uncased/hypernymsuite/SHWARTZ/exp_data_results_anchor_type_Coordinate_remove_Y_PUNC_FULL_concate_or_single_max_anchor_num_10_anchor_scorer_probAvg_filter_obj_True_filter_objects_with_input_True_wnp_True_cpt_False.HYPERNYMSUITE.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
